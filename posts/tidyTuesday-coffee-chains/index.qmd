---
title: 'tidyTuesday: coffee chains'
author: 'Robert W. Walker'
date: '2023-02-05'
categories:
  - R
  - tidyverse
  - Maps
  - geocoding
tags:
  - R
  - tidyTuesday
  - tidyverse
bibliography: "bibliography.bib"
nocite: |
     @*
format: 
   html:
     code-fold: true
     code-copy: hover
     code-block-border-left: true
     df-print: paged
     fig-format: retina
     footnotes-hover: true
     html-math-method: katex
     toc: true
     toc-title: Navigation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, message=FALSE, warning=FALSE)
```


# The tidyTuesday for this week is coffee chain locations

For this week:
1. The basic link to the [`#tidyTuesday`](https://github.com/rfordatascience/tidytuesday) shows [an original article](http://flowingdata.com/2014/03/18/coffee-place-geography/) for Week 6.

The page notes that Starbucks, Tim Horton, and Dunkin Donuts have raw data available.

```{r LoadData, message=FALSE, warning=FALSE}
library(readxl)
library(tidyverse)
library(janitor)
library(geofacet)
library(ggbeeswarm)
library(ggrepel)
library(leaflet)
Starbucks <- readRDS(url("https://github.com/robertwwalker/academic-mymod/raw/master/data/week6SB.rds"))
Dunkin.Donuts <- readRDS(url("https://github.com/robertwwalker/academic-mymod/raw/master/data/week6DD.rds"))
Tim.Hortons <- readRDS(url("https://github.com/robertwwalker/academic-mymod/raw/master/data/week6TH.rds"))
```

What do the data look like?

### Starbucks Data

```{r}
library(skimr)
skim(Starbucks)
```

### Dunkin Donuts Data


```{r}
skim(Dunkin.Donuts)
```

### Tim Horton's Data

```{r}
skim(Tim.Hortons)
```

## Plot Starbucks

A basic plot of the global Starbucks data.

```{r}
library(ggmap)
mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
mp <- ggplot() +   mapWorld
mp <- mp + geom_point(aes(x=Starbucks$Longitude, y=Starbucks$Latitude) ,color="dark green", size=0.5) + xlab("") + ylab("")
mp <- mp + geom_point(aes(x=Dunkin.Donuts$loc_LONG_centroid, y=Dunkin.Donuts$loc_LAT_centroid) ,color="orange", size=0.5) + xlab("") + ylab("") + theme_void()
mp
```

## Starbucks and Dunkin

Google Maps interface changed and there are limits to what can be geocoded without fees.  It can get rather expensive if one is not careful.  Let me try this out.  The first step is to create the addresses to be geocoded.  Let's look at the `Tim.Hortons` data.

```{r}
library(DT)
head(Tim.Hortons) %>% datatable()
```

I will need to paste/glue them together.  I want to paste the address, the city, the state and postal code, then the country but the state and postal code are separate entries so paste them with a space delimiter embedded in the bigger paste command with a comma separation.

### Geocoding Tim Horton's

What follows is the code that I used to create them and to geocode them.  I then saved the result and will load it from the saved version.

```{r, eval=FALSE}
Tim.Hortons.GC <- Tim.Hortons %>% mutate(full.address=paste(address,city,paste(state, postal_code, sep=" "),toupper(country),sep=", "))
Tim.Hortons.GC <- Tim.Hortons.GC %>% mutate_geocode(full.address, output="latlon")
save(Tim.Hortons.GC, file="data/THGC.RData")
```

Load the saved and geocoded data

```{r}
load("data/THGC.RData")
head(Tim.Hortons.GC)
```

Now I want to filter off US locations and create the most basic data structure to map.

```{r}
THUS <- Tim.Hortons.GC %>% 
  select(country,full.address,lon,lat)
names(THUS) <- c("Country","Address","Longitude","Latitude")
THUS$chain <- "Tim Horton's"
head(THUS)
```

### Dunkin Donuts

Thankfully, Dunkin Donuts is already geocoded just as Starbucks was.  In this case, I just need some organized data that I can bind together with the same structure as the Tim Horton's data.

```{r}
DDUS <- Dunkin.Donuts %>% select(e_country, e_address, loc_LONG_centroid,loc_LAT_centroid)
names(DDUS) <- c("Country","Address","Longitude","Latitude")
DDUS$chain <- "Dunkin"
head(DDUS)
```

Finally, let me put together a version of the Starbucks data that looks just as the others.

```{r}
SBUX <- Starbucks %>% select(Country,`Street Address`,Longitude,Latitude)
names(SBUX) <- c("Country","Address","Longitude","Latitude")
SBUX$chain <- "Starbucks"
head(SBUX)
```

With all three of the data sources in a similar format and the like, it is now time to bind them together.  There are over 19,000 rows and this would yield 19,000+ popups.  That will excessively task resources so, as proof of concept, I will simply sample 300 of them and plot those.

```{r}
Map.Coffee.Complete <- bind_rows(DDUS,SBUX,THUS)
US.Map.Coffee <- Map.Coffee.Complete[c(sample(c(1:19246), size=300, replace=FALSE)),]
```

Now I have all the data that I need to build the map.  
That works as planned.

```{r}
mp <- leaflet() %>% 
  addTiles() %>%
  addMarkers(~Longitude, ~Latitude, data=US.Map.Coffee, popup=~Address)
mp
```

## A Full World Map

```{r}
library(ggmap)
mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
mp <- ggplot() + mapWorld
mp <- mp + geom_point(aes(x=Longitude, y=Latitude, color=chain), size=0.5, alpha=0.5, data=Map.Coffee.Complete) + xlab("") + ylab("") + theme_void()
mp
```


# References

```{r}
knitr::write_bib(names(sessionInfo()$otherPkgs), file="bibliography.bib")
```

