[
  {
    "objectID": "posts/smart-Prediction/index.html",
    "href": "posts/smart-Prediction/index.html",
    "title": "A Small Thread on Smart Prediction",
    "section": "",
    "text": "A linear regression example. The data can be loaded from the web.\n\n# if needed, download ugtests data\nurl <- \"http://peopleanalytics-regression-book.org/data/ugtests.csv\"\nugtests <- read.csv(url)\nstr(ugtests)\n\n'data.frame':   975 obs. of  4 variables:\n $ Yr1  : int  27 70 27 26 46 86 40 60 49 80 ...\n $ Yr2  : int  50 104 36 75 77 122 100 92 98 127 ...\n $ Yr3  : int  52 126 148 115 75 119 125 78 119 67 ...\n $ Final: int  93 207 175 125 114 159 153 84 147 80 ...\n\n\nThere are 975 individuals graduating in the past three years from the biology department of a large academic institution. We have data on four examinations:\n\na first year exam ranging from 0 to 100 (Yr1)\na second year exam ranging from 0 to 200 (Yr2)\na third year exam ranging from 0 to 200 (Yr3)\na Final year exam ranging from 0 to 300 (Final)\n\n\nlibrary(skimr); library(kableExtra); library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::group_rows() masks kableExtra::group_rows()\n✖ dplyr::lag()        masks stats::lag()\n\nskim(ugtests) %>% dplyr::filter(skim_type==\"numeric\") %>% kable()\n\n\n\n \n  \n    skim_type \n    skim_variable \n    n_missing \n    complete_rate \n    numeric.mean \n    numeric.sd \n    numeric.p0 \n    numeric.p25 \n    numeric.p50 \n    numeric.p75 \n    numeric.p100 \n    numeric.hist \n  \n \n\n  \n    numeric \n    Yr1 \n    0 \n    1 \n    52.14564 \n    14.92408 \n    3 \n    42 \n    53 \n    62 \n    99 \n    ▁▃▇▅▁ \n  \n  \n    numeric \n    Yr2 \n    0 \n    1 \n    92.39897 \n    30.03847 \n    6 \n    73 \n    94 \n    112 \n    188 \n    ▁▅▇▃▁ \n  \n  \n    numeric \n    Yr3 \n    0 \n    1 \n    105.12103 \n    33.50705 \n    8 \n    81 \n    105 \n    130 \n    198 \n    ▁▅▇▅▁ \n  \n  \n    numeric \n    Final \n    0 \n    1 \n    148.96205 \n    44.33966 \n    8 \n    118 \n    147 \n    175 \n    295 \n    ▁▅▇▃▁ \n  \n\n\n\n\n\n\n\n\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n# display a pairplot of all four columns of data\nGGally::ggpairs(ugtests)\n\n\n\n\n\nmy.lm <- lm(Final ~ Yr1 + Yr2 + Yr3, data=ugtests)\nsummary(my.lm)\n\n\nCall:\nlm(formula = Final ~ Yr1 + Yr2 + Yr3, data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-92.638 -20.349   0.001  18.954  98.489 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 14.14599    5.48006   2.581  0.00999 ** \nYr1          0.07603    0.06538   1.163  0.24519    \nYr2          0.43129    0.03251  13.267  < 2e-16 ***\nYr3          0.86568    0.02914  29.710  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.43 on 971 degrees of freedom\nMultiple R-squared:  0.5303,    Adjusted R-squared:  0.5289 \nF-statistic: 365.5 on 3 and 971 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\nugtests %>% mutate(Fitted.Value = predict(my.lm)) %>% kable() %>% scroll_box(height=\"300px\")\n\n\n\n \n  \n    Yr1 \n    Yr2 \n    Yr3 \n    Final \n    Fitted.Value \n  \n \n\n  \n    27 \n    50 \n    52 \n    93 \n    82.77839 \n  \n  \n    70 \n    104 \n    126 \n    207 \n    173.39734 \n  \n  \n    27 \n    36 \n    148 \n    175 \n    159.84579 \n  \n  \n    26 \n    75 \n    115 \n    125 \n    148.02242 \n  \n  \n    46 \n    77 \n    75 \n    114 \n    115.77826 \n  \n  \n    86 \n    122 \n    119 \n    159 \n    176.31713 \n  \n  \n    40 \n    100 \n    125 \n    153 \n    168.52573 \n  \n  \n    60 \n    92 \n    78 \n    84 \n    125.90895 \n  \n  \n    49 \n    98 \n    119 \n    147 \n    163.15331 \n  \n  \n    80 \n    127 \n    67 \n    80 \n    133.00197 \n  \n  \n    43 \n    134 \n    61 \n    154 \n    128.01391 \n  \n  \n    26 \n    53 \n    150 \n    154 \n    168.83298 \n  \n  \n    64 \n    123 \n    110 \n    175 \n    167.28471 \n  \n  \n    62 \n    84 \n    142 \n    182 \n    178.01432 \n  \n  \n    61 \n    65 \n    134 \n    155 \n    162.81842 \n  \n  \n    60 \n    150 \n    116 \n    198 \n    183.81939 \n  \n  \n    58 \n    76 \n    107 \n    161 \n    143.96109 \n  \n  \n    28 \n    81 \n    143 \n    229 \n    175.00126 \n  \n  \n    64 \n    87 \n    106 \n    100 \n    148.29571 \n  \n  \n    55 \n    111 \n    135 \n    179 \n    183.06708 \n  \n  \n    77 \n    97 \n    111 \n    164 \n    157.92531 \n  \n  \n    50 \n    92 \n    72 \n    130 \n    119.95460 \n  \n  \n    47 \n    83 \n    129 \n    194 \n    165.18879 \n  \n  \n    65 \n    72 \n    148 \n    152 \n    178.26106 \n  \n  \n    57 \n    180 \n    112 \n    216 \n    193.06715 \n  \n  \n    41 \n    41 \n    152 \n    123 \n    166.52931 \n  \n  \n    49 \n    90 \n    166 \n    232 \n    200.39004 \n  \n  \n    93 \n    102 \n    136 \n    168 \n    182.94018 \n  \n  \n    32 \n    62 \n    160 \n    151 \n    181.82752 \n  \n  \n    53 \n    73 \n    63 \n    88 \n    104.19713 \n  \n  \n    28 \n    84 \n    109 \n    184 \n    146.86195 \n  \n  \n    75 \n    125 \n    98 \n    134 \n    158.59539 \n  \n  \n    44 \n    55 \n    111 \n    115 \n    137.30246 \n  \n  \n    41 \n    127 \n    96 \n    167 \n    155.14171 \n  \n  \n    55 \n    97 \n    101 \n    170 \n    147.59592 \n  \n  \n    68 \n    109 \n    141 \n    229 \n    188.38693 \n  \n  \n    73 \n    52 \n    124 \n    132 \n    149.46722 \n  \n  \n    32 \n    92 \n    154 \n    245 \n    189.57199 \n  \n  \n    49 \n    65 \n    138 \n    180 \n    165.36883 \n  \n  \n    63 \n    107 \n    165 \n    213 \n    207.92058 \n  \n  \n    43 \n    87 \n    120 \n    211 \n    158.81869 \n  \n  \n    40 \n    110 \n    93 \n    151 \n    145.13679 \n  \n  \n    46 \n    71 \n    91 \n    121 \n    127.04145 \n  \n  \n    28 \n    118 \n    136 \n    180 \n    184.89905 \n  \n  \n    46 \n    124 \n    176 \n    232 \n    223.48248 \n  \n  \n    41 \n    97 \n    152 \n    214 \n    190.68129 \n  \n  \n    76 \n    95 \n    52 \n    123 \n    105.91152 \n  \n  \n    52 \n    106 \n    144 \n    166 \n    188.47370 \n  \n  \n    47 \n    104 \n    124 \n    111 \n    169.91737 \n  \n  \n    54 \n    27 \n    111 \n    90 \n    125.98673 \n  \n  \n    36 \n    97 \n    140 \n    187 \n    179.91299 \n  \n  \n    73 \n    22 \n    146 \n    160 \n    155.57364 \n  \n  \n    60 \n    68 \n    54 \n    125 \n    94.78176 \n  \n  \n    67 \n    45 \n    80 \n    145 \n    107.90209 \n  \n  \n    50 \n    99 \n    94 \n    168 \n    142.01859 \n  \n  \n    32 \n    72 \n    92 \n    114 \n    127.27405 \n  \n  \n    75 \n    103 \n    91 \n    152 \n    143.04734 \n  \n  \n    60 \n    80 \n    43 \n    125 \n    90.43469 \n  \n  \n    54 \n    13 \n    106 \n    143 \n    115.62032 \n  \n  \n    69 \n    64 \n    161 \n    161 \n    186.36874 \n  \n  \n    54 \n    125 \n    107 \n    98 \n    164.78997 \n  \n  \n    52 \n    65 \n    157 \n    183 \n    182.04486 \n  \n  \n    36 \n    138 \n    72 \n    152 \n    138.72937 \n  \n  \n    36 \n    131 \n    116 \n    203 \n    173.80034 \n  \n  \n    39 \n    105 \n    116 \n    158 \n    162.81500 \n  \n  \n    50 \n    71 \n    72 \n    65 \n    110.89761 \n  \n  \n    55 \n    110 \n    106 \n    133 \n    157.53103 \n  \n  \n    33 \n    89 \n    134 \n    122 \n    171.04054 \n  \n  \n    52 \n    68 \n    135 \n    138 \n    164.29372 \n  \n  \n    59 \n    97 \n    105 \n    132 \n    151.36275 \n  \n  \n    42 \n    101 \n    165 \n    174 \n    203.73632 \n  \n  \n    39 \n    76 \n    97 \n    173 \n    133.85978 \n  \n  \n    45 \n    63 \n    131 \n    124 \n    158.14239 \n  \n  \n    55 \n    71 \n    111 \n    139 \n    145.03931 \n  \n  \n    69 \n    55 \n    82 \n    119 \n    114.09836 \n  \n  \n    72 \n    62 \n    104 \n    171 \n    136.39042 \n  \n  \n    61 \n    108 \n    98 \n    160 \n    150.19917 \n  \n  \n    55 \n    90 \n    49 \n    117 \n    99.56150 \n  \n  \n    35 \n    84 \n    107 \n    178 \n    145.66277 \n  \n  \n    59 \n    36 \n    95 \n    122 \n    116.39753 \n  \n  \n    44 \n    74 \n    87 \n    144 \n    124.72053 \n  \n  \n    43 \n    78 \n    101 \n    124 \n    138.48918 \n  \n  \n    66 \n    142 \n    101 \n    244 \n    167.84005 \n  \n  \n    38 \n    71 \n    63 \n    96 \n    102.19417 \n  \n  \n    62 \n    96 \n    147 \n    248 \n    187.51815 \n  \n  \n    46 \n    63 \n    120 \n    194 \n    148.69592 \n  \n  \n    59 \n    105 \n    157 \n    198 \n    199.82845 \n  \n  \n    68 \n    72 \n    111 \n    160 \n    146.45894 \n  \n  \n    54 \n    86 \n    79 \n    124 \n    123.73077 \n  \n  \n    44 \n    66 \n    102 \n    136 \n    134.25546 \n  \n  \n    41 \n    87 \n    91 \n    127 \n    133.56188 \n  \n  \n    15 \n    97 \n    132 \n    193 \n    171.39099 \n  \n  \n    52 \n    88 \n    107 \n    93 \n    148.68036 \n  \n  \n    53 \n    92 \n    118 \n    182 \n    160.00402 \n  \n  \n    54 \n    71 \n    107 \n    114 \n    141.50056 \n  \n  \n    75 \n    71 \n    108 \n    147 \n    143.96279 \n  \n  \n    52 \n    54 \n    98 \n    122 \n    126.22552 \n  \n  \n    41 \n    72 \n    113 \n    172 \n    146.13759 \n  \n  \n    52 \n    74 \n    128 \n    108 \n    160.82167 \n  \n  \n    64 \n    95 \n    125 \n    158 \n    168.19393 \n  \n  \n    64 \n    122 \n    78 \n    168 \n    139.15162 \n  \n  \n    29 \n    57 \n    99 \n    101 \n    126.63646 \n  \n  \n    50 \n    107 \n    91 \n    163 \n    142.87183 \n  \n  \n    62 \n    98 \n    171 \n    197 \n    209.15707 \n  \n  \n    45 \n    65 \n    134 \n    162 \n    161.60200 \n  \n  \n    49 \n    93 \n    129 \n    174 \n    169.65369 \n  \n  \n    70 \n    37 \n    76 \n    137 \n    101.21716 \n  \n  \n    40 \n    71 \n    98 \n    154 \n    132.64506 \n  \n  \n    50 \n    105 \n    81 \n    154 \n    133.35245 \n  \n  \n    53 \n    66 \n    60 \n    126 \n    98.58109 \n  \n  \n    70 \n    110 \n    44 \n    105 \n    104.99919 \n  \n  \n    65 \n    37 \n    101 \n    102 \n    122.47906 \n  \n  \n    79 \n    122 \n    69 \n    92 \n    132.50088 \n  \n  \n    60 \n    63 \n    103 \n    131 \n    135.04371 \n  \n  \n    50 \n    114 \n    118 \n    189 \n    169.26422 \n  \n  \n    66 \n    94 \n    112 \n    101 \n    156.66084 \n  \n  \n    46 \n    156 \n    135 \n    184 \n    201.79068 \n  \n  \n    31 \n    85 \n    57 \n    108 \n    102.50589 \n  \n  \n    82 \n    99 \n    184 \n    211 \n    222.36274 \n  \n  \n    63 \n    71 \n    102 \n    172 \n    137.85639 \n  \n  \n    33 \n    78 \n    78 \n    144 \n    117.81825 \n  \n  \n    48 \n    39 \n    67 \n    88 \n    92.61602 \n  \n  \n    31 \n    80 \n    133 \n    153 \n    166.14124 \n  \n  \n    59 \n    67 \n    50 \n    86 \n    90.81172 \n  \n  \n    60 \n    128 \n    94 \n    171 \n    155.28613 \n  \n  \n    60 \n    121 \n    174 \n    263 \n    221.52163 \n  \n  \n    26 \n    108 \n    63 \n    158 \n    117.23941 \n  \n  \n    36 \n    129 \n    61 \n    146 \n    125.32530 \n  \n  \n    63 \n    83 \n    115 \n    144 \n    154.28567 \n  \n  \n    48 \n    74 \n    87 \n    111 \n    125.02463 \n  \n  \n    26 \n    132 \n    88 \n    81 \n    149.23229 \n  \n  \n    39 \n    125 \n    136 \n    201 \n    188.75433 \n  \n  \n    46 \n    121 \n    113 \n    126 \n    167.65071 \n  \n  \n    54 \n    79 \n    103 \n    150 \n    141.48812 \n  \n  \n    70 \n    95 \n    102 \n    136 \n    148.73942 \n  \n  \n    50 \n    85 \n    85 \n    132 \n    128.18946 \n  \n  \n    34 \n    74 \n    144 \n    176 \n    173.30410 \n  \n  \n    62 \n    97 \n    61 \n    168 \n    113.50085 \n  \n  \n    49 \n    56 \n    121 \n    141 \n    146.77068 \n  \n  \n    10 \n    36 \n    132 \n    153 \n    144.70245 \n  \n  \n    50 \n    92 \n    99 \n    143 \n    143.32800 \n  \n  \n    23 \n    102 \n    130 \n    170 \n    172.42426 \n  \n  \n    74 \n    126 \n    84 \n    110 \n    146.83111 \n  \n  \n    31 \n    88 \n    124 \n    142 \n    161.80039 \n  \n  \n    38 \n    149 \n    86 \n    123 \n    155.74509 \n  \n  \n    70 \n    102 \n    67 \n    136 \n    121.45958 \n  \n  \n    42 \n    104 \n    67 \n    111 \n    120.19341 \n  \n  \n    50 \n    103 \n    155 \n    248 \n    196.55029 \n  \n  \n    56 \n    26 \n    90 \n    97 \n    107.52819 \n  \n  \n    43 \n    77 \n    110 \n    100 \n    145.84903 \n  \n  \n    38 \n    83 \n    89 \n    106 \n    129.87730 \n  \n  \n    70 \n    86 \n    32 \n    88 \n    84.26017 \n  \n  \n    50 \n    93 \n    103 \n    113 \n    147.22201 \n  \n  \n    45 \n    92 \n    133 \n    186 \n    172.38103 \n  \n  \n    50 \n    123 \n    90 \n    146 \n    148.90671 \n  \n  \n    73 \n    105 \n    146 \n    204 \n    191.37033 \n  \n  \n    59 \n    78 \n    47 \n    79 \n    92.95881 \n  \n  \n    44 \n    49 \n    87 \n    116 \n    113.93839 \n  \n  \n    34 \n    58 \n    85 \n    59 \n    115.32834 \n  \n  \n    48 \n    161 \n    151 \n    289 \n    217.95006 \n  \n  \n    53 \n    18 \n    96 \n    70 \n    109.04391 \n  \n  \n    47 \n    101 \n    140 \n    183 \n    182.47442 \n  \n  \n    46 \n    149 \n    106 \n    189 \n    173.66693 \n  \n  \n    25 \n    121 \n    87 \n    83 \n    143.54644 \n  \n  \n    71 \n    136 \n    156 \n    171 \n    213.24494 \n  \n  \n    27 \n    114 \n    103 \n    169 \n    154.53040 \n  \n  \n    61 \n    106 \n    108 \n    110 \n    157.99341 \n  \n  \n    36 \n    108 \n    121 \n    113 \n    168.20918 \n  \n  \n    66 \n    104 \n    91 \n    124 \n    142.79439 \n  \n  \n    42 \n    27 \n    95 \n    129 \n    111.22351 \n  \n  \n    58 \n    116 \n    116 \n    174 \n    169.00364 \n  \n  \n    48 \n    72 \n    54 \n    165 \n    95.59458 \n  \n  \n    80 \n    143 \n    137 \n    247 \n    200.50023 \n  \n  \n    52 \n    133 \n    87 \n    159 \n    150.77458 \n  \n  \n    50 \n    37 \n    80 \n    41 \n    103.15936 \n  \n  \n    27 \n    128 \n    75 \n    127 \n    136.32932 \n  \n  \n    44 \n    116 \n    98 \n    187 \n    152.35701 \n  \n  \n    60 \n    101 \n    68 \n    100 \n    121.13371 \n  \n  \n    64 \n    97 \n    64 \n    150 \n    116.24995 \n  \n  \n    35 \n    120 \n    120 \n    189 \n    172.44290 \n  \n  \n    34 \n    94 \n    56 \n    68 \n    105.74986 \n  \n  \n    57 \n    116 \n    88 \n    134 \n    144.68854 \n  \n  \n    76 \n    163 \n    60 \n    100 \n    142.16437 \n  \n  \n    48 \n    17 \n    90 \n    70 \n    103.03841 \n  \n  \n    74 \n    39 \n    55 \n    104 \n    84.20453 \n  \n  \n    54 \n    46 \n    100 \n    125 \n    124.65866 \n  \n  \n    47 \n    70 \n    147 \n    168 \n    175.16434 \n  \n  \n    57 \n    111 \n    133 \n    166 \n    181.48777 \n  \n  \n    56 \n    89 \n    146 \n    210 \n    183.17732 \n  \n  \n    25 \n    73 \n    137 \n    137 \n    166.12881 \n  \n  \n    73 \n    26 \n    91 \n    79 \n    109.68631 \n  \n  \n    64 \n    63 \n    119 \n    105 \n    149.19871 \n  \n  \n    67 \n    64 \n    118 \n    135 \n    148.99240 \n  \n  \n    43 \n    117 \n    64 \n    140 \n    123.27911 \n  \n  \n    47 \n    123 \n    99 \n    154 \n    156.46977 \n  \n  \n    57 \n    107 \n    54 \n    118 \n    111.37381 \n  \n  \n    21 \n    44 \n    114 \n    144 \n    133.40676 \n  \n  \n    50 \n    71 \n    66 \n    163 \n    105.70352 \n  \n  \n    54 \n    116 \n    127 \n    144 \n    178.22203 \n  \n  \n    76 \n    137 \n    97 \n    139 \n    162.98116 \n  \n  \n    48 \n    42 \n    61 \n    109 \n    88.71579 \n  \n  \n    32 \n    97 \n    97 \n    142 \n    142.38459 \n  \n  \n    70 \n    57 \n    95 \n    116 \n    126.29081 \n  \n  \n    60 \n    123 \n    143 \n    206 \n    195.54808 \n  \n  \n    76 \n    122 \n    57 \n    164 \n    121.88463 \n  \n  \n    55 \n    87 \n    138 \n    171 \n    175.31327 \n  \n  \n    46 \n    89 \n    133 \n    183 \n    171.16320 \n  \n  \n    59 \n    129 \n    63 \n    93 \n    128.80527 \n  \n  \n    64 \n    90 \n    115 \n    123 \n    157.38069 \n  \n  \n    54 \n    106 \n    93 \n    118 \n    144.47601 \n  \n  \n    47 \n    106 \n    95 \n    164 \n    145.67519 \n  \n  \n    71 \n    109 \n    105 \n    148 \n    157.45049 \n  \n  \n    54 \n    86 \n    41 \n    125 \n    90.83488 \n  \n  \n    59 \n    42 \n    102 \n    156 \n    125.04501 \n  \n  \n    36 \n    111 \n    61 \n    73 \n    117.56217 \n  \n  \n    50 \n    120 \n    112 \n    180 \n    166.65784 \n  \n  \n    57 \n    65 \n    111 \n    89 \n    142.60365 \n  \n  \n    58 \n    99 \n    104 \n    188 \n    151.28361 \n  \n  \n    30 \n    73 \n    105 \n    110 \n    138.80714 \n  \n  \n    78 \n    120 \n    93 \n    185 \n    152.33864 \n  \n  \n    36 \n    93 \n    139 \n    157 \n    177.32217 \n  \n  \n    56 \n    112 \n    79 \n    128 \n    135.09624 \n  \n  \n    42 \n    111 \n    121 \n    172 \n    169.95920 \n  \n  \n    76 \n    83 \n    122 \n    147 \n    161.33378 \n  \n  \n    65 \n    71 \n    117 \n    171 \n    150.99366 \n  \n  \n    40 \n    118 \n    115 \n    97 \n    167.63206 \n  \n  \n    56 \n    59 \n    68 \n    105 \n    102.71562 \n  \n  \n    56 \n    103 \n    55 \n    105 \n    110.43832 \n  \n  \n    81 \n    100 \n    111 \n    153 \n    159.52327 \n  \n  \n    42 \n    105 \n    103 \n    157 \n    151.78922 \n  \n  \n    57 \n    124 \n    100 \n    174 \n    158.52699 \n  \n  \n    58 \n    52 \n    168 \n    133 \n    186.41680 \n  \n  \n    27 \n    65 \n    93 \n    143 \n    124.74060 \n  \n  \n    38 \n    95 \n    70 \n    81 \n    118.60478 \n  \n  \n    41 \n    98 \n    119 \n    155 \n    162.54510 \n  \n  \n    65 \n    107 \n    154 \n    196 \n    198.55014 \n  \n  \n    60 \n    75 \n    84 \n    129 \n    123.77119 \n  \n  \n    50 \n    136 \n    153 \n    229 \n    209.05134 \n  \n  \n    24 \n    114 \n    164 \n    286 \n    207.10887 \n  \n  \n    55 \n    83 \n    65 \n    106 \n    110.39340 \n  \n  \n    73 \n    135 \n    71 \n    115 \n    139.38280 \n  \n  \n    28 \n    111 \n    120 \n    230 \n    168.02915 \n  \n  \n    52 \n    105 \n    119 \n    167 \n    166.40038 \n  \n  \n    56 \n    95 \n    185 \n    237 \n    219.52660 \n  \n  \n    38 \n    114 \n    90 \n    107 \n    144.11283 \n  \n  \n    21 \n    84 \n    125 \n    154 \n    160.18067 \n  \n  \n    48 \n    92 \n    145 \n    172 \n    182.99728 \n  \n  \n    50 \n    39 \n    135 \n    171 \n    151.63440 \n  \n  \n    50 \n    52 \n    129 \n    115 \n    152.04702 \n  \n  \n    61 \n    60 \n    151 \n    146 \n    175.37858 \n  \n  \n    61 \n    123 \n    94 \n    162 \n    153.20573 \n  \n  \n    65 \n    126 \n    139 \n    198 \n    193.75934 \n  \n  \n    42 \n    117 \n    86 \n    123 \n    142.24807 \n  \n  \n    50 \n    106 \n    163 \n    224 \n    204.76959 \n  \n  \n    46 \n    49 \n    126 \n    132 \n    147.85201 \n  \n  \n    59 \n    61 \n    54 \n    135 \n    91.68673 \n  \n  \n    62 \n    90 \n    140 \n    201 \n    178.87067 \n  \n  \n    85 \n    156 \n    88 \n    102 \n    164.06869 \n  \n  \n    72 \n    131 \n    105 \n    152 \n    167.01479 \n  \n  \n    53 \n    132 \n    113 \n    203 \n    172.92703 \n  \n  \n    21 \n    116 \n    67 \n    102 \n    123.77229 \n  \n  \n    45 \n    44 \n    160 \n    144 \n    175.05272 \n  \n  \n    59 \n    95 \n    67 \n    101 \n    117.60429 \n  \n  \n    76 \n    91 \n    61 \n    86 \n    111.97751 \n  \n  \n    53 \n    110 \n    109 \n    179 \n    159.97603 \n  \n  \n    71 \n    46 \n    147 \n    74 \n    166.63812 \n  \n  \n    69 \n    110 \n    123 \n    138 \n    173.31198 \n  \n  \n    37 \n    101 \n    170 \n    222 \n    207.68459 \n  \n  \n    50 \n    132 \n    76 \n    124 \n    140.66875 \n  \n  \n    56 \n    83 \n    94 \n    97 \n    135.57418 \n  \n  \n    68 \n    100 \n    132 \n    181 \n    176.71423 \n  \n  \n    94 \n    120 \n    112 \n    141 \n    170.00300 \n  \n  \n    37 \n    90 \n    132 \n    154 \n    170.04457 \n  \n  \n    24 \n    99 \n    137 \n    185 \n    177.26620 \n  \n  \n    62 \n    68 \n    98 \n    135 \n    133.02378 \n  \n  \n    77 \n    124 \n    84 \n    161 \n    146.19662 \n  \n  \n    29 \n    70 \n    139 \n    185 \n    166.87042 \n  \n  \n    48 \n    84 \n    127 \n    182 \n    163.96474 \n  \n  \n    63 \n    124 \n    97 \n    127 \n    156.38611 \n  \n  \n    47 \n    136 \n    97 \n    104 \n    160.34511 \n  \n  \n    50 \n    70 \n    27 \n    170 \n    71.51067 \n  \n  \n    17 \n    97 \n    156 \n    226 \n    192.31939 \n  \n  \n    45 \n    92 \n    37 \n    128 \n    89.27563 \n  \n  \n    41 \n    65 \n    117 \n    177 \n    146.58132 \n  \n  \n    79 \n    108 \n    84 \n    152 \n    139.44811 \n  \n  \n    71 \n    84 \n    57 \n    140 \n    105.11565 \n  \n  \n    75 \n    30 \n    54 \n    170 \n    79.53330 \n  \n  \n    65 \n    74 \n    81 \n    116 \n    121.12299 \n  \n  \n    52 \n    97 \n    58 \n    118 \n    110.14355 \n  \n  \n    67 \n    72 \n    148 \n    181 \n    178.41312 \n  \n  \n    67 \n    38 \n    142 \n    135 \n    158.55532 \n  \n  \n    56 \n    88 \n    144 \n    141 \n    181.01467 \n  \n  \n    61 \n    123 \n    152 \n    221 \n    203.41524 \n  \n  \n    50 \n    110 \n    164 \n    206 \n    207.36041 \n  \n  \n    35 \n    81 \n    65 \n    90 \n    108.01030 \n  \n  \n    71 \n    89 \n    133 \n    167 \n    173.06385 \n  \n  \n    52 \n    82 \n    107 \n    111 \n    146.09265 \n  \n  \n    63 \n    106 \n    74 \n    160 \n    128.71230 \n  \n  \n    72 \n    97 \n    64 \n    135 \n    116.85816 \n  \n  \n    56 \n    128 \n    165 \n    206 \n    216.44539 \n  \n  \n    64 \n    68 \n    140 \n    214 \n    169.53445 \n  \n  \n    62 \n    85 \n    80 \n    99 \n    124.77337 \n  \n  \n    73 \n    114 \n    111 \n    182 \n    164.95305 \n  \n  \n    40 \n    121 \n    140 \n    216 \n    190.56794 \n  \n  \n    57 \n    144 \n    56 \n    127 \n    129.06273 \n  \n  \n    45 \n    85 \n    102 \n    78 \n    142.52591 \n  \n  \n    53 \n    25 \n    77 \n    128 \n    95.61497 \n  \n  \n    56 \n    65 \n    144 \n    124 \n    171.09510 \n  \n  \n    27 \n    100 \n    149 \n    196 \n    188.31374 \n  \n  \n    43 \n    50 \n    63 \n    121 \n    93.51730 \n  \n  \n    77 \n    80 \n    73 \n    166 \n    117.69757 \n  \n  \n    50 \n    61 \n    89 \n    127 \n    121.30134 \n  \n  \n    47 \n    102 \n    135 \n    225 \n    178.57730 \n  \n  \n    63 \n    85 \n    118 \n    164 \n    157.74528 \n  \n  \n    64 \n    161 \n    95 \n    164 \n    170.68833 \n  \n  \n    59 \n    65 \n    85 \n    119 \n    120.24799 \n  \n  \n    49 \n    118 \n    55 \n    42 \n    116.37542 \n  \n  \n    71 \n    73 \n    131 \n    126 \n    164.43192 \n  \n  \n    65 \n    106 \n    128 \n    146 \n    175.61114 \n  \n  \n    41 \n    131 \n    169 \n    237 \n    220.06158 \n  \n  \n    71 \n    73 \n    151 \n    190 \n    181.74555 \n  \n  \n    44 \n    134 \n    99 \n    120 \n    160.98583 \n  \n  \n    39 \n    56 \n    52 \n    95 \n    86.27842 \n  \n  \n    99 \n    87 \n    158 \n    238 \n    195.97205 \n  \n  \n    17 \n    106 \n    87 \n    134 \n    136.46895 \n  \n  \n    41 \n    62 \n    68 \n    126 \n    102.86908 \n  \n  \n    47 \n    119 \n    175 \n    231 \n    220.53640 \n  \n  \n    65 \n    103 \n    72 \n    93 \n    125.83914 \n  \n  \n    57 \n    94 \n    147 \n    234 \n    186.27545 \n  \n  \n    36 \n    66 \n    152 \n    201 \n    176.93132 \n  \n  \n    39 \n    103 \n    135 \n    159 \n    178.40037 \n  \n  \n    31 \n    123 \n    91 \n    167 \n    148.32790 \n  \n  \n    44 \n    78 \n    151 \n    137 \n    181.84927 \n  \n  \n    19 \n    98 \n    87 \n    154 \n    133.17072 \n  \n  \n    39 \n    119 \n    114 \n    157 \n    167.12163 \n  \n  \n    42 \n    116 \n    143 \n    271 \n    191.16061 \n  \n  \n    33 \n    128 \n    111 \n    179 \n    167.95000 \n  \n  \n    46 \n    126 \n    161 \n    271 \n    211.35983 \n  \n  \n    48 \n    125 \n    106 \n    154 \n    163.46813 \n  \n  \n    56 \n    83 \n    49 \n    162 \n    96.61853 \n  \n  \n    60 \n    73 \n    117 \n    162 \n    151.47610 \n  \n  \n    61 \n    100 \n    90 \n    151 \n    139.82344 \n  \n  \n    48 \n    109 \n    85 \n    164 \n    138.38826 \n  \n  \n    42 \n    96 \n    136 \n    160 \n    176.47513 \n  \n  \n    54 \n    92 \n    56 \n    66 \n    106.40781 \n  \n  \n    84 \n    98 \n    111 \n    182 \n    158.88878 \n  \n  \n    77 \n    126 \n    121 \n    195 \n    179.08940 \n  \n  \n    53 \n    62 \n    120 \n    141 \n    148.79682 \n  \n  \n    58 \n    98 \n    95 \n    132 \n    143.06119 \n  \n  \n    29 \n    65 \n    57 \n    109 \n    93.72813 \n  \n  \n    64 \n    82 \n    93 \n    114 \n    134.88542 \n  \n  \n    33 \n    78 \n    119 \n    97 \n    153.31118 \n  \n  \n    55 \n    108 \n    60 \n    109 \n    116.84713 \n  \n  \n    42 \n    102 \n    145 \n    206 \n    186.85398 \n  \n  \n    56 \n    140 \n    114 \n    178 \n    177.47107 \n  \n  \n    54 \n    90 \n    99 \n    105 \n    142.76953 \n  \n  \n    65 \n    84 \n    125 \n    160 \n    163.52582 \n  \n  \n    38 \n    73 \n    138 \n    170 \n    167.98283 \n  \n  \n    54 \n    92 \n    138 \n    155 \n    177.39367 \n  \n  \n    69 \n    133 \n    158 \n    228 \n    213.53039 \n  \n  \n    55 \n    92 \n    119 \n    152 \n    161.02175 \n  \n  \n    45 \n    97 \n    81 \n    191 \n    129.52203 \n  \n  \n    49 \n    139 \n    118 \n    201 \n    179.97033 \n  \n  \n    72 \n    79 \n    124 \n    146 \n    161.03589 \n  \n  \n    57 \n    88 \n    93 \n    91 \n    136.94095 \n  \n  \n    59 \n    45 \n    103 \n    122 \n    127.20454 \n  \n  \n    49 \n    109 \n    109 \n    226 \n    159.24064 \n  \n  \n    61 \n    119 \n    95 \n    158 \n    152.34627 \n  \n  \n    58 \n    120 \n    136 \n    184 \n    188.04240 \n  \n  \n    57 \n    105 \n    146 \n    210 \n    190.15391 \n  \n  \n    62 \n    114 \n    131 \n    227 \n    181.43039 \n  \n  \n    40 \n    85 \n    91 \n    109 \n    132.62329 \n  \n  \n    56 \n    86 \n    129 \n    200 \n    167.16688 \n  \n  \n    50 \n    120 \n    101 \n    152 \n    157.13535 \n  \n  \n    78 \n    133 \n    142 \n    209 \n    200.36373 \n  \n  \n    22 \n    52 \n    98 \n    152 \n    123.08217 \n  \n  \n    34 \n    65 \n    59 \n    66 \n    95.83962 \n  \n  \n    60 \n    125 \n    127 \n    230 \n    182.55975 \n  \n  \n    66 \n    77 \n    133 \n    138 \n    167.50830 \n  \n  \n    47 \n    81 \n    28 \n    77 \n    76.89241 \n  \n  \n    45 \n    111 \n    87 \n    185 \n    140.75411 \n  \n  \n    40 \n    109 \n    60 \n    57 \n    116.13802 \n  \n  \n    52 \n    97 \n    56 \n    132 \n    108.41218 \n  \n  \n    69 \n    71 \n    140 \n    167 \n    171.20843 \n  \n  \n    48 \n    107 \n    52 \n    123 \n    108.95821 \n  \n  \n    37 \n    117 \n    106 \n    167 \n    159.18156 \n  \n  \n    55 \n    73 \n    114 \n    152 \n    148.49892 \n  \n  \n    57 \n    42 \n    84 \n    124 \n    109.31069 \n  \n  \n    28 \n    101 \n    92 \n    144 \n    139.47722 \n  \n  \n    52 \n    23 \n    174 \n    153 \n    178.64745 \n  \n  \n    29 \n    110 \n    117 \n    110 \n    165.07685 \n  \n  \n    44 \n    115 \n    125 \n    161 \n    175.29912 \n  \n  \n    65 \n    87 \n    116 \n    148 \n    157.02854 \n  \n  \n    79 \n    87 \n    119 \n    138 \n    160.68996 \n  \n  \n    58 \n    104 \n    156 \n    159 \n    198.45546 \n  \n  \n    82 \n    97 \n    67 \n    111 \n    120.21546 \n  \n  \n    58 \n    110 \n    95 \n    123 \n    148.23662 \n  \n  \n    47 \n    92 \n    103 \n    190 \n    146.56264 \n  \n  \n    56 \n    81 \n    133 \n    182 \n    168.47318 \n  \n  \n    77 \n    103 \n    125 \n    179 \n    172.63256 \n  \n  \n    28 \n    109 \n    157 \n    239 \n    199.19678 \n  \n  \n    54 \n    92 \n    105 \n    139 \n    148.82619 \n  \n  \n    59 \n    81 \n    67 \n    114 \n    111.56629 \n  \n  \n    21 \n    110 \n    111 \n    132 \n    159.27455 \n  \n  \n    47 \n    26 \n    56 \n    129 \n    77.41079 \n  \n  \n    43 \n    8 \n    127 \n    82 \n    130.80692 \n  \n  \n    40 \n    92 \n    55 \n    111 \n    104.47776 \n  \n  \n    44 \n    92 \n    137 \n    105 \n    175.76773 \n  \n  \n    49 \n    108 \n    95 \n    129 \n    146.68981 \n  \n  \n    45 \n    56 \n    109 \n    132 \n    136.07840 \n  \n  \n    70 \n    134 \n    138 \n    191 \n    196.72408 \n  \n  \n    36 \n    57 \n    87 \n    105 \n    116.78047 \n  \n  \n    60 \n    103 \n    52 \n    94 \n    108.14538 \n  \n  \n    57 \n    65 \n    109 \n    175 \n    140.87229 \n  \n  \n    82 \n    40 \n    77 \n    85 \n    104.28901 \n  \n  \n    35 \n    105 \n    183 \n    229 \n    220.51154 \n  \n  \n    37 \n    48 \n    100 \n    107 \n    124.22878 \n  \n  \n    49 \n    113 \n    62 \n    59 \n    120.27876 \n  \n  \n    64 \n    87 \n    109 \n    162 \n    150.89275 \n  \n  \n    57 \n    96 \n    116 \n    114 \n    160.30190 \n  \n  \n    24 \n    115 \n    69 \n    62 \n    125.30044 \n  \n  \n    48 \n    99 \n    81 \n    163 \n    130.61268 \n  \n  \n    59 \n    89 \n    125 \n    174 \n    165.22609 \n  \n  \n    48 \n    102 \n    140 \n    145 \n    182.98173 \n  \n  \n    39 \n    79 \n    169 \n    173 \n    197.48268 \n  \n  \n    35 \n    19 \n    118 \n    96 \n    127.15171 \n  \n  \n    50 \n    77 \n    100 \n    108 \n    137.72440 \n  \n  \n    54 \n    136 \n    71 \n    167 \n    138.36959 \n  \n  \n    63 \n    108 \n    143 \n    187 \n    189.30688 \n  \n  \n    19 \n    82 \n    93 \n    150 \n    131.46424 \n  \n  \n    40 \n    117 \n    61 \n    134 \n    120.45398 \n  \n  \n    43 \n    83 \n    85 \n    128 \n    126.79471 \n  \n  \n    69 \n    93 \n    116 \n    172 \n    159.92036 \n  \n  \n    49 \n    32 \n    86 \n    149 \n    106.12099 \n  \n  \n    39 \n    84 \n    107 \n    94 \n    145.96688 \n  \n  \n    49 \n    127 \n    146 \n    238 \n    199.03398 \n  \n  \n    61 \n    133 \n    144 \n    279 \n    200.80264 \n  \n  \n    70 \n    57 \n    55 \n    85 \n    91.66356 \n  \n  \n    71 \n    84 \n    175 \n    219 \n    207.26604 \n  \n  \n    59 \n    143 \n    47 \n    81 \n    120.99236 \n  \n  \n    72 \n    102 \n    82 \n    143 \n    134.59685 \n  \n  \n    72 \n    128 \n    129 \n    180 \n    186.49729 \n  \n  \n    52 \n    46 \n    101 \n    147 \n    125.37228 \n  \n  \n    3 \n    52 \n    63 \n    128 \n    91.33883 \n  \n  \n    56 \n    171 \n    143 \n    220 \n    215.94567 \n  \n  \n    52 \n    130 \n    45 \n    48 \n    113.12211 \n  \n  \n    62 \n    132 \n    75 \n    109 \n    140.71538 \n  \n  \n    38 \n    94 \n    146 \n    146 \n    183.96527 \n  \n  \n    49 \n    63 \n    75 \n    118 \n    109.96835 \n  \n  \n    86 \n    89 \n    102 \n    171 \n    147.36813 \n  \n  \n    50 \n    107 \n    102 \n    167 \n    152.39432 \n  \n  \n    33 \n    68 \n    120 \n    126 \n    149.86401 \n  \n  \n    17 \n    80 \n    65 \n    79 \n    106.21055 \n  \n  \n    41 \n    98 \n    120 \n    147 \n    163.41078 \n  \n  \n    66 \n    141 \n    102 \n    178 \n    168.27444 \n  \n  \n    84 \n    101 \n    106 \n    110 \n    155.85423 \n  \n  \n    32 \n    82 \n    98 \n    134 \n    136.78099 \n  \n  \n    35 \n    102 \n    166 \n    220 \n    204.50110 \n  \n  \n    45 \n    65 \n    81 \n    137 \n    115.72090 \n  \n  \n    41 \n    132 \n    107 \n    188 \n    166.82063 \n  \n  \n    80 \n    100 \n    58 \n    128 \n    113.56614 \n  \n  \n    55 \n    103 \n    70 \n    91 \n    123.34751 \n  \n  \n    60 \n    105 \n    84 \n    151 \n    136.70975 \n  \n  \n    62 \n    76 \n    106 \n    123 \n    143.39951 \n  \n  \n    25 \n    106 \n    85 \n    100 \n    135.34580 \n  \n  \n    57 \n    71 \n    57 \n    83 \n    98.44458 \n  \n  \n    62 \n    104 \n    117 \n    212 \n    164.99800 \n  \n  \n    53 \n    187 \n    75 \n    108 \n    163.75184 \n  \n  \n    71 \n    95 \n    113 \n    151 \n    158.33794 \n  \n  \n    26 \n    107 \n    101 \n    184 \n    149.70401 \n  \n  \n    44 \n    99 \n    100 \n    106 \n    146.75652 \n  \n  \n    76 \n    76 \n    112 \n    193 \n    149.65797 \n  \n  \n    42 \n    106 \n    160 \n    177 \n    201.56434 \n  \n  \n    57 \n    129 \n    100 \n    172 \n    160.68342 \n  \n  \n    47 \n    94 \n    100 \n    153 \n    144.82817 \n  \n  \n    58 \n    82 \n    108 \n    106 \n    147.41448 \n  \n  \n    50 \n    51 \n    85 \n    173 \n    113.52576 \n  \n  \n    65 \n    110 \n    144 \n    164 \n    191.18718 \n  \n  \n    44 \n    136 \n    79 \n    145 \n    144.53477 \n  \n  \n    43 \n    103 \n    97 \n    132 \n    145.80859 \n  \n  \n    64 \n    123 \n    85 \n    126 \n    145.64267 \n  \n  \n    50 \n    167 \n    106 \n    177 \n    181.73417 \n  \n  \n    61 \n    60 \n    112 \n    106 \n    141.61701 \n  \n  \n    52 \n    108 \n    98 \n    174 \n    149.51494 \n  \n  \n    75 \n    44 \n    108 \n    130 \n    132.31808 \n  \n  \n    67 \n    123 \n    110 \n    226 \n    167.51278 \n  \n  \n    39 \n    53 \n    102 \n    129 \n    128.26862 \n  \n  \n    52 \n    102 \n    81 \n    156 \n    132.21064 \n  \n  \n    48 \n    91 \n    43 \n    86 \n    94.26651 \n  \n  \n    76 \n    97 \n    138 \n    154 \n    181.22267 \n  \n  \n    52 \n    65 \n    108 \n    169 \n    139.62648 \n  \n  \n    39 \n    134 \n    141 \n    195 \n    196.96431 \n  \n  \n    39 \n    104 \n    80 \n    106 \n    131.21919 \n  \n  \n    49 \n    104 \n    27 \n    53 \n    86.09835 \n  \n  \n    68 \n    90 \n    117 \n    135 \n    159.41616 \n  \n  \n    56 \n    138 \n    141 \n    256 \n    199.98189 \n  \n  \n    61 \n    76 \n    77 \n    110 \n    118.21873 \n  \n  \n    88 \n    85 \n    81 \n    123 \n    127.61573 \n  \n  \n    43 \n    96 \n    151 \n    198 \n    189.53638 \n  \n  \n    91 \n    103 \n    110 \n    159 \n    160.71170 \n  \n  \n    26 \n    74 \n    70 \n    124 \n    108.63548 \n  \n  \n    8 \n    31 \n    126 \n    110 \n    137.19988 \n  \n  \n    36 \n    79 \n    77 \n    116 \n    117.61193 \n  \n  \n    43 \n    57 \n    85 \n    126 \n    115.58129 \n  \n  \n    54 \n    78 \n    150 \n    220 \n    181.74385 \n  \n  \n    40 \n    70 \n    123 \n    171 \n    153.85581 \n  \n  \n    17 \n    71 \n    76 \n    110 \n    111.85147 \n  \n  \n    63 \n    63 \n    96 \n    89 \n    129.21202 \n  \n  \n    67 \n    79 \n    86 \n    182 \n    127.75988 \n  \n  \n    50 \n    85 \n    82 \n    169 \n    125.59242 \n  \n  \n    35 \n    139 \n    92 \n    183 \n    156.39825 \n  \n  \n    55 \n    96 \n    72 \n    157 \n    122.05988 \n  \n  \n    65 \n    50 \n    104 \n    129 \n    130.68281 \n  \n  \n    58 \n    96 \n    125 \n    171 \n    168.16906 \n  \n  \n    63 \n    89 \n    111 \n    198 \n    153.41066 \n  \n  \n    30 \n    118 \n    90 \n    125 \n    145.22976 \n  \n  \n    33 \n    160 \n    8 \n    8 \n    92.58597 \n  \n  \n    62 \n    53 \n    139 \n    163 \n    162.04743 \n  \n  \n    57 \n    133 \n    41 \n    76 \n    111.33337 \n  \n  \n    50 \n    105 \n    52 \n    107 \n    108.24769 \n  \n  \n    46 \n    113 \n    117 \n    154 \n    167.66315 \n  \n  \n    72 \n    97 \n    69 \n    114 \n    121.18656 \n  \n  \n    65 \n    123 \n    89 \n    207 \n    149.18143 \n  \n  \n    42 \n    164 \n    141 \n    295 \n    210.13095 \n  \n  \n    54 \n    87 \n    147 \n    192 \n    183.02837 \n  \n  \n    81 \n    64 \n    107 \n    159 \n    140.53427 \n  \n  \n    59 \n    120 \n    88 \n    149 \n    146.56573 \n  \n  \n    42 \n    99 \n    98 \n    156 \n    144.87310 \n  \n  \n    47 \n    78 \n    133 \n    163 \n    166.49509 \n  \n  \n    44 \n    51 \n    96 \n    135 \n    122.59210 \n  \n  \n    56 \n    60 \n    123 \n    153 \n    150.75937 \n  \n  \n    22 \n    96 \n    79 \n    76 \n    125.61078 \n  \n  \n    55 \n    63 \n    47 \n    106 \n    86.18543 \n  \n  \n    56 \n    98 \n    48 \n    115 \n    102.22212 \n  \n  \n    50 \n    102 \n    108 \n    135 \n    155.43198 \n  \n  \n    57 \n    112 \n    94 \n    142 \n    148.15748 \n  \n  \n    62 \n    146 \n    78 \n    153 \n    149.35042 \n  \n  \n    61 \n    80 \n    183 \n    189 \n    211.70608 \n  \n  \n    81 \n    89 \n    125 \n    157 \n    166.89867 \n  \n  \n    59 \n    116 \n    109 \n    165 \n    163.01990 \n  \n  \n    41 \n    112 \n    116 \n    147 \n    165.98605 \n  \n  \n    49 \n    97 \n    83 \n    122 \n    131.55750 \n  \n  \n    33 \n    59 \n    112 \n    111 \n    139.05699 \n  \n  \n    72 \n    142 \n    64 \n    96 \n    136.26600 \n  \n  \n    38 \n    128 \n    133 \n    167 \n    187.37512 \n  \n  \n    52 \n    162 \n    140 \n    269 \n    209.16296 \n  \n  \n    61 \n    100 \n    72 \n    134 \n    124.24118 \n  \n  \n    37 \n    133 \n    165 \n    267 \n    217.15732 \n  \n  \n    71 \n    127 \n    66 \n    85 \n    131.45206 \n  \n  \n    56 \n    117 \n    152 \n    265 \n    200.44739 \n  \n  \n    62 \n    97 \n    117 \n    157 \n    161.97900 \n  \n  \n    56 \n    81 \n    183 \n    194 \n    211.75724 \n  \n  \n    50 \n    67 \n    173 \n    154 \n    196.60627 \n  \n  \n    56 \n    129 \n    98 \n    105 \n    158.87603 \n  \n  \n    29 \n    137 \n    82 \n    146 \n    146.42271 \n  \n  \n    40 \n    41 \n    143 \n    151 \n    158.66215 \n  \n  \n    63 \n    69 \n    53 \n    109 \n    94.57544 \n  \n  \n    81 \n    57 \n    99 \n    120 \n    130.58982 \n  \n  \n    67 \n    156 \n    154 \n    232 \n    219.83518 \n  \n  \n    38 \n    145 \n    103 \n    148 \n    168.73653 \n  \n  \n    52 \n    85 \n    56 \n    173 \n    103.23676 \n  \n  \n    56 \n    78 \n    100 \n    124 \n    138.61184 \n  \n  \n    42 \n    74 \n    104 \n    164 \n    139.28506 \n  \n  \n    31 \n    85 \n    43 \n    88 \n    90.38635 \n  \n  \n    50 \n    73 \n    67 \n    102 \n    107.43178 \n  \n  \n    63 \n    123 \n    85 \n    164 \n    145.56665 \n  \n  \n    75 \n    177 \n    100 \n    151 \n    182.75359 \n  \n  \n    69 \n    53 \n    49 \n    130 \n    84.66830 \n  \n  \n    42 \n    91 \n    45 \n    90 \n    95.54172 \n  \n  \n    55 \n    73 \n    70 \n    172 \n    110.40895 \n  \n  \n    57 \n    95 \n    95 \n    151 \n    141.69131 \n  \n  \n    54 \n    84 \n    110 \n    125 \n    149.70431 \n  \n  \n    57 \n    122 \n    98 \n    202 \n    155.93306 \n  \n  \n    65 \n    106 \n    96 \n    95 \n    147.90934 \n  \n  \n    40 \n    27 \n    44 \n    80 \n    66.92172 \n  \n  \n    75 \n    85 \n    105 \n    113 \n    147.40374 \n  \n  \n    53 \n    114 \n    112 \n    176 \n    164.29821 \n  \n  \n    75 \n    49 \n    70 \n    139 \n    101.57863 \n  \n  \n    44 \n    117 \n    84 \n    144 \n    140.66876 \n  \n  \n    66 \n    71 \n    91 \n    135 \n    128.56197 \n  \n  \n    52 \n    92 \n    142 \n    188 \n    180.70434 \n  \n  \n    54 \n    48 \n    131 \n    165 \n    152.35734 \n  \n  \n    57 \n    54 \n    65 \n    86 \n    98.03817 \n  \n  \n    40 \n    80 \n    80 \n    162 \n    120.94437 \n  \n  \n    66 \n    147 \n    94 \n    120 \n    163.93671 \n  \n  \n    61 \n    68 \n    64 \n    159 \n    103.51459 \n  \n  \n    27 \n    113 \n    196 \n    193 \n    234.60747 \n  \n  \n    60 \n    102 \n    139 \n    114 \n    183.02836 \n  \n  \n    49 \n    62 \n    79 \n    63 \n    112.99979 \n  \n  \n    73 \n    100 \n    74 \n    140 \n    126.88485 \n  \n  \n    57 \n    48 \n    90 \n    175 \n    117.09249 \n  \n  \n    22 \n    116 \n    152 \n    235 \n    197.43122 \n  \n  \n    34 \n    83 \n    158 \n    230 \n    189.30520 \n  \n  \n    53 \n    72 \n    174 \n    202 \n    199.85646 \n  \n  \n    43 \n    96 \n    168 \n    201 \n    204.25296 \n  \n  \n    10 \n    97 \n    69 \n    94 \n    116.47294 \n  \n  \n    29 \n    76 \n    97 \n    126 \n    133.09952 \n  \n  \n    69 \n    101 \n    112 \n    145 \n    159.90792 \n  \n  \n    55 \n    97 \n    40 \n    24 \n    94.78936 \n  \n  \n    71 \n    112 \n    91 \n    150 \n    146.62481 \n  \n  \n    47 \n    78 \n    127 \n    210 \n    161.30100 \n  \n  \n    54 \n    105 \n    165 \n    245 \n    206.37377 \n  \n  \n    66 \n    60 \n    146 \n    208 \n    171.43030 \n  \n  \n    47 \n    65 \n    66 \n    151 \n    102.88773 \n  \n  \n    74 \n    98 \n    55 \n    155 \n    109.65036 \n  \n  \n    43 \n    110 \n    51 \n    79 \n    109.00625 \n  \n  \n    74 \n    78 \n    93 \n    170 \n    133.92054 \n  \n  \n    61 \n    60 \n    86 \n    142 \n    119.10930 \n  \n  \n    59 \n    130 \n    68 \n    124 \n    133.56496 \n  \n  \n    38 \n    99 \n    118 \n    155 \n    161.88262 \n  \n  \n    67 \n    126 \n    164 \n    287 \n    215.55343 \n  \n  \n    39 \n    85 \n    104 \n    67 \n    143.80112 \n  \n  \n    54 \n    133 \n    72 \n    114 \n    137.94141 \n  \n  \n    70 \n    59 \n    82 \n    137 \n    115.89952 \n  \n  \n    42 \n    96 \n    130 \n    154 \n    171.28105 \n  \n  \n    64 \n    22 \n    111 \n    110 \n    124.59056 \n  \n  \n    44 \n    106 \n    72 \n    116 \n    125.53644 \n  \n  \n    33 \n    85 \n    74 \n    108 \n    117.37452 \n  \n  \n    71 \n    91 \n    67 \n    96 \n    116.79146 \n  \n  \n    63 \n    24 \n    105 \n    152 \n    120.18302 \n  \n  \n    42 \n    132 \n    43 \n    113 \n    111.49305 \n  \n  \n    47 \n    104 \n    96 \n    151 \n    145.67830 \n  \n  \n    59 \n    85 \n    132 \n    191 \n    169.56072 \n  \n  \n    50 \n    45 \n    122 \n    110 \n    142.96825 \n  \n  \n    71 \n    118 \n    149 \n    235 \n    199.42203 \n  \n  \n    46 \n    85 \n    144 \n    193 \n    178.96055 \n  \n  \n    53 \n    106 \n    134 \n    140 \n    179.89291 \n  \n  \n    68 \n    75 \n    88 \n    150 \n    127.84212 \n  \n  \n    42 \n    75 \n    137 \n    141 \n    168.28382 \n  \n  \n    61 \n    100 \n    125 \n    176 \n    170.12228 \n  \n  \n    96 \n    124 \n    115 \n    182 \n    174.47724 \n  \n  \n    73 \n    110 \n    164 \n    247 \n    209.10902 \n  \n  \n    69 \n    74 \n    115 \n    144 \n    150.86026 \n  \n  \n    64 \n    69 \n    58 \n    102 \n    98.97987 \n  \n  \n    64 \n    116 \n    113 \n    116 \n    166.86275 \n  \n  \n    40 \n    79 \n    105 \n    112 \n    142.15511 \n  \n  \n    55 \n    131 \n    96 \n    146 \n    157.93122 \n  \n  \n    62 \n    100 \n    83 \n    137 \n    133.83970 \n  \n  \n    37 \n    86 \n    157 \n    192 \n    189.96146 \n  \n  \n    36 \n    120 \n    130 \n    161 \n    181.17574 \n  \n  \n    36 \n    60 \n    86 \n    104 \n    117.20864 \n  \n  \n    57 \n    53 \n    101 \n    147 \n    128.77141 \n  \n  \n    18 \n    103 \n    33 \n    128 \n    88.50434 \n  \n  \n    72 \n    73 \n    103 \n    133 \n    140.26888 \n  \n  \n    11 \n    19 \n    104 \n    79 \n    113.20755 \n  \n  \n    58 \n    123 \n    101 \n    174 \n    159.03742 \n  \n  \n    68 \n    83 \n    44 \n    108 \n    93.20243 \n  \n  \n    43 \n    74 \n    180 \n    193 \n    205.15286 \n  \n  \n    10 \n    159 \n    84 \n    179 \n    156.19785 \n  \n  \n    39 \n    95 \n    41 \n    59 \n    93.57605 \n  \n  \n    32 \n    96 \n    109 \n    108 \n    152.34148 \n  \n  \n    41 \n    84 \n    132 \n    138 \n    167.76096 \n  \n  \n    47 \n    43 \n    87 \n    158 \n    111.57876 \n  \n  \n    32 \n    104 \n    110 \n    147 \n    156.65744 \n  \n  \n    34 \n    84 \n    146 \n    133 \n    179.34831 \n  \n  \n    53 \n    110 \n    59 \n    65 \n    116.69196 \n  \n  \n    61 \n    68 \n    103 \n    149 \n    137.27616 \n  \n  \n    46 \n    82 \n    99 \n    156 \n    138.71104 \n  \n  \n    42 \n    72 \n    67 \n    89 \n    106.39228 \n  \n  \n    58 \n    152 \n    104 \n    199 \n    174.14174 \n  \n  \n    79 \n    70 \n    100 \n    144 \n    136.91016 \n  \n  \n    58 \n    56 \n    102 \n    146 \n    131.00698 \n  \n  \n    60 \n    78 \n    122 \n    137 \n    157.96093 \n  \n  \n    72 \n    106 \n    91 \n    134 \n    144.11312 \n  \n  \n    63 \n    85 \n    109 \n    170 \n    149.95415 \n  \n  \n    69 \n    33 \n    74 \n    147 \n    97.68463 \n  \n  \n    32 \n    21 \n    67 \n    142 \n    83.63646 \n  \n  \n    50 \n    87 \n    98 \n    199 \n    140.30589 \n  \n  \n    43 \n    104 \n    141 \n    230 \n    184.32985 \n  \n  \n    30 \n    92 \n    52 \n    87 \n    101.12046 \n  \n  \n    58 \n    84 \n    166 \n    186 \n    198.48657 \n  \n  \n    84 \n    86 \n    97 \n    171 \n    141.59381 \n  \n  \n    58 \n    70 \n    85 \n    114 \n    122.32839 \n  \n  \n    55 \n    53 \n    106 \n    136 \n    132.94777 \n  \n  \n    58 \n    83 \n    156 \n    155 \n    189.39847 \n  \n  \n    83 \n    109 \n    146 \n    172 \n    193.85573 \n  \n  \n    44 \n    103 \n    91 \n    167 \n    140.69053 \n  \n  \n    54 \n    51 \n    102 \n    117 \n    128.54644 \n  \n  \n    47 \n    81 \n    82 \n    123 \n    123.63920 \n  \n  \n    40 \n    103 \n    130 \n    189 \n    174.14799 \n  \n  \n    42 \n    82 \n    27 \n    64 \n    76.07789 \n  \n  \n    30 \n    160 \n    66 \n    155 \n    142.56740 \n  \n  \n    54 \n    139 \n    74 \n    110 \n    142.26049 \n  \n  \n    50 \n    111 \n    44 \n    35 \n    103.90995 \n  \n  \n    69 \n    143 \n    84 \n    178 \n    153.78283 \n  \n  \n    59 \n    109 \n    137 \n    184 \n    184.23997 \n  \n  \n    66 \n    72 \n    138 \n    140 \n    169.68028 \n  \n  \n    40 \n    119 \n    110 \n    178 \n    163.73493 \n  \n  \n    53 \n    52 \n    130 \n    146 \n    153.14078 \n  \n  \n    41 \n    103 \n    177 \n    248 \n    214.91104 \n  \n  \n    37 \n    121 \n    162 \n    222 \n    209.38485 \n  \n  \n    42 \n    60 \n    167 \n    178 \n    187.78498 \n  \n  \n    65 \n    108 \n    144 \n    224 \n    190.32461 \n  \n  \n    50 \n    119 \n    155 \n    204 \n    203.45085 \n  \n  \n    72 \n    76 \n    92 \n    151 \n    132.04024 \n  \n  \n    43 \n    67 \n    117 \n    118 \n    147.59594 \n  \n  \n    45 \n    130 \n    157 \n    276 \n    209.54622 \n  \n  \n    53 \n    73 \n    119 \n    132 \n    152.67528 \n  \n  \n    80 \n    97 \n    101 \n    73 \n    149.49657 \n  \n  \n    43 \n    89 \n    74 \n    113 \n    119.85993 \n  \n  \n    29 \n    79 \n    125 \n    135 \n    158.63245 \n  \n  \n    44 \n    88 \n    160 \n    170 \n    193.95325 \n  \n  \n    70 \n    139 \n    90 \n    141 \n    157.32780 \n  \n  \n    45 \n    54 \n    39 \n    127 \n    74.61815 \n  \n  \n    49 \n    96 \n    93 \n    143 \n    139.78303 \n  \n  \n    55 \n    114 \n    94 \n    140 \n    148.86800 \n  \n  \n    39 \n    95 \n    130 \n    232 \n    170.62168 \n  \n  \n    36 \n    101 \n    135 \n    183 \n    177.30972 \n  \n  \n    59 \n    58 \n    113 \n    154 \n    141.46807 \n  \n  \n    44 \n    146 \n    98 \n    137 \n    165.29557 \n  \n  \n    41 \n    45 \n    56 \n    102 \n    85.14906 \n  \n  \n    39 \n    123 \n    145 \n    180 \n    195.68289 \n  \n  \n    54 \n    74 \n    51 \n    103 \n    94.31627 \n  \n  \n    73 \n    119 \n    119 \n    224 \n    174.03493 \n  \n  \n    47 \n    88 \n    43 \n    114 \n    92.89663 \n  \n  \n    52 \n    85 \n    80 \n    113 \n    124.01311 \n  \n  \n    61 \n    47 \n    158 \n    137 \n    175.83164 \n  \n  \n    56 \n    70 \n    61 \n    127 \n    101.39999 \n  \n  \n    70 \n    79 \n    108 \n    106 \n    147.03294 \n  \n  \n    28 \n    108 \n    92 \n    170 \n    142.49622 \n  \n  \n    47 \n    54 \n    71 \n    90 \n    102.47200 \n  \n  \n    66 \n    97 \n    115 \n    145 \n    160.55174 \n  \n  \n    29 \n    105 \n    106 \n    153 \n    153.39793 \n  \n  \n    70 \n    130 \n    120 \n    186 \n    179.41667 \n  \n  \n    71 \n    93 \n    118 \n    111 \n    161.80378 \n  \n  \n    42 \n    111 \n    142 \n    202 \n    188.13850 \n  \n  \n    38 \n    130 \n    113 \n    158 \n    170.92407 \n  \n  \n    50 \n    116 \n    131 \n    183 \n    181.38065 \n  \n  \n    49 \n    106 \n    138 \n    202 \n    183.05153 \n  \n  \n    58 \n    100 \n    55 \n    117 \n    109.29652 \n  \n  \n    37 \n    105 \n    167 \n    206 \n    206.81269 \n  \n  \n    54 \n    16 \n    95 \n    138 \n    107.39169 \n  \n  \n    64 \n    123 \n    90 \n    198 \n    149.97108 \n  \n  \n    44 \n    109 \n    59 \n    68 \n    115.57644 \n  \n  \n    30 \n    85 \n    98 \n    155 \n    137.92279 \n  \n  \n    67 \n    79 \n    68 \n    134 \n    112.17762 \n  \n  \n    52 \n    124 \n    104 \n    193 \n    161.60959 \n  \n  \n    50 \n    114 \n    65 \n    102 \n    123.38311 \n  \n  \n    58 \n    46 \n    74 \n    121 \n    102.45505 \n  \n  \n    38 \n    71 \n    85 \n    192 \n    121.23915 \n  \n  \n    28 \n    137 \n    84 \n    215 \n    148.07805 \n  \n  \n    59 \n    74 \n    62 \n    162 \n    104.21889 \n  \n  \n    58 \n    113 \n    40 \n    89 \n    101.91801 \n  \n  \n    79 \n    94 \n    51 \n    166 \n    104.84263 \n  \n  \n    57 \n    125 \n    101 \n    156 \n    159.82396 \n  \n  \n    99 \n    76 \n    105 \n    110 \n    145.34680 \n  \n  \n    59 \n    110 \n    137 \n    218 \n    184.67126 \n  \n  \n    34 \n    38 \n    135 \n    118 \n    149.98669 \n  \n  \n    54 \n    76 \n    177 \n    205 \n    204.25467 \n  \n  \n    61 \n    132 \n    60 \n    140 \n    127.65413 \n  \n  \n    48 \n    60 \n    106 \n    152 \n    135.43458 \n  \n  \n    63 \n    146 \n    123 \n    186 \n    188.38210 \n  \n  \n    53 \n    125 \n    45 \n    96 \n    111.04171 \n  \n  \n    41 \n    147 \n    96 \n    98 \n    163.76741 \n  \n  \n    23 \n    78 \n    66 \n    124 \n    106.66981 \n  \n  \n    40 \n    107 \n    144 \n    155 \n    187.99267 \n  \n  \n    30 \n    52 \n    152 \n    161 \n    170.43716 \n  \n  \n    53 \n    124 \n    69 \n    110 \n    131.38677 \n  \n  \n    58 \n    137 \n    137 \n    211 \n    196.23994 \n  \n  \n    69 \n    68 \n    127 \n    184 \n    158.66072 \n  \n  \n    32 \n    65 \n    84 \n    147 \n    117.32960 \n  \n  \n    74 \n    104 \n    60 \n    104 \n    116.56648 \n  \n  \n    58 \n    69 \n    55 \n    131 \n    95.92667 \n  \n  \n    75 \n    124 \n    152 \n    208 \n    204.91089 \n  \n  \n    14 \n    59 \n    159 \n    174 \n    178.29951 \n  \n  \n    49 \n    108 \n    123 \n    178 \n    170.92889 \n  \n  \n    52 \n    55 \n    145 \n    149 \n    167.34383 \n  \n  \n    52 \n    71 \n    79 \n    106 \n    117.10943 \n  \n  \n    53 \n    124 \n    110 \n    150 \n    166.87970 \n  \n  \n    61 \n    100 \n    131 \n    170 \n    175.31637 \n  \n  \n    38 \n    154 \n    79 \n    115 \n    151.84175 \n  \n  \n    62 \n    84 \n    91 \n    116 \n    133.86458 \n  \n  \n    45 \n    109 \n    96 \n    151 \n    147.68267 \n  \n  \n    21 \n    123 \n    132 \n    192 \n    183.06057 \n  \n  \n    37 \n    90 \n    97 \n    110 \n    139.74572 \n  \n  \n    75 \n    121 \n    138 \n    171 \n    191.49750 \n  \n  \n    52 \n    62 \n    130 \n    130 \n    157.37761 \n  \n  \n    31 \n    163 \n    138 \n    235 \n    206.26633 \n  \n  \n    55 \n    97 \n    116 \n    101 \n    160.58114 \n  \n  \n    47 \n    85 \n    155 \n    201 \n    188.55907 \n  \n  \n    57 \n    110 \n    103 \n    149 \n    155.08604 \n  \n  \n    61 \n    100 \n    111 \n    187 \n    158.00274 \n  \n  \n    50 \n    94 \n    128 \n    120 \n    169.29532 \n  \n  \n    40 \n    104 \n    79 \n    110 \n    130.42954 \n  \n  \n    71 \n    57 \n    85 \n    111 \n    117.71002 \n  \n  \n    50 \n    119 \n    48 \n    82 \n    110.82296 \n  \n  \n    54 \n    78 \n    74 \n    99 \n    115.95208 \n  \n  \n    36 \n    112 \n    77 \n    118 \n    131.84435 \n  \n  \n    32 \n    117 \n    108 \n    191 \n    160.53279 \n  \n  \n    61 \n    75 \n    123 \n    145 \n    157.60878 \n  \n  \n    38 \n    55 \n    112 \n    136 \n    137.71198 \n  \n  \n    58 \n    90 \n    173 \n    243 \n    207.13405 \n  \n  \n    31 \n    93 \n    63 \n    152 \n    111.15026 \n  \n  \n    60 \n    117 \n    75 \n    120 \n    134.09404 \n  \n  \n    34 \n    95 \n    155 \n    190 \n    191.88358 \n  \n  \n    44 \n    112 \n    90 \n    206 \n    143.70642 \n  \n  \n    63 \n    102 \n    138 \n    198 \n    182.39076 \n  \n  \n    59 \n    46 \n    98 \n    139 \n    123.30742 \n  \n  \n    35 \n    96 \n    89 \n    113 \n    135.25593 \n  \n  \n    60 \n    96 \n    115 \n    114 \n    159.66430 \n  \n  \n    53 \n    89 \n    94 \n    108 \n    137.93381 \n  \n  \n    57 \n    144 \n    79 \n    163 \n    148.97340 \n  \n  \n    39 \n    46 \n    103 \n    145 \n    126.11531 \n  \n  \n    43 \n    75 \n    54 \n    109 \n    96.50831 \n  \n  \n    46 \n    109 \n    67 \n    121 \n    122.65395 \n  \n  \n    33 \n    118 \n    108 \n    114 \n    161.04010 \n  \n  \n    35 \n    62 \n    161 \n    173 \n    182.92128 \n  \n  \n    56 \n    57 \n    84 \n    186 \n    115.70395 \n  \n  \n    65 \n    87 \n    78 \n    134 \n    124.13266 \n  \n  \n    49 \n    36 \n    112 \n    143 \n    130.35385 \n  \n  \n    38 \n    84 \n    63 \n    141 \n    107.80088 \n  \n  \n    46 \n    58 \n    77 \n    99 \n    109.31520 \n  \n  \n    75 \n    69 \n    116 \n    141 \n    150.02567 \n  \n  \n    43 \n    138 \n    102 \n    167 \n    165.23199 \n  \n  \n    90 \n    97 \n    52 \n    122 \n    107.83846 \n  \n  \n    60 \n    112 \n    164 \n    243 \n    208.98325 \n  \n  \n    32 \n    124 \n    140 \n    213 \n    191.25359 \n  \n  \n    71 \n    83 \n    89 \n    162 \n    132.38617 \n  \n  \n    57 \n    121 \n    72 \n    124 \n    132.99406 \n  \n  \n    58 \n    139 \n    53 \n    86 \n    124.38528 \n  \n  \n    66 \n    118 \n    139 \n    174 \n    190.38509 \n  \n  \n    53 \n    81 \n    133 \n    151 \n    168.24510 \n  \n  \n    64 \n    42 \n    124 \n    111 \n    144.47013 \n  \n  \n    59 \n    110 \n    139 \n    179 \n    186.40262 \n  \n  \n    62 \n    132 \n    136 \n    242 \n    193.52193 \n  \n  \n    49 \n    111 \n    154 \n    218 \n    199.05886 \n  \n  \n    70 \n    60 \n    166 \n    165 \n    189.04803 \n  \n  \n    56 \n    124 \n    108 \n    148 \n    165.37642 \n  \n  \n    45 \n    134 \n    176 \n    287 \n    227.71931 \n  \n  \n    69 \n    87 \n    144 \n    182 \n    181.57172 \n  \n  \n    56 \n    105 \n    151 \n    164 \n    194.40629 \n  \n  \n    68 \n    42 \n    89 \n    128 \n    114.47539 \n  \n  \n    68 \n    97 \n    76 \n    111 \n    126.94223 \n  \n  \n    44 \n    123 \n    119 \n    212 \n    173.55531 \n  \n  \n    33 \n    87 \n    138 \n    208 \n    173.64069 \n  \n  \n    66 \n    81 \n    37 \n    119 \n    86.12804 \n  \n  \n    44 \n    149 \n    89 \n    154 \n    158.79830 \n  \n  \n    68 \n    116 \n    104 \n    131 \n    159.37572 \n  \n  \n    56 \n    77 \n    73 \n    89 \n    114.80716 \n  \n  \n    8 \n    101 \n    79 \n    138 \n    126.70284 \n  \n  \n    74 \n    100 \n    81 \n    126 \n    133.02065 \n  \n  \n    47 \n    107 \n    78 \n    129 \n    131.38989 \n  \n  \n    29 \n    66 \n    29 \n    83 \n    69.92034 \n  \n  \n    68 \n    96 \n    84 \n    108 \n    133.43639 \n  \n  \n    46 \n    100 \n    63 \n    100 \n    115.30965 \n  \n  \n    49 \n    103 \n    130 \n    150 \n    174.83223 \n  \n  \n    43 \n    77 \n    77 \n    106 \n    117.28155 \n  \n  \n    68 \n    149 \n    152 \n    190 \n    215.16084 \n  \n  \n    64 \n    6 \n    108 \n    67 \n    115.09295 \n  \n  \n    49 \n    57 \n    88 \n    140 \n    118.63449 \n  \n  \n    72 \n    125 \n    88 \n    155 \n    149.71050 \n  \n  \n    56 \n    48 \n    69 \n    119 \n    98.83716 \n  \n  \n    39 \n    59 \n    110 \n    173 \n    137.78178 \n  \n  \n    48 \n    94 \n    114 \n    189 \n    157.02373 \n  \n  \n    70 \n    92 \n    141 \n    203 \n    181.20713 \n  \n  \n    46 \n    90 \n    105 \n    170 \n    147.35541 \n  \n  \n    57 \n    65 \n    103 \n    151 \n    135.67820 \n  \n  \n    62 \n    92 \n    120 \n    169 \n    162.41962 \n  \n  \n    62 \n    64 \n    88 \n    129 \n    122.64183 \n  \n  \n    55 \n    64 \n    139 \n    94 \n    166.25939 \n  \n  \n    45 \n    132 \n    105 \n    205 \n    165.39337 \n  \n  \n    37 \n    125 \n    118 \n    165 \n    173.02002 \n  \n  \n    46 \n    39 \n    125 \n    132 \n    142.67348 \n  \n  \n    31 \n    75 \n    80 \n    88 \n    118.10370 \n  \n  \n    61 \n    59 \n    89 \n    142 \n    121.27506 \n  \n  \n    43 \n    18 \n    152 \n    98 \n    156.76180 \n  \n  \n    67 \n    110 \n    41 \n    98 \n    102.17407 \n  \n  \n    54 \n    83 \n    67 \n    69 \n    112.04873 \n  \n  \n    17 \n    126 \n    106 \n    112 \n    161.54260 \n  \n  \n    64 \n    46 \n    124 \n    162 \n    146.19527 \n  \n  \n    49 \n    92 \n    109 \n    154 \n    151.90878 \n  \n  \n    47 \n    55 \n    66 \n    153 \n    98.57488 \n  \n  \n    61 \n    75 \n    113 \n    159 \n    148.95197 \n  \n  \n    27 \n    114 \n    88 \n    116 \n    141.54518 \n  \n  \n    52 \n    79 \n    107 \n    118 \n    144.79879 \n  \n  \n    22 \n    96 \n    91 \n    138 \n    135.99896 \n  \n  \n    66 \n    137 \n    164 \n    257 \n    220.22154 \n  \n  \n    31 \n    122 \n    113 \n    170 \n    166.94160 \n  \n  \n    42 \n    53 \n    151 \n    135 \n    170.91508 \n  \n  \n    57 \n    86 \n    91 \n    128 \n    134.34702 \n  \n  \n    60 \n    41 \n    120 \n    128 \n    140.27201 \n  \n  \n    50 \n    61 \n    121 \n    192 \n    149.00314 \n  \n  \n    68 \n    137 \n    119 \n    175 \n    181.41794 \n  \n  \n    58 \n    70 \n    159 \n    159 \n    186.38880 \n  \n  \n    39 \n    64 \n    78 \n    134 \n    112.23641 \n  \n  \n    58 \n    84 \n    95 \n    142 \n    137.02320 \n  \n  \n    72 \n    124 \n    89 \n    136 \n    150.14489 \n  \n  \n    40 \n    104 \n    106 \n    225 \n    153.80293 \n  \n  \n    43 \n    43 \n    113 \n    148 \n    133.78237 \n  \n  \n    66 \n    93 \n    136 \n    178 \n    177.00591 \n  \n  \n    53 \n    59 \n    62 \n    87 \n    97.29345 \n  \n  \n    49 \n    124 \n    123 \n    161 \n    177.82945 \n  \n  \n    70 \n    65 \n    71 \n    101 \n    108.96474 \n  \n  \n    50 \n    83 \n    104 \n    141 \n    143.77484 \n  \n  \n    59 \n    47 \n    82 \n    141 \n    109.88781 \n  \n  \n    54 \n    99 \n    89 \n    125 \n    137.99429 \n  \n  \n    52 \n    80 \n    165 \n    136 \n    195.43959 \n  \n  \n    42 \n    86 \n    91 \n    148 \n    133.20663 \n  \n  \n    58 \n    115 \n    112 \n    147 \n    165.10963 \n  \n  \n    44 \n    78 \n    55 \n    119 \n    98.74387 \n  \n  \n    80 \n    89 \n    51 \n    85 \n    102.76223 \n  \n  \n    62 \n    103 \n    139 \n    220 \n    183.61170 \n  \n  \n    50 \n    139 \n    198 \n    286 \n    249.30085 \n  \n  \n    50 \n    106 \n    133 \n    192 \n    178.79915 \n  \n  \n    50 \n    141 \n    79 \n    127 \n    147.14736 \n  \n  \n    52 \n    75 \n    37 \n    56 \n    82.47596 \n  \n  \n    63 \n    80 \n    171 \n    176 \n    201.46996 \n  \n  \n    66 \n    45 \n    130 \n    139 \n    151.11012 \n  \n  \n    50 \n    104 \n    83 \n    141 \n    134.65252 \n  \n  \n    58 \n    94 \n    39 \n    50 \n    92.85790 \n  \n  \n    53 \n    50 \n    96 \n    169 \n    122.84505 \n  \n  \n    45 \n    94 \n    94 \n    115 \n    139.48203 \n  \n  \n    35 \n    137 \n    120 \n    183 \n    179.77475 \n  \n  \n    43 \n    100 \n    128 \n    174 \n    171.35085 \n  \n  \n    38 \n    101 \n    131 \n    238 \n    173.99905 \n  \n  \n    44 \n    158 \n    147 \n    193 \n    212.88938 \n  \n  \n    56 \n    90 \n    79 \n    81 \n    125.60796 \n  \n  \n    37 \n    46 \n    163 \n    130 \n    177.90413 \n  \n  \n    47 \n    97 \n    122 \n    167 \n    165.16701 \n  \n  \n    70 \n    102 \n    119 \n    150 \n    166.47500 \n  \n  \n    50 \n    92 \n    66 \n    59 \n    114.76052 \n  \n  \n    45 \n    116 \n    79 \n    130 \n    135.98509 \n  \n  \n    53 \n    21 \n    93 \n    130 \n    107.74073 \n  \n  \n    41 \n    75 \n    137 \n    203 \n    168.20780 \n  \n  \n    49 \n    110 \n    164 \n    182 \n    207.28439 \n  \n  \n    64 \n    60 \n    97 \n    111 \n    128.85987 \n  \n  \n    67 \n    129 \n    114 \n    183 \n    173.56322 \n  \n  \n    72 \n    46 \n    99 \n    178 \n    125.16145 \n  \n  \n    67 \n    96 \n    37 \n    86 \n    92.67335 \n  \n  \n    47 \n    78 \n    128 \n    158 \n    162.16668 \n  \n  \n    47 \n    177 \n    130 \n    244 \n    206.59530 \n  \n  \n    54 \n    89 \n    151 \n    172 \n    187.35367 \n  \n  \n    56 \n    64 \n    137 \n    125 \n    164.60405 \n  \n  \n    34 \n    123 \n    104 \n    134 \n    159.80983 \n  \n  \n    57 \n    81 \n    87 \n    98 \n    128.72787 \n  \n  \n    59 \n    134 \n    107 \n    169 \n    169.05167 \n  \n  \n    75 \n    33 \n    110 \n    118 \n    129.30531 \n  \n  \n    28 \n    114 \n    56 \n    83 \n    113.91941 \n  \n  \n    31 \n    31 \n    100 \n    122 \n    116.44077 \n  \n  \n    55 \n    108 \n    95 \n    181 \n    147.14597 \n  \n  \n    41 \n    31 \n    99 \n    124 \n    116.33535 \n  \n  \n    48 \n    106 \n    156 \n    215 \n    198.55777 \n  \n  \n    40 \n    36 \n    119 \n    109 \n    135.72938 \n  \n  \n    21 \n    118 \n    110 \n    175 \n    161.85915 \n  \n  \n    38 \n    147 \n    102 \n    136 \n    168.73342 \n  \n  \n    34 \n    122 \n    111 \n    183 \n    165.43831 \n  \n  \n    62 \n    94 \n    62 \n    150 \n    113.07268 \n  \n  \n    71 \n    81 \n    137 \n    213 \n    173.07630 \n  \n  \n    78 \n    89 \n    45 \n    28 \n    97.41609 \n  \n  \n    36 \n    93 \n    123 \n    207 \n    163.47127 \n  \n  \n    31 \n    123 \n    108 \n    176 \n    163.04448 \n  \n  \n    84 \n    136 \n    115 \n    199 \n    178.74035 \n  \n  \n    34 \n    119 \n    108 \n    166 \n    161.54741 \n  \n  \n    41 \n    80 \n    68 \n    142 \n    110.63222 \n  \n  \n    45 \n    86 \n    151 \n    125 \n    185.37558 \n  \n  \n    46 \n    94 \n    112 \n    171 \n    155.14032 \n  \n  \n    55 \n    58 \n    44 \n    92 \n    81.43196 \n  \n  \n    64 \n    115 \n    61 \n    97 \n    121.41604 \n  \n  \n    48 \n    98 \n    125 \n    154 \n    168.27137 \n  \n  \n    54 \n    80 \n    74 \n    136 \n    116.81465 \n  \n  \n    66 \n    81 \n    125 \n    99 \n    162.30799 \n  \n  \n    56 \n    44 \n    105 \n    110 \n    128.27654 \n  \n  \n    46 \n    110 \n    135 \n    223 \n    181.95155 \n  \n  \n    49 \n    56 \n    74 \n    72 \n    106.08367 \n  \n  \n    66 \n    188 \n    119 \n    260 \n    203.26144 \n  \n  \n    41 \n    89 \n    79 \n    123 \n    124.03628 \n  \n  \n    50 \n    75 \n    159 \n    154 \n    187.93702 \n  \n  \n    64 \n    139 \n    92 \n    165 \n    158.60301 \n  \n  \n    46 \n    55 \n    47 \n    150 \n    82.05091 \n  \n  \n    49 \n    129 \n    109 \n    166 \n    167.86634 \n  \n  \n    78 \n    68 \n    166 \n    176 \n    193.10652 \n  \n  \n    44 \n    61 \n    116 \n    155 \n    144.21857 \n  \n  \n    80 \n    97 \n    121 \n    148 \n    166.81020 \n  \n  \n    37 \n    79 \n    120 \n    178 \n    154.91225 \n  \n  \n    58 \n    135 \n    125 \n    172 \n    184.98919 \n  \n\n\n\n\n\n\n\n\nSuppose we have a student with a 55 on Yr1, a 95 on Yr2 and a 110 on Yr3.\nFirst, what would their data look like?\n\nHypothetical.Student <- data.frame(Yr1=55, Yr2=95, Yr3=110)\nHypothetical.Student\n\n  Yr1 Yr2 Yr3\n1  55  95 110\n\n\nLet’s predict, first the single best guess – the fitted value.\nThe equation we sought estimates for was:\n\nlibrary(equatiomatic)\nequatiomatic::extract_eq(my.lm)\n\n\\[\n\\operatorname{Final} = \\alpha + \\beta_{1}(\\operatorname{Yr1}) + \\beta_{2}(\\operatorname{Yr2}) + \\beta_{3}(\\operatorname{Yr3}) + \\epsilon\n\\]\n\n\nAnd it was estimated to be\n\nequatiomatic::extract_eq(my.lm, use_coefs = TRUE, coef_digits = 4)\n\n\\[\n\\operatorname{\\widehat{Final}} = 14.146 + 0.076(\\operatorname{Yr1}) + 0.4313(\\operatorname{Yr2}) + 0.8657(\\operatorname{Yr3})\n\\]\n\n\nOur best guess for Hypothetical.Student must then be:\n\n14.145 + 0.076*55 + 0.4313*95 + 0.8657*110\n\n[1] 154.5255\n\n\nWhat does predict produce?\n\npredict(my.lm, newdata = Hypothetical.Student)\n\n       1 \n154.5245 \n\n\nThe same thing except that mine by hand was restricted to four digits.\nIn exact form, we could produce, using matrix multiplication,\n\nc(summary(my.lm)$coefficients[,1])\n\n(Intercept)         Yr1         Yr2         Yr3 \n14.14598945  0.07602621  0.43128539  0.86568123 \n\nc(1,Hypothetical.Student)\n\n[[1]]\n[1] 1\n\n$Yr1\n[1] 55\n\n$Yr2\n[1] 95\n\n$Yr3\n[1] 110\n\nc(1,55,95,110)%*%c(summary(my.lm)$coefficients[,1])\n\n         [,1]\n[1,] 154.5245\n\n\nBecause that is all predict does.\n\n\nTo produce confidence intervals, we can add the interval option. For an interval of the predicted average, we have:\n\npredict(my.lm, newdata = Hypothetical.Student, interval=\"confidence\")\n\n       fit     lwr     upr\n1 154.5245 152.551 156.498\n\n\n\n\n\nAn interval of the predicted range of data, we have\n\npredict(my.lm, newdata = Hypothetical.Student, interval=\"prediction\")\n\n       fit      lwr      upr\n1 154.5245 94.76778 214.2812\n\n\n\n\n\n\nOne great thing about R is smart prediction. So what does it do? Let’s try out the centering operations that I used.\n\nmy.lm <- lm(Final ~ scale(Yr1, scale=FALSE) + scale(Yr2, scale=FALSE) + scale(Yr3, scale=FALSE), data=ugtests)\nsummary(my.lm)\n\n\nCall:\nlm(formula = Final ~ scale(Yr1, scale = FALSE) + scale(Yr2, scale = FALSE) + \n    scale(Yr3, scale = FALSE), data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-92.638 -20.349   0.001  18.954  98.489 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               148.96205    0.97467 152.833   <2e-16 ***\nscale(Yr1, scale = FALSE)   0.07603    0.06538   1.163    0.245    \nscale(Yr2, scale = FALSE)   0.43129    0.03251  13.267   <2e-16 ***\nscale(Yr3, scale = FALSE)   0.86568    0.02914  29.710   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.43 on 971 degrees of freedom\nMultiple R-squared:  0.5303,    Adjusted R-squared:  0.5289 \nF-statistic: 365.5 on 3 and 971 DF,  p-value: < 2.2e-16\n\n\n\nequatiomatic::extract_eq(my.lm, use_coefs = TRUE, coef_digits = 4)\n\n\\[\n\\operatorname{\\widehat{Final}} = 148.9621 + 0.076(\\operatorname{scale(Yr1,\\ scale\\ =\\ FALSE)}) + 0.4313(\\operatorname{scale(Yr2,\\ scale\\ =\\ FALSE)}) + 0.8657(\\operatorname{scale(Yr3,\\ scale\\ =\\ FALSE)})\n\\]\n\n\nOnly the intercept is impacted; the original intercept was the expected Final for a student that had all zeroes [possible but a very poor performance] and they’d have expected a 14.15 [the original intercept]. After the centering operation for each predictor, the average student [mean scores on Yr1, Yr2, and Yr3] could expect a score of 148.96205 – the intercept from the regression on centered data.\nNow let’s predict our Hypothetical.Student.\n\npredict(my.lm, newdata=Hypothetical.Student)\n\n       1 \n154.5245 \n\n\nThe result is the same.\n\npredict(my.lm, newdata=Hypothetical.Student, interval=\"confidence\")\n\n       fit     lwr     upr\n1 154.5245 152.551 156.498\n\n\n\npredict(my.lm, newdata=Hypothetical.Student, interval=\"prediction\")\n\n       fit      lwr      upr\n1 154.5245 94.76778 214.2812\n\n\nThis works because R knows that each variable was centered, the mean was subtracted because that is what scale does when the [unfortunately named] argument scale inside the function scale is set to FALSE => we are not creating z-scores [the default is \\(\\frac{x_{i} - \\overline{x}}{sd(x)}\\)] but are just taking \\(x_{i} - \\overline{x}\\) or centering the data.\n\n\n\nLet me try a regression where Yr1, Yr2, and Yr3 are allowed to have effects with curvature using each term and its square.\n\nmy.lm.Sq <- lm(Final ~ Yr1 + Yr1^2 + Yr2 + Yr2^2 + Yr3 + Yr3^2, data=ugtests)\nsummary(my.lm.Sq)\n\n\nCall:\nlm(formula = Final ~ Yr1 + Yr1^2 + Yr2 + Yr2^2 + Yr3 + Yr3^2, \n    data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-92.638 -20.349   0.001  18.954  98.489 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 14.14599    5.48006   2.581  0.00999 ** \nYr1          0.07603    0.06538   1.163  0.24519    \nYr2          0.43129    0.03251  13.267  < 2e-16 ***\nYr3          0.86568    0.02914  29.710  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.43 on 971 degrees of freedom\nMultiple R-squared:  0.5303,    Adjusted R-squared:  0.5289 \nF-statistic: 365.5 on 3 and 971 DF,  p-value: < 2.2e-16\n\n\nUnfortunately, that did not actually include the squared terms, we still only have three lines. We could use this:\n\nmy.lm.Sq <- lm(Final ~ Yr1 + Yr1*Yr1 + Yr2 + Yr2*Yr2 + Yr3 + Yr3*Yr3, data=ugtests)\nsummary(my.lm.Sq)\n\n\nCall:\nlm(formula = Final ~ Yr1 + Yr1 * Yr1 + Yr2 + Yr2 * Yr2 + Yr3 + \n    Yr3 * Yr3, data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-92.638 -20.349   0.001  18.954  98.489 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 14.14599    5.48006   2.581  0.00999 ** \nYr1          0.07603    0.06538   1.163  0.24519    \nYr2          0.43129    0.03251  13.267  < 2e-16 ***\nYr3          0.86568    0.02914  29.710  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.43 on 971 degrees of freedom\nMultiple R-squared:  0.5303,    Adjusted R-squared:  0.5289 \nF-statistic: 365.5 on 3 and 971 DF,  p-value: < 2.2e-16\n\n\nBut that also does not work. The key is to give \\(R\\) an object for the squared term that treats Yr1, Yr2, and Yr3 as base terms to be squared; the function for this is I.\n\nmy.lm.Sq <- lm(Final ~ Yr1 + I(Yr1^2) + Yr2 + I(Yr2^2) + Yr3 + I(Yr3^2), data=ugtests)\nsummary(my.lm.Sq)\n\n\nCall:\nlm(formula = Final ~ Yr1 + I(Yr1^2) + Yr2 + I(Yr2^2) + Yr3 + \n    I(Yr3^2), data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.292 -19.764  -0.006  18.961  93.503 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 24.4243935 13.4033492   1.822   0.0687 .  \nYr1          0.2023539  0.3209042   0.631   0.5285    \nI(Yr1^2)    -0.0011955  0.0030483  -0.392   0.6950    \nYr2          0.3434989  0.1446076   2.375   0.0177 *  \nI(Yr2^2)     0.0004756  0.0007687   0.619   0.5362    \nYr3          0.6617121  0.1549276   4.271 2.14e-05 ***\nI(Yr3^2)     0.0009624  0.0007183   1.340   0.1806    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.45 on 968 degrees of freedom\nMultiple R-squared:  0.5314,    Adjusted R-squared:  0.5285 \nF-statistic:   183 on 6 and 968 DF,  p-value: < 2.2e-16\n\n\nDoes the curvature improve fit? We can use an F test.\n\nanova(my.lm, my.lm.Sq)\n\nAnalysis of Variance Table\n\nModel 1: Final ~ scale(Yr1, scale = FALSE) + scale(Yr2, scale = FALSE) + \n    scale(Yr3, scale = FALSE)\nModel 2: Final ~ Yr1 + I(Yr1^2) + Yr2 + I(Yr2^2) + Yr3 + I(Yr3^2)\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1    971 899371                           \n2    968 897272  3    2098.6 0.7547 0.5197\n\n\nWe cannot tell the two models apart so the squared terms do not improve the model. That wasn’t really the goal, it was to illustrate Smart Prediction.\nWhat would we expect, given this new model, for our hypothetical student?\n\npredict(my.lm.Sq, newdata=Hypothetical.Student)\n\n       1 \n153.2958 \n\n\nI will forego the intervals but it just works because R knows to square each of Yr1, Yr2, and Yr3.\n\n\n\nSuppose that Yr1 and Yr2 have an interactive effect. We could use the I() construct but we do not have to. The regression would be:\n\nmy.lm.Int <- lm(Final ~ Yr1 + Yr2 + Yr1*Yr2 + Yr3, data=ugtests)\nsummary(my.lm.Int)\n\n\nCall:\nlm(formula = Final ~ Yr1 + Yr2 + Yr1 * Yr2 + Yr3, data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.745 -20.774  -0.013  19.112  98.618 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.961723  11.930732   0.248    0.804    \nYr1          0.290161   0.213180   1.361    0.174    \nYr2          0.550808   0.117829   4.675 3.36e-06 ***\nYr3          0.866264   0.029141  29.727  < 2e-16 ***\nYr1:Yr2     -0.002295   0.002175  -1.055    0.292    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.43 on 970 degrees of freedom\nMultiple R-squared:  0.5309,    Adjusted R-squared:  0.5289 \nF-statistic: 274.4 on 4 and 970 DF,  p-value: < 2.2e-16\n\nmy.lm.I <- lm(Final ~ Yr1 + Yr2 + I(Yr1*Yr2) + Yr3, data=ugtests)\nsummary(my.lm.I)\n\n\nCall:\nlm(formula = Final ~ Yr1 + Yr2 + I(Yr1 * Yr2) + Yr3, data = ugtests)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.745 -20.774  -0.013  19.112  98.618 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.961723  11.930732   0.248    0.804    \nYr1           0.290161   0.213180   1.361    0.174    \nYr2           0.550808   0.117829   4.675 3.36e-06 ***\nI(Yr1 * Yr2) -0.002295   0.002175  -1.055    0.292    \nYr3           0.866264   0.029141  29.727  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.43 on 970 degrees of freedom\nMultiple R-squared:  0.5309,    Adjusted R-squared:  0.5289 \nF-statistic: 274.4 on 4 and 970 DF,  p-value: < 2.2e-16\n\n\nIt is worth noting that this does not improve the fit of the model.\n\nanova(my.lm, my.lm.I)\n\nAnalysis of Variance Table\n\nModel 1: Final ~ scale(Yr1, scale = FALSE) + scale(Yr2, scale = FALSE) + \n    scale(Yr3, scale = FALSE)\nModel 2: Final ~ Yr1 + Yr2 + I(Yr1 * Yr2) + Yr3\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1    971 899371                           \n2    970 898340  1    1031.5 1.1137 0.2915\n\nanova(my.lm, my.lm.Int)\n\nAnalysis of Variance Table\n\nModel 1: Final ~ scale(Yr1, scale = FALSE) + scale(Yr2, scale = FALSE) + \n    scale(Yr3, scale = FALSE)\nModel 2: Final ~ Yr1 + Yr2 + Yr1 * Yr2 + Yr3\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1    971 899371                           \n2    970 898340  1    1031.5 1.1137 0.2915\n\n\nThe same holds for both:\n\npredict(my.lm.I, newdata=Hypothetical.Student)\n\n      1 \n154.544 \n\npredict(my.lm.Int, newdata=Hypothetical.Student)\n\n      1 \n154.544 \n\n\n\n\n\nLet me generate some fake data to showcase use cases for quadratic functions of x as determinants of y.\n\n\nI will generate \\(y\\) according to the following equation.\n\\[y = x + 2*x^2 + \\epsilon\\]\nwhere x is a sequence from -5 to 5 and \\(\\epsilon\\) is Normal(0,1).\n\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nfake.df <- data.frame(x=seq(-5,5, by=0.05))\nfake.df$y <- fake.df$x + 2*fake.df$x^2 + rnorm(201)\n\n\n\n\nLet me plot x and y and include the estimated regression line [that does not include the squared term].\n\nfake.df %>% ggplot() + aes(x=x, y=y) + geom_point() + geom_smooth(method=\"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nTo be transparent, here is the regression.\n\nsummary(lm(y~x, data=fake.df))\n\n\nCall:\nlm(formula = y ~ x, data = fake.df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.881 -13.564  -4.011  11.655  32.283 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  16.8459     1.0606  15.884  < 2e-16 ***\nx             0.9736     0.3656   2.663  0.00837 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.04 on 199 degrees of freedom\nMultiple R-squared:  0.03441,   Adjusted R-squared:  0.02956 \nF-statistic: 7.093 on 1 and 199 DF,  p-value: 0.008374\n\n\nNote just looking at the table would suggest we conclude that \\(y\\) is a linear function of \\(x\\) and this is, at best, partially true. It is actually a quadratic function of \\(x\\). The fit is not very good, though.\nWhat do the residuals look like?\n\nfake.df %<>% mutate(resid = lm(y~x, fake.df)$residuals)\nfake.df %>% ggplot() + aes(x=x, y=resid) + geom_point() + theme_minimal() + labs(y=\"Residuals from linear regression with only x\")\n\n\n\n\nThis is a characteristic pattern of a quadratic, a because the inflection point is at zero and \\(x\\) can be both positive or negative. Real world data is almost always a bit messier. Nevertheless, I digress. Let’s look at the regression estimates including a squared term.\n\nsummary(lm(y~x+I(x^2), fake.df))\n\n\nCall:\nlm(formula = y ~ x + I(x^2), data = fake.df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.85154 -0.72408 -0.00959  0.55789  3.07849 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.158945   0.111171    1.43    0.154    \nx           0.973576   0.025546   38.11   <2e-16 ***\nI(x^2)      1.982605   0.009845  201.38   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.051 on 198 degrees of freedom\nMultiple R-squared:  0.9953,    Adjusted R-squared:  0.9953 \nF-statistic: 2.1e+04 on 2 and 198 DF,  p-value: < 2.2e-16\n\n\nNotice both the linear and the squared term are statistically different from zero and that the linear term has a much smaller standard error because it is far more precisely estimated. What do the residuals now look like?\n\nfake.df %<>% mutate(resid.sq = lm(y~x+I(x^2), fake.df)$residuals)\nfake.df %>% ggplot() + aes(x=x, y=resid.sq) + geom_point()\n\n\n\n\nThese are basically random with respect to \\(x\\).\nI should also point out that the residuals are well behaved now; they were not in the previous case.\n\nlibrary(gvlma)\ngvlma(lm(y~x, data=fake.df))\n\n\nCall:\nlm(formula = y ~ x, data = fake.df)\n\nCoefficients:\n(Intercept)            x  \n    16.8459       0.9736  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = lm(y ~ x, data = fake.df)) \n\n                       Value   p-value                   Decision\nGlobal Stat        2.193e+02 0.0000000 Assumptions NOT satisfied!\nSkewness           1.275e+01 0.0003564 Assumptions NOT satisfied!\nKurtosis           6.495e+00 0.0108195 Assumptions NOT satisfied!\nLink Function      2.000e+02 0.0000000 Assumptions NOT satisfied!\nHeteroscedasticity 7.628e-03 0.9304026    Assumptions acceptable.\n\n\nVersus\n\ngvlma(lm(y~x+I(x^2), data=fake.df))\n\n\nCall:\nlm(formula = y ~ x + I(x^2), data = fake.df)\n\nCoefficients:\n(Intercept)            x       I(x^2)  \n     0.1589       0.9736       1.9826  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = lm(y ~ x + I(x^2), data = fake.df)) \n\n                       Value p-value                Decision\nGlobal Stat        4.7545761  0.3134 Assumptions acceptable.\nSkewness           1.8889919  0.1693 Assumptions acceptable.\nKurtosis           0.5404830  0.4622 Assumptions acceptable.\nLink Function      2.3249033  0.1273 Assumptions acceptable.\nHeteroscedasticity 0.0001979  0.9888 Assumptions acceptable."
  },
  {
    "objectID": "posts/binomial-vaccine-efficacy/index.html",
    "href": "posts/binomial-vaccine-efficacy/index.html",
    "title": "Vaccine Efficacy: A Binomial Problem",
    "section": "",
    "text": "When the first bits of efficacy on the Pfizer/BioNTech vaccine were released, this provides an excellent example for analysis using the binomial. The blog post from phastar is here.\n\nA Quick and Dirty Vaccine Analysis: Initial Trials\nLast November, we got the first formal data with very encouraging news regarding the efficacy of the Pfizer/BioNTech COVID-19 vaccine. A thorough and interesting description of the study can be found on phastar. Using supplemental data from the blog post (I had not seen these key data details elsewhere), we can more fully understand what talk of vaccine efficacy means. I should also their use of 95% is something embedded in the study protocol.\nThe trial is a two-armed trial with equal numbers in the vaccine and placebo groups. The total sample is 43,538 with 21769 in each arm. Moveover, we learn that of 94 COVID cases, there were 8 in the vaccine group and 86 in the placebo group. Disease condition is yes/no, repeated in identical trials for the two groups, to yield the following two exact binomial analyses. First, let us examine the vaccinated groups.\n\n# The Vaccinated Group\nbinom.test(8, 21769)\n\n\n    Exact binomial test\n\ndata:  8 and 21769\nnumber of successes = 8, number of trials = 21769, p-value < 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.0001586712 0.0007239827\nsample estimates:\nprobability of success \n          0.0003674951 \n\n\nIn the vaccinated group, the probability of infection, with 95% confidence/probability, is estimated to range from 0.000159 to 0.000724. 1.6 to 7.2 in 10,000. What about the unvaccinated group?\n\n# The Placebo Group\nbinom.test(86, 21769)\n\n\n    Exact binomial test\n\ndata:  86 and 21769\nnumber of successes = 86, number of trials = 21769, p-value < 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.003161126 0.004876658\nsample estimates:\nprobability of success \n           0.003950572 \n\n\nIn the placebo group, the probability of infection, with 95% confidence/probability, is estimated to range from 0.0032 to 0.0049. That’s somewhere between 32 and 49 in 10,000. The smallest probability for the placebo group is 0.0032 while the largest probability for the vaccinated group is 0.000724. The ratio is over 4.4 meaning you are at least 4.4 times more likely to be infected if unvaccinated, though the circulating variants and their frequency were quite different one year ago.\nAs the article suggests, the standard measure of interest is vaccine efficacy; it is measured as \\[\nVE = \\frac{Pr(Infection|Placebo) - Pr(Infection|Vaccine)}{Pr(Infection|Placebo)}\n\\]\nWith the two intervals above, we have intervals for each of the two quantities in the calculation. What I do not know is what we might assume as a distribution for the confidence interval. Because it is two-sided, a uniform doesn’t seem entirely unreasonable and should at least well constitute bounds on effectiveness if not rendering an appropriate shape.\nLet me use a very basic Monte Carlo simulation to work through it. I will first generate random probabilities between the two ends of the confidence interval for the No.Vaccine group and then do the same thing for the Vaccine group.\n\nNo.Vaccine <- runif(1000, 0.003161126, 0.004876658)\nVaccine <- runif(1000, 0.0001586712, 0.0007239827)\n\nFinally, I want to calculate Vaccine Efficacy using the simulated data and the formula given above.\n\nSimulated.Data <- data.frame(Vaccine,No.Vaccine) %>% mutate(Vaccine.Efficacy = (No.Vaccine - Vaccine) / No.Vaccine) \n\nI conclude by plotting Vaccine.Efficacy.\n\nSimulated.Data %>% ggplot() + aes(x=Vaccine.Efficacy) + \n  geom_histogram(binwidth=0.005) + \n# geom_density(color=\"red\", size=3) + \n  labs(title=\"Pfizer Vaccine Efficacy\", x=\"Simulated Vaccine Efficacy\", caption=\"Efficacy calculated using uniform simulations from 95% exact binomial intervals; 8 and 86 of 21769 for the groups.\") + theme_minimal()"
  },
  {
    "objectID": "posts/2019-10-25-a-quick-and-dirty-introduction-to-r/index.html",
    "href": "posts/2019-10-25-a-quick-and-dirty-introduction-to-r/index.html",
    "title": "A Quick and Dirty Introduction to R",
    "section": "",
    "text": "Some Data\nI will start with some inline data.\n\nlibrary(tidyverse); library(skimr);\nSupport.Times <- structure(list(Screened = c(26.9, 28.4, 23.9, 21.8, 22.4, 25.9, \n26.5, 20, 23.7, 23.7, 22.6, 19.4, 27.3, 25.3, 27.7, 25.3, 28.4, \n24.2, 20.4, 29.6, 27, 23.6, 18.3, 28.1, 20.5, 24.1, 27.2, 26.4, \n24.5, 25.6, 17.9, 23.5, 25.3, 20.2, 26.3, 27.9), Not.Screened = c(24.7, \n19.1, 21, 17.8, 22.8, 24.4, 17.9, 20.5, 20, 26.2, 14.5, 22.4, \n21.1, 24.3, 22, 24.3, 23.9, 19.6, 23.8, 29.2, 19.7, 20.9, 25.2, \n22.5, 23.1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)), class = \"data.frame\", row.names = c(NA, -36L))\n\nNow I will use the tidyverse to stack it. This can also be done with stack(Support.Times).\nstack(Support.Times) %>% drop_na()\nUsing the tidyverse, the new data SSTimes will stack the data using pivot longer into two variables that I will name Self.Screen and Call.Time to store the stacked data. The final command drops the missing data. Then I will group them and skim them.\n\nSSTimes <- Support.Times %>% pivot_longer(., c(Screened,Not.Screened), names_to = \"Self.Screen\", values_to = \"Call.Time\") %>% drop_na()\nSSTimes %>% group_by(Self.Screen) %>% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n61\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nSelf.Screen\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nSelf.Screen\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCall.Time\nNot.Screened\n0\n1\n22.04\n3.11\n14.5\n20.00\n22.4\n24.30\n29.2\n▁▅▇▇▁\n\n\nCall.Time\nScreened\n0\n1\n24.44\n3.08\n17.9\n22.55\n24.9\n26.92\n29.6\n▃▃▆▇▅\n\n\n\n\n\nSo I have 25 observations that are not screened and 36 that are screened. What does it look like?\n\nggplot(SSTimes, aes(x=Self.Screen, y=Call.Time, fill=Self.Screen)) + geom_violin(alpha = 0.2) + scale_fill_discrete(guide=FALSE) + labs(title = \"Self Screen and Non-Self Screen Call Times\")\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\n\n\n\n\n\nHere is a picture of the distributions of the two means.\n\ngplots::plotmeans(Call.Time~Self.Screen, data=SSTimes, n.label=FALSE, ci.label=TRUE, ylim=c(20,27))\n\n\n\n\nWhat does the t-test look like?\n\nt.test(Support.Times$Not.Screened, Support.Times$Screened)\n\n\n    Welch Two Sample t-test\n\ndata:  Support.Times$Not.Screened and Support.Times$Screened\nt = -2.9793, df = 51.512, p-value = 0.004399\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.0216630 -0.7841148\nsample estimates:\nmean of x mean of y \n 22.03600  24.43889 \n\nt.test(Call.Time~Self.Screen, data=SSTimes)\n\n\n    Welch Two Sample t-test\n\ndata:  Call.Time by Self.Screen\nt = -2.9793, df = 51.512, p-value = 0.004399\nalternative hypothesis: true difference in means between group Not.Screened and group Screened is not equal to 0\n95 percent confidence interval:\n -4.0216630 -0.7841148\nsample estimates:\nmean in group Not.Screened     mean in group Screened \n                  22.03600                   24.43889 \n\n\nIt is worth noting that R stores a bunch of stuff. For example, it stores the standard error of the difference and that is worth looking at in this case; the standard error that describes the difference in the averages is 0.8065242.\n\nResample.Times <- ResampleProps::ResampleDiffMeans(Support.Times$Screened,Support.Times$Not.Screened)\nsd(Resample.Times)\n\n[1] 0.8053244"
  },
  {
    "objectID": "posts/quick-fredr/index.html",
    "href": "posts/quick-fredr/index.html",
    "title": "fredr: quick and dirty",
    "section": "",
    "text": "Downloading the FRED data on national debt as a percentage of GDP. I first want to examine the US data and will then turn to some comparisons. fredr makes it markable asy to do! I will use two core tools from fredr. First, fredr_series_search allows one to enter search text and retrieve the responsive series given that search text. They can be sorted in particular ways, two such options are shown below. In the first chunk, I will download the “national debt” data and show the top 6 responsive series.\n\nlibrary(fredr);library(ggthemes)\nDebt.Search <- fredr_series_search_text(\n  search_text = \"national debt\",\n  order_by = \"popularity\",\n  sort_order = \"desc\")\nDebt.Search <- Debt.Search %>% top_n(6)\nDebt.Search %>% select(id, title)\n\n# A tibble: 14 × 2\n   id               title                                                       \n   <chr>            <chr>                                                       \n 1 DDDM04USA156NWDB Outstanding Domestic Public Debt Securities to GDP for Unit…\n 2 DDDM04INA156NWDB Outstanding Domestic Public Debt Securities to GDP for India\n 3 DDDM04CAA156NWDB Outstanding Domestic Public Debt Securities to GDP for Cana…\n 4 WLSFAL           Liabilities: Deposits with F.R. Banks, Other Than Reserve B…\n 5 DDDM04CNA156NWDB Outstanding Domestic Public Debt Securities to GDP for China\n 6 DDDM04LBA156NWDB Outstanding Domestic Public Debt Securities to GDP for Leba…\n 7 DDDM04JPA156NWDB Outstanding Domestic Public Debt Securities to GDP for Japan\n 8 WDSFAL           Factors Absorbing Reserve Funds: Deposits with Federal Rese…\n 9 DDDM04BRA156NWDB Outstanding Domestic Public Debt Securities to GDP for Braz…\n10 DDDM04GRA156NWDB Outstanding Domestic Public Debt Securities to GDP for Gree…\n11 DDDM04IDA156NWDB Outstanding Domestic Public Debt Securities to GDP for Indo…\n12 DDDM04SGA156NWDB Outstanding Domestic Public Debt Securities to GDP for Sing…\n13 DDDM04MXA156NWDB Outstanding Domestic Public Debt Securities to GDP for Mexi…\n14 DDDM04VEA156NWDB Outstanding Domestic Public Debt Securities to GDP for Boli…\n\n\nNext, I need to acquire the data that I want. I probably should have reversed the order of some of the operations here. For example, I don’t really want the non-domestic public debt but I am not going to filter them before downloading. That’s not great but it isn’t all that much data either. The command fredr aliases the fredr_series_observations command that obtains data directly from FRED. I will use a variant of map to grab the relevant series id above and then join them back to the Search results.\n\nDebt.Data <- map_dfr(Debt.Search$id, fredr) %>% left_join(Debt.Search, by=c(\"series_id\" = \"id\"))\n\nNow let me splice off the United States and plot it.\n\nUS.Debt <- dplyr::filter(Debt.Data, grepl('to GDP for United States', title))\nggplot(US.Debt, aes(x=date, y=value)) + geom_line(size=3) + theme_economist() + theme(plot.title = element_text(color=\"red\", size=11, face=\"bold.italic\")) + labs(title=US.Debt$title[1], y=\"Debt to GDP\", x=\"Date\")\n\n\n\n\nAnd because I ended up with a bunch of them; multiple time series plots. To automate this, I will first remove everything that represents liabilities above in the FRB system. Then I need to use the series title to select everything that I want and separate off the country names for labels. The only hard-coding hacks for the final plot are the title. Here’s what we get, with color encoding the country names.\n\nlibrary(stringr)\nCtry.DD <- Debt.Data %>% filter(!grepl('Liabilities: Deposits', title))\nCtry.DD <- Ctry.DD %>% mutate(Country = str_remove(title, str_remove(US.Debt$title[1], \"United States\")))\nplot1 <- Ctry.DD %>% filter(!str_starts(Country, \"Factors\")) %>% ggplot(., aes(x=date, y=value, color=Country)) + geom_line(size=1) + scale_color_viridis_d() + labs(title=\"Public Debt to GDP\", y=\"Public Debt to GDP\") + guides(color=\"none\")\nlibrary(widgetframe)\nplotly::ggplotly(plot1)"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "",
    "text": "There is detailed help for all that Markdown can do under Help in the RStudio. The key to it is knitting documents with the Knit button in the RStudio. If we use helpers like the R Commander, Radiant, or esquisse, we will need the R code implanted in the Markdown document in particular ways. I will use Markdown for everything. I even use a close relation of Markdown in my scholarly pursuits.\n\n\nWe will rely on five. The tidyverse is Hadley Wickham’s collection of packages. It represents a different philosophy for the construction of exploratory data analysis with literate programming – code that you can read. We will rely on the %>% piping operators of the magrittr package that pipes something to a subsequent command as a core function of the tidyverse.\nFor everything that we want in a summary, there is the skimr function skim. For cross-tabulation the easy way, there is janitor. The other two are developmental pieces of software that have yet to deploy into the regular package system of R. esquisse and parts of that’s so random blog’s package for implementing ggmosaic.\npkgTest <- function(x)\n  {\n    if (!require(x,character.only = TRUE))\n    {\n      install.packages(x,dep=TRUE, type=\"binary\")\n        if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n    }\n}\npkgTest(\"tidyverse\")\npkgTest(\"magrittr\")\npkgTest(\"skimr\")\npkgTest(\"janitor\")\npkgTest(\"devtools\")\ndevtools::install_github(\"EdwinTH/thatssorandom\")\npkgTest(\"dreamRs/esquisse\")\n\n\n\nWe have an embedded data object; if you look at the beginning of the document, I have used an R command called dput to embed the data in the document. Above, there is encoded text of Bond.Funds to use as an example. To get a sense of the data, I will load the skim function and put it to work. In R, we will use the library command to load functions into the namespace – the set of recognizable commands. R needs to know how a function is defined to use it. The function skim appears in the skimr library.\n\nlibrary(skimr)\nskim(Bond.Funds)\n\n\nData summary\n\n\nName\nBond.Funds\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFund Number\n0\n1\n4\n6\n0\n184\n0\n\n\nType\n0\n1\n20\n23\n0\n2\n0\n\n\nFees\n0\n1\n2\n3\n0\n2\n0\n\n\nRisk\n0\n1\n7\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAssets\n0\n1\n910.65\n2253.27\n12.40\n113.72\n268.4\n621.95\n18603.50\n▇▁▁▁▁\n\n\nExpense Ratio\n0\n1\n0.71\n0.26\n0.12\n0.53\n0.7\n0.90\n1.94\n▂▇▅▁▁\n\n\nReturn 2009\n0\n1\n7.16\n6.09\n-8.80\n3.48\n6.4\n10.72\n32.00\n▁▇▅▁▁\n\n\n3-Year Return\n0\n1\n4.66\n2.52\n-13.80\n4.05\n5.1\n6.10\n9.40\n▁▁▁▅▇\n\n\n5-Year Return\n0\n1\n3.99\n1.49\n-7.30\n3.60\n4.3\n4.90\n6.80\n▁▁▁▅▇\n\n\n\n\n# skimr::skim(Bond.Funds)"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#numerical-summary",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#numerical-summary",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "Numerical Summary",
    "text": "Numerical Summary\n\nlibrary(tidyverse)\nBond.Funds %>% group_by(Risk) %>% \n  summarise(Avg.Return = mean(`Return 2009`), SD.Return=sd(`Return 2009`), median.Return=median(`Return 2009`), IQR.Return=IQR(`Return 2009`))\n\n# A tibble: 3 × 5\n  Risk          Avg.Return SD.Return median.Return IQR.Return\n  <chr>              <dbl>     <dbl>         <dbl>      <dbl>\n1 Above average       8.31      9.24           7.9      13.0 \n2 Average             6.87      4.39           6         7.3 \n3 Below average       6.31      2.71           6.1       3.18\n\n\nI can also use skim.\n\nBond.Funds %>% group_by(Risk,Fees) %>% skim(`Return 2009`)\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nRisk, Fees\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nRisk\nFees\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nReturn 2009\nAbove average\nNo\n0\n1\n8.25\n8.92\n-8.8\n0.70\n9.90\n13.50\n32.0\n▃▃▇▂▁\n\n\nReturn 2009\nAbove average\nYes\n0\n1\n8.42\n9.96\n-4.8\n0.98\n6.85\n14.93\n29.7\n▇▆▃▃▂\n\n\nReturn 2009\nAverage\nNo\n0\n1\n7.37\n4.51\n-1.1\n4.30\n6.50\n11.20\n16.4\n▆▆▇▇▃\n\n\nReturn 2009\nAverage\nYes\n0\n1\n5.66\n3.93\n-0.6\n3.35\n4.80\n8.00\n12.9\n▃▇▅▂▅\n\n\nReturn 2009\nBelow average\nNo\n0\n1\n6.33\n2.80\n0.2\n4.85\n6.20\n7.58\n13.0\n▂▅▇▃▁\n\n\nReturn 2009\nBelow average\nYes\n0\n1\n6.26\n2.46\n1.5\n5.02\n6.05\n8.22\n10.1\n▂▃▇▆▃\n\n\n\n\n\nI want to recreate a categorical pivot table also."
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#categorical-descriptions-requires-tables-or-graphics",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#categorical-descriptions-requires-tables-or-graphics",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "Categorical Descriptions Requires Tables [or Graphics]",
    "text": "Categorical Descriptions Requires Tables [or Graphics]\nThere are numerous ways to build tables in R. Base R has a table function that works but it does not naturally work inside data environments; we have to provide them using $ or with environments [or %$% in magrittr]. This brief description of environments is part of a broader idea of scoping in R.\n\nEasiest: janitor\nThe package janitor contains a tabyl with the ability to add totals and calculate percentages of relevance. Here are two examples.\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nBond.Funds %>% tabyl(Fees,Risk) %>% adorn_totals(c(\"row\",\"col\"))\n\n  Fees Above average Average Below average Total\n    No            37      49            44   130\n   Yes            22      20            12    54\n Total            59      69            56   184\n\nBond.Funds %>% tabyl(Fees,Risk) %>% adorn_percentages(\"row\")\n\n Fees Above average   Average Below average\n   No     0.2846154 0.3769231     0.3384615\n  Yes     0.4074074 0.3703704     0.2222222\n\n\n\n\nEasier with xtabs and formulae\nThis is actually made much easier with a slightly new form of syntax: formulae. Base R, as you have already learned (or will learn) with swirl, uses different and less readable syntax than the tidyverse. But this is a problem that is quite easy for R in the base commands table and xtabs [crosstabs]. In the first instance, we merely create a table counting values. In the second, the data is a named argument for the function xtabs that requires a statement of margins for the table as a series of names with “+”. The order will determine the rows [first] and the columns [second].\n\ntable(Bond.Funds$Fees,Bond.Funds$Risk)\n\n     \n      Above average Average Below average\n  No             37      49            44\n  Yes            22      20            12\n\nxtabs(~Fees+Risk, data=Bond.Funds)\n\n     Risk\nFees  Above average Average Below average\n  No             37      49            44\n  Yes            22      20            12\n\n\nThese can also be assigned as objects using the “<-”; this saves a local version of the table as something that we can work on. I will call mine FR.Tab for the F(ees)R(isk).Tab(le).\n\nFR.Tab <- xtabs(~Fees+Risk, data=Bond.Funds)\n\n\n\nWorst: Table\nBase R table is great but it requires that we specify an environment. To grab a variable from inside a data.frame requires $, as in\n\ntable(Bond.Funds$Fees,Bond.Funds$Risk)\n\n     \n      Above average Average Below average\n  No             37      49            44\n  Yes            22      20            12\n\nBRTab1 <- table(Bond.Funds$Fees,Bond.Funds$Risk)\n\nWe can accomplish the same with with, telling R to evaluate something inside whatever data object is in with, for example,\n\nwith(Bond.Funds, table(Fees,Risk))\n\n     Risk\nFees  Above average Average Below average\n  No             37      49            44\n  Yes            22      20            12\n\nWBF1 <- with(Bond.Funds, table(Fees,Risk))"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#conditional-frequency",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#conditional-frequency",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "Conditional Frequency",
    "text": "Conditional Frequency\nIf we think about conditional probability as measured in proportions of the table, we can ask R to calculate them. The command is prop.table and the inputs are a table and a margin here 1 is rows [conditioning on the first name you entered] and 2 is columns [the second name you entered]. Nothing specified is joint or total.\n\nprop.table(FR.Tab)\n\n     Risk\nFees  Above average    Average Below average\n  No     0.20108696 0.26630435    0.23913043\n  Yes    0.11956522 0.10869565    0.06521739\n\nprop.table(FR.Tab, 1)\n\n     Risk\nFees  Above average   Average Below average\n  No      0.2846154 0.3769231     0.3384615\n  Yes     0.4074074 0.3703704     0.2222222\n\nprop.table(FR.Tab, 2)\n\n     Risk\nFees  Above average   Average Below average\n  No      0.6271186 0.7101449     0.7857143\n  Yes     0.3728814 0.2898551     0.2142857\n\nprop.table(WBF1)\n\n     Risk\nFees  Above average    Average Below average\n  No     0.20108696 0.26630435    0.23913043\n  Yes    0.11956522 0.10869565    0.06521739\n\nprop.table(WBF1, 1)\n\n     Risk\nFees  Above average   Average Below average\n  No      0.2846154 0.3769231     0.3384615\n  Yes     0.4074074 0.3703704     0.2222222\n\nprop.table(WBF1, 2)\n\n     Risk\nFees  Above average   Average Below average\n  No      0.6271186 0.7101449     0.7857143\n  Yes     0.3728814 0.2898551     0.2142857"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#pivot-plots-mosaic",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#pivot-plots-mosaic",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "Pivot Plots [Mosaic]",
    "text": "Pivot Plots [Mosaic]\nBase R Graphics contain a mosaic with the same formula as the cross-tabulation above.\n\nmosaicplot(~Risk+Fees, data=Bond.Funds)\n\n\n\n\nI recently came across a nice plotter for tabular data on github. You can search for it as thatssorandom. We installed it above.\n\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the thatssorandom package.\n  Please report the issue to the authors.\n\n\n\n\n\nNotice it handles an implicit plotting of the set of conditional probabilities along the relevant margin. It is plotting \\(Pr(Fees|Risk)\\) as breaks along the y-axis defined by frequency/empirical probability. This would be the equivalent of taking the column marginal of the table of Fees and Risk that we saw before. Now it has a graphical representation.\n\nprop.table(FR.Tab, 2)\n\n     Risk\nFees  Above average   Average Below average\n  No      0.6271186 0.7101449     0.7857143\n  Yes     0.3728814 0.2898551     0.2142857"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#for-berkeley-admissions",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#for-berkeley-admissions",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "For Berkeley Admissions:",
    "text": "For Berkeley Admissions:\n\ndata(\"UCBAdmissions\")\nUCB <- DescTools::Untable(UCBAdmissions)\nUCB$Gender <- as.character(UCB$Gender)\nUCB$Gender[UCB$Gender==\"Male\"] <- \"M\"\nUCB$Gender[UCB$Gender==\"Female\"] <- \"F\"\nUCB$DeptMF <- paste(UCB$Dept,UCB$Gender, sep=\":\")\nUCB <- UCB %>% select(Admit,DeptMF)\np1 <- ggmm(UCB, x=DeptMF, y=Admit, add_text = \"n\")\np1 + labs(x=\"Dept:M/F\", y=\"Admitted\") + theme(axis.text=element_text(size=10))"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#barplots",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#barplots",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "Barplots",
    "text": "Barplots\nBasic things like barplots can be accomplished in many ways. Using the R4DS approach, we have\n\nggplot(data = Bond.Funds) + \n  stat_count(mapping = aes(x = Risk))\n\n\n\n\nPlaced into densities. This is really only helpful with another dimension because the X is categorical so all bars will be height 1.\n\nggplot(data = Bond.Funds, aes(x = Risk, fill=Fees)) + geom_bar(position=\"fill\")\n\n\n\n\nOr in Base R\n\npar(mfrow=c(1,2))\nbarplot(table(Bond.Funds$Risk))\nbarplot(table(Bond.Funds$Fees,Bond.Funds$Risk))\n\n\n\n\nA legend would help.\n\npar(mfrow=c(1,2))\nbarplot(table(Bond.Funds$Fees,Bond.Funds$Risk), legend=TRUE)\nbarplot(table(Bond.Funds$Fees,Bond.Funds$Risk), legend=TRUE, args.legend=list(bty=\"n\"))"
  },
  {
    "objectID": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#simple-visualization-esquisse",
    "href": "posts/2019-10-09-tables-pivots-bars-and-mosaics/index.html#simple-visualization-esquisse",
    "title": "Tables, Pivots, Bars, and Mosaics",
    "section": "Simple Visualization: esquisse()",
    "text": "Simple Visualization: esquisse()\nThere is a wonderful tool for quickly succeeding with one of the most elegant and frustrating parts of R – ggplot2. Hadley Wickham’s Grammar of Graphics is brilliant when understood but is hard to comprehend initially and the programming structure of the package makes it hard for learners. Fortunately, a package called esquisse is available to make ggplot2 drag and drop to harness much of the power in an easy fashion. With code in the output, it also facilitates learning how to manipulate the code of ggplot2.\nesquisse is quite powerful; we can explore this at length. Here is a simple graphic that I created with x and fills.\n\nlibrary(ggplot2)\nplt1 <- ggplot(data = Bond.Funds) +\n  aes(x = Type, fill = Fees) +\n  geom_bar() +\n  theme_minimal()\nplt1\n\n\n\n\nIf you notice, esquisse directly outputs graphics to powerpoint. This feature is quite useful."
  },
  {
    "objectID": "posts/clock-c-datetimes/index.html",
    "href": "posts/clock-c-datetimes/index.html",
    "title": "Allison Horst teaches ACFs",
    "section": "",
    "text": "Allison Horst and the Auto Correlation Function (ACF)\nThe inimitable Allison Horst put this together. It’s lovely….\nA link\n\n\nA new series to introduce the autocorrelation function (ACF) w/ time series data, with special thanks to @robjhyndman for feedback & suggestions! 👾🧵1/9: Meet the monster family. The youngest generation is on the right (that's our host). pic.twitter.com/9iBtV88KfU\n\n— Allison Horst @allison_horst@mastodon.social (@allison_horst) February 16, 2021"
  },
  {
    "objectID": "posts/visualizing-two-qualities/index.html",
    "href": "posts/visualizing-two-qualities/index.html",
    "title": "Visualizing Two Qualitative Variables",
    "section": "",
    "text": "A dataset for illustrating the various available visualizations needs a certain degree of richness with manageable size. The dataset on Bonds contains three categorical and a few quantitative indicators sufficient to show what we might wish.\n\n\n\nBonds <- read.csv(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/BondFunds.csv\"))\n\n\n\n\n\nlibrary(skimr)\nBonds %>%\n    skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFund.Number\n0\n1\n4\n6\n0\n184\n0\n\n\nType\n0\n1\n20\n23\n0\n2\n0\n\n\nFees\n0\n1\n2\n3\n0\n2\n0\n\n\nRisk\n0\n1\n7\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAssets\n0\n1\n910.65\n2253.27\n12.40\n113.72\n268.4\n621.95\n18603.50\n▇▁▁▁▁\n\n\nExpense.Ratio\n0\n1\n0.71\n0.26\n0.12\n0.53\n0.7\n0.90\n1.94\n▂▇▅▁▁\n\n\nReturn.2009\n0\n1\n7.16\n6.09\n-8.80\n3.48\n6.4\n10.72\n32.00\n▁▇▅▁▁\n\n\nX3.Year.Return\n0\n1\n4.66\n2.52\n-13.80\n4.05\n5.1\n6.10\n9.40\n▁▁▁▅▇\n\n\nX5.Year.Return\n0\n1\n3.99\n1.49\n-7.30\n3.60\n4.3\n4.90\n6.80\n▁▁▁▅▇\n\n\n\n\n\nMost data types are represented. There is no time variable so dates and the visualizations that go with time series are omitted."
  },
  {
    "objectID": "posts/visualizing-two-qualities/index.html#building-a-table",
    "href": "posts/visualizing-two-qualities/index.html#building-a-table",
    "title": "Visualizing Two Qualitative Variables",
    "section": "Building a Table",
    "text": "Building a Table\n\nBTDF <- Bonds %>%\n    group_by(Risk, Fees) %>%\n    summarise(Count = n()) %>%\n    data.frame()\n\n`summarise()` has grouped output by 'Risk'. You can override using the\n`.groups` argument.\n\nBTDF %>%\n    pivot_wider(names_from = Fees, values_from = Count)\n\n# A tibble: 3 × 3\n  Risk             No   Yes\n  <chr>         <int> <int>\n1 Above average    37    22\n2 Average          49    20\n3 Below average    44    12\n\n\nThe table as a data.frame.\n\nBTDF\n\n           Risk Fees Count\n1 Above average   No    37\n2 Above average  Yes    22\n3       Average   No    49\n4       Average  Yes    20\n5 Below average   No    44\n6 Below average  Yes    12"
  },
  {
    "objectID": "posts/visualizing-two-qualities/index.html#geom_tile",
    "href": "posts/visualizing-two-qualities/index.html#geom_tile",
    "title": "Visualizing Two Qualitative Variables",
    "section": "geom_tile",
    "text": "geom_tile\n\nBTDF %>%\n    ggplot(., aes(x = Risk, y = Fees, fill = Count)) + geom_tile() + scale_fill_viridis_c() +\n    theme_minimal() + labs(fill = \"Number of Funds\")"
  },
  {
    "objectID": "posts/visualizing-two-qualities/index.html#geom_label-a-visual-table",
    "href": "posts/visualizing-two-qualities/index.html#geom_label-a-visual-table",
    "title": "Visualizing Two Qualitative Variables",
    "section": "geom_label a visual table",
    "text": "geom_label a visual table\n\nBTDF %>%\n    ggplot(., aes(x = Risk, y = Fees, label = Count)) + geom_label() + theme_minimal() +\n    labs(subtitle = \"Counts of Funds Shown\")\n\n\n\n\n\nA Tile Table\n\nBTDF %>%\n    ggplot(., aes(x = Risk, y = Fees, label = Count, fill = Count)) + geom_tile(alpha = 0.2) +\n    scale_fill_viridis_c() + geom_text() + theme_minimal() + labs(subtitle = \"Counts of Funds Shown\")"
  },
  {
    "objectID": "posts/visualizing-two-qualities/index.html#geom_count",
    "href": "posts/visualizing-two-qualities/index.html#geom_count",
    "title": "Visualizing Two Qualitative Variables",
    "section": "geom_count()",
    "text": "geom_count()\n\nBonds %>%\n    ggplot() + aes(x = Risk, y = Fees) + geom_count() + theme_minimal()"
  },
  {
    "objectID": "posts/visualizing-two-qualities/index.html#conditional-probability-positionfill",
    "href": "posts/visualizing-two-qualities/index.html#conditional-probability-positionfill",
    "title": "Visualizing Two Qualitative Variables",
    "section": "Conditional Probability: (position=\"fill\")",
    "text": "Conditional Probability: (position=\"fill\")\nWe can also plot this normalized by the number in each category of x so that the plots represent conditional probability.\n\nBonds %>%\n    ggplot() + aes(x = Risk, fill = Fees) + geom_bar(position = \"fill\")"
  },
  {
    "objectID": "posts/ggtimeseries/index.html",
    "href": "posts/ggtimeseries/index.html",
    "title": "ggtimeseries",
    "section": "",
    "text": "ggtimeseries\nggTimeSeries is a collection of specialized plots for Time Series data above and beyond those normally deployed. It includes waterfall charts, steamgraphs, and some calendar visualizations that are all quite neat.\nHere is a link\nI found stat_waterfall() to have particular uses.\n\n\n\nWaterfall"
  },
  {
    "objectID": "posts/seasonal-adjustment/index.html",
    "href": "posts/seasonal-adjustment/index.html",
    "title": "A nice post on seasonal adjustment",
    "section": "",
    "text": "Seasonal adjustment\nA nice blog post on seasonal adjustment\nThe package contains a nice vignette for handling multiple series for seasonal adjustments using seasonal. You can find it here….\n\n\n\nscreenshot"
  },
  {
    "objectID": "posts/normal-residuals-in-radiant/index.html",
    "href": "posts/normal-residuals-in-radiant/index.html",
    "title": "Normal Residuals in Radiant",
    "section": "",
    "text": "radiant is a very convenient graphical interface for a curated subset of R’s capabilities. In this example, I show how to incorporate additional code into radiant to examine residual normality as a component of validating regression inference.\nLet us first begin with some example data. We can read the data off of the github host location for this website.\nYou can access the radiant state file here."
  },
  {
    "objectID": "posts/normal-residuals-in-radiant/index.html#regression-dialog",
    "href": "posts/normal-residuals-in-radiant/index.html#regression-dialog",
    "title": "Normal Residuals in Radiant",
    "section": "Regression Dialog",
    "text": "Regression Dialog\nI want a regression to illustrate, let me try to explain life_exp or life expectancy.\n\n\n\nRegression\n\n\nWe need to make sure we write the code to the report by using the scribe button just below and to the right of +Store.\n\n\n\nRadiantCode\n\n\nPress the button and the resulting code will appear in the Report tab in radiant under Rmd.\n\nlibrary(radiant)\nresult <- regress(\n  State.Data, \n  rvar = \"life_exp\", \n  evar = c(\"population\", \"income\", \"illiteracy\", \"murder\", \"hs_grad\")\n)\nsummary(result)\n\nKnit the report to see the following output.\n\n\nLinear regression (OLS)\nData     : State.Data \nResponse variable    : life_exp \nExplanatory variables: population, income, illiteracy, murder, hs_grad \nNull hyp.: the effect of x on life_exp is zero\nAlt. hyp.: the effect of x on life_exp is not zero\n\n             coefficient std.error t.value p.value    \n (Intercept)      69.684     1.252  55.653  < .001 ***\n population        0.000     0.000   2.571   0.014 *  \n income           -0.000     0.000  -0.286   0.776    \n illiteracy        0.389     0.296   1.312   0.196    \n murder           -0.302     0.045  -6.751  < .001 ***\n hs_grad           0.056     0.021   2.667   0.011 *  \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.713,  Adjusted R-squared: 0.68 \nF-statistic: 21.856 df(5,44), p.value < .001\nNr obs: 50 \n\n\n\ngvlma\nTo investigate residuals using radiant, we need to first call a library. The library is gvlma or general validation of linear model assumptions. The necessary command is library(gvlma). Then we want to call gvlma on the model. In this case, that is gvlma(result$model).\n\n\n\ngvlma\n\n\nOnce we have added the code, click knit report and the following output should result.\n\nlibrary(gvlma)\ngvlma::gvlma(result$model)\n\n\nCall:\nlm(formula = form_upper, data = dataset)\n\nCoefficients:\n(Intercept)   population       income   illiteracy       murder      hs_grad  \n  6.968e+01    7.149e-05   -6.874e-05    3.885e-01   -3.017e-01    5.587e-02  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = result$model) \n\n                      Value p-value                Decision\nGlobal Stat        1.857253  0.7620 Assumptions acceptable.\nSkewness           0.002941  0.9568 Assumptions acceptable.\nKurtosis           0.327674  0.5670 Assumptions acceptable.\nLink Function      0.786788  0.3751 Assumptions acceptable.\nHeteroscedasticity 0.739851  0.3897 Assumptions acceptable.\n\n\nThere are reasons to prefer gvlma but we could also use a few other tools. We could deploy a command that requires no additional libraries. With a null hypothesis that residuals are normal and recognizing this is probably best in cases like this with only fifty observations.\n\nshapiro.test(result$model$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  result$model$residuals\nW = 0.97747, p-value = 0.4508\n\n\nWe could also use plotlyreg with the requisite packages installed. I don’t currently like this because it fails to pass the axis names.\n\nsource(url(\"https://github.com/robertwwalker/DADMStuff/raw/master/PlotlyReg.R\"))\nRegressionPlots(result$model)\n\n\n\n\n\nradiant() also has a nice internal dashboard for assessing this.\n\n\n\ndashboard\n\n\nThat can be added to the report by clicking on the pencil/tablet.\n\n\n\ndashboard2"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html",
    "href": "posts/visualizing-one-quantitative-variable/index.html",
    "title": "Visualizing One Quantitative Variable",
    "section": "",
    "text": "A dataset for illustrating the various available visualizations needs a certain degree of richness with manageable size. The dataset on Bonds contains three categorical and a few quantitative indicators sufficient to show what we might wish.\n\n\n\nBonds <- read.csv(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/BondFunds.csv\"))\n\n\n\n\n\nlibrary(skimr)\nBonds %>%\n    skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFund.Number\n0\n1\n4\n6\n0\n184\n0\n\n\nType\n0\n1\n20\n23\n0\n2\n0\n\n\nFees\n0\n1\n2\n3\n0\n2\n0\n\n\nRisk\n0\n1\n7\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAssets\n0\n1\n910.65\n2253.27\n12.40\n113.72\n268.4\n621.95\n18603.50\n▇▁▁▁▁\n\n\nExpense.Ratio\n0\n1\n0.71\n0.26\n0.12\n0.53\n0.7\n0.90\n1.94\n▂▇▅▁▁\n\n\nReturn.2009\n0\n1\n7.16\n6.09\n-8.80\n3.48\n6.4\n10.72\n32.00\n▁▇▅▁▁\n\n\nX3.Year.Return\n0\n1\n4.66\n2.52\n-13.80\n4.05\n5.1\n6.10\n9.40\n▁▁▁▅▇\n\n\nX5.Year.Return\n0\n1\n3.99\n1.49\n-7.30\n3.60\n4.3\n4.90\n6.80\n▁▁▁▅▇\n\n\n\n\n\nMost data types are represented. There is no time variable so dates and the visualizations that go with time series are omitted."
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_histogram",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_histogram",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_histogram()",
    "text": "geom_histogram()\nA histogram divides the data into categories and counts the observations per category. The width of the categories [on x] is determined by binwidth= or the binwidth can be calculated as a function of the range and the number of bins bin=. I will define it as Gen.Hist.\n\nA Base Histogram\n\nGen.Hist <- Bonds %>%\n    ggplot() + aes(x = Assets) + geom_histogram()\nGen.Hist\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nHistograms [bins]\nWe can choose more bins. 50? That is far more than the default of 30.\n\nBin50.Hist <- Bonds %>%\n    ggplot() + aes(x = Assets) + geom_histogram(bins = 50)\nBin50.Hist\n\n\n\n\nWe can also choose fewer bins. I will choose 10.\n\nBin10.Hist <- Bonds %>%\n    ggplot() + aes(x = Assets) + geom_histogram(bins = 10)\nBin10.Hist\n\n\n\n\n\n\nHistograms [binwidth]\nWe can also set the width of bins in the metric of x; I will choose 500 (bigger).\n\nBinW500.Hist <- Bonds %>%\n    ggplot() + aes(x = Assets) + geom_histogram(binwidth = 500)\nBinW500.Hist\n\n\n\n\nWe can also set the width of bins in the metric of x; I will choose 50 (smaller width makes more bins).\n\nBinW50.Hist <- Bonds %>%\n    ggplot() + aes(x = Assets) + geom_histogram(binwidth = 50)\nBinW50.Hist"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_dotplot",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_dotplot",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_dotplot()",
    "text": "geom_dotplot()\ngeom_dotplot() places a dot for every observation in the relevant bin. We can control the size of the bins [in the original metric] with binwidth=.\n\nSmall binwidth\n\nBonds %>%\n    ggplot() + aes(x = Assets) + geom_dotplot(binwidth = 10)\n\n\n\n\n\n\nLarge binwidth\n\nBonds %>%\n    ggplot() + aes(x = Assets) + geom_dotplot(binwidth = 1000)\n\n\n\n\n\n\nAn ?optimal? binwidth\nEach dot represents a datum with bins of size 100.\n\nBonds %>%\n    ggplot() + aes(x = Assets) + geom_dotplot(binwidth = 100) + labs(y = \"\")"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_freqpoly",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_freqpoly",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_freqpoly()",
    "text": "geom_freqpoly()\ngeom_freqpoly() is the line equivalent of a histogram. The arguments are similar, the output doesn’t include the bars as it does in the histogram.\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_freqpoly()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nMore bins\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_freqpoly(bins = 50)\n\n\n\n\n\n\nFewer bins\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_freqpoly(bins = 10)"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_area",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_area",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_area()",
    "text": "geom_area()\nIs a relative of the histogram with lines connecting the midpoints of the bins and an associated fill from zero.\n\nDefaults to 30 bins\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_area(stat = \"bin\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nSmall binwidth with a large number of bins\nI will color in the area with magenta and clean up the theme.\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_area(stat = \"bin\", bins = 100, fill = \"magenta\") +\n    theme_minimal()"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_density",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_density",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_density()",
    "text": "geom_density()\nA relative of the histogram and the area plots above, the density plot smooths out the blocks of a histogram with a moving window [known as the bandwidth].\n\ngeom_density() outlines\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_density(outline.type = \"upper\")\n\n\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_density(outline.type = \"lower\")\n\n\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_density(outline.type = \"full\")\n\n\n\n\n\n\ngeom_density() adjust\nAdjust applies a numeric correction to the bandwidth. Numbers greater than 1 make the bandwidth bigger [and the graphic smoother] and numbers less than 1 [but greater than zero] make the bandwidth smaller and the graphic more jagged.\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_density(adjust = 2)\n\n\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_density(adjust = 1/2)"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_boxplot",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_boxplot",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_boxplot",
    "text": "geom_boxplot\nA boxplot shows a box of the first and third quartiles and a notch at the median. The dots above or below denote points outside the hinges. The hinges [default to 1.5*IQR] show a range of expected data while the individual dots show possible outliers outside the hinges. To adjust the hinges, the argument coef=1.5 can be adjusted.\n\nBonds %>%\n    ggplot(., aes(x = Assets)) + geom_boxplot()"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_qq",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_qq",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_qq()",
    "text": "geom_qq()\nTo compare empirical and theoretical quantiles. Comparing a distribution to the normal or others is common and this provides the tool for doing so. The default is a normal.\nThe empirical cumulative distribution function arises when we sort a quantitative variable and show the percentiles below said value.\n\nBonds %>%\n    ggplot(aes(sample = Assets)) + geom_qq()"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#stat_ecdfgeom",
    "href": "posts/visualizing-one-quantitative-variable/index.html#stat_ecdfgeom",
    "title": "Visualizing One Quantitative Variable",
    "section": "stat_ecdf(geom = )",
    "text": "stat_ecdf(geom = )\nWe could do this with most geometries. I will show a few.\n\nstat_ecdf(geom = \"step\")\n\nBonds %>%\n    ggplot(aes(x = Assets)) + stat_ecdf(geom = \"point\") + stat_ecdf(geom = \"step\",\n    alpha = 0.1) + labs(y = \"ECDF: Proportion less than Assets\") + theme_minimal()\n\n\n\n\n\n\nstat_ecdf(geom = \"point\")\n\nBonds %>%\n    ggplot(aes(x = Assets)) + stat_ecdf(geom = \"point\") + stat_ecdf(geom = \"step\",\n    alpha = 0.1) + labs(y = \"ECDF: Proportion less than Assets\") + theme_minimal()\n\n\n\n\n\n\nCombining two\n\nBonds %>%\n    ggplot(aes(x = Assets)) + stat_ecdf(geom = \"point\") + stat_ecdf(geom = \"step\",\n    alpha = 0.1) + labs(y = \"ECDF: Proportion less than Assets\") + theme_minimal()\n\n\n\n\n\n\nstat_ecdf(geom = \"line\")\n\nBonds %>%\n    ggplot(aes(x = Assets)) + stat_ecdf(geom = \"line\") + labs(y = \"ECDF: Proportion less than Assets\") +\n    theme_minimal()\n\n\n\n\n\n\nstat_ecdf(geom = \"area\")\n\nBonds %>%\n    ggplot(aes(x = Assets)) + stat_ecdf(geom = \"area\", alpha = 0.2) + labs(y = \"ECDF: Proportion less than Assets\") +\n    theme_minimal()"
  },
  {
    "objectID": "posts/visualizing-one-quantitative-variable/index.html#geom_boxplot-1",
    "href": "posts/visualizing-one-quantitative-variable/index.html#geom_boxplot-1",
    "title": "Visualizing One Quantitative Variable",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\nA boxplot is a method for visualizing the five-number summary that we deploy to summarise asymmetric quantitative data. The technical name is a box-and-whisker plot. The outer edges of the box provide visual representation of the first [\\(25^{th}\\) percentile] and third quartiles [\\(75^{th}\\) percentile]. The whiskers extend out, by default, to represent 1.5 times the interquartile range. Anything outside of the whiskers could be classified as an outlier, this definition originally owes, as far as I know, to John Tukey, and is often referred to as Tukey’s rule. If one wished to adjust this, the argument is coef=.\n\nBonds %>%\n    ggplot() + aes(x = Return.2009) + geom_boxplot()\n\n\n\n\nI do not like the default y-axis because it is completely meaningless. Some call this chart junk. To remove it, I will need to cancel the two key elements of the y-axis, the labels and the breaks. I will add a minimal theme.\n\nBonds %>%\n    ggplot() + aes(x = Return.2009) + geom_boxplot() + scale_y_discrete(labels = NULL,\n    breaks = NULL) + labs(y = \"\") + theme_minimal()\n\n\n\n\nThough we often think about aesthetics as functions of data, they can be set to constant in cases that make sense. For example, suppose I want to color the lines of the boxplot; that’s color (rather than fill).\n\nBonds %>%\n    ggplot() + aes(x = Return.2009) + geom_boxplot(color = \"black\", fill = \"grey50\") +\n    scale_y_discrete(labels = NULL, breaks = NULL) + labs(y = \"\") + theme_minimal()"
  },
  {
    "objectID": "posts/wrangling-tutorials/index.html",
    "href": "posts/wrangling-tutorials/index.html",
    "title": "Tutorials on Wrangling",
    "section": "",
    "text": "An excellent collection of data wrangling tutorials\nIf you have not already, at the R Console, install learnr\ninstall.packages(\"learnr\")\nThis should make a Tutorial pane available in the RStudio. You can start the tutorials from within RStudio.\nThere’s a nice web collection of tutorials on the rstudio learnr site on github: Examples"
  },
  {
    "objectID": "posts/acfs-horst/index.html",
    "href": "posts/acfs-horst/index.html",
    "title": "the clock package: a c port",
    "section": "",
    "text": "the clock package\nThe main page for the just-released clock package by Davis Vaughan is linked. This is a supplement to lubridate that handles a number of special cases with native C++ date/time structures instead of R’s date classes. There are many date and time edge cases and clock allows them to be handled in a systematic and consistent way. There are some useful vignettes for illustration.\n\nGetting Started\nMotivations for clock\nFrequently Asked Questions\n\nThe full function reference\nHere is the package website."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to the FAQ for DADM",
    "section": "",
    "text": "Setting Up\n\nTo hit the ground running, you will probably need two key bits of software: R and RStudio. To wit,\n\nIf you prefer something like VSCode or another IDE, that is your choice. I will heavily utilize RMarkdown and quarto and both are extensively supported in RStudio. The most recent version of RStudio can be obtained here\n\\(R\\) can be obtained from the Comprehensive R Archive Network – CRAN for just about all non-mobile OS’s. If you work on a Mac, do make sure that you acquire the one for the specific Mac that you have, e.g. Intel Mac or Apple Silicon [ARM64]"
  },
  {
    "objectID": "posts/default-ggplot-theme-set/index.html",
    "href": "posts/default-ggplot-theme-set/index.html",
    "title": "Changing the Default ggplot theme",
    "section": "",
    "text": "One can globally set the theme in an RMarkdown or Quarto Markdown document with theme_set(). If run at the console, every subsequent ggplot invocation will default to that theme. If set inside an R/Qmd file, then it will apply to everything in the file. First, let me load ggplot."
  },
  {
    "objectID": "posts/default-ggplot-theme-set/index.html#the-cars-data",
    "href": "posts/default-ggplot-theme-set/index.html#the-cars-data",
    "title": "Changing the Default ggplot theme",
    "section": "The cars data",
    "text": "The cars data\nI will use R’s internal cars dataset to illustrate. This is the data; ?cars will detail the variables.\n\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85"
  },
  {
    "objectID": "posts/default-ggplot-theme-set/index.html#a-plot-with-defaults",
    "href": "posts/default-ggplot-theme-set/index.html#a-plot-with-defaults",
    "title": "Changing the Default ggplot theme",
    "section": "A plot with defaults",
    "text": "A plot with defaults\n\nggplot(cars) + aes(x=speed, y=dist) + geom_point()"
  },
  {
    "objectID": "posts/default-ggplot-theme-set/index.html#setting-a-default-theme",
    "href": "posts/default-ggplot-theme-set/index.html#setting-a-default-theme",
    "title": "Changing the Default ggplot theme",
    "section": "Setting a default theme",
    "text": "Setting a default theme\nLet me set the theme for this to theme_minimal.\n\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "posts/default-ggplot-theme-set/index.html#the-same-plot-with-a-new-default-theme",
    "href": "posts/default-ggplot-theme-set/index.html#the-same-plot-with-a-new-default-theme",
    "title": "Changing the Default ggplot theme",
    "section": "The Same Plot with a New Default Theme",
    "text": "The Same Plot with a New Default Theme\n\nggplot(cars) + aes(x=speed, y=dist) + geom_point()"
  },
  {
    "objectID": "posts/timetk-is-awesome/index.html",
    "href": "posts/timetk-is-awesome/index.html",
    "title": "timetk is really, really handy",
    "section": "",
    "text": "The timetk or time toolkit package for R provides a glorious complementary fork to the tsibble adopted in the FPP 3 text [and the preceding forecast package built around fpp2]. If you want to know about time series data types, I cannot stress how useful and complete the vignette on time series coercion that is written intothe documentation for timetk\n\n\nWrangling is tidy and some of the things that you may have found frustrating about aggregation before may make more sense when shown using this approach. For example, we needed effort to massage daily data on equities, that’s a specific function of the indexing in a daily time series where markets are closed on weekends. Time needs to be redefined. Questions like this get some attention here\n\n\n\nThis function allow you easily aggregate data.frame data with the declaration of a time variable. Elsewhere, I have an example of pivoting data from wide to long. It is very handy.\n\nlibrary(tidyverse)\nNWS <- read.csv(\n  url(\"https://www.weather.gov/source/pqr/climate/webdata/Portland_dailyclimatedata.csv\"), \n                skip=6, \n                na.strings = c(\"M\",\"-\", \"\")) %>% \n  rename(Variable = X) %>%\n  mutate(across(where(is.character), \n                ~str_remove(.x, \"/A\"))) %>%\n  filter(!(MO==1 & YR==2020))\nlibrary(magrittr)\n# I really like the magrittr %<>% pipe for updating data during cleaning\n# Start the daily data\nNWS.Daily <- NWS %>% select(-AVG.or.Total)\n# Rename the columns because Variable is actually X\nnames(NWS.Daily) <- c(\"YR\",\"MO\",\"Variable\",paste0(\"Day.\",1:31))\n# Create the daily data frame though it contains days that do not actually exist. \n# Every month nominally has 31 days.\nNWS.DF <- NWS.Daily %>% \n  pivot_longer(., cols=starts_with(\"Day.\"), names_to = \"Day\", values_to = \"value\") %>% \n  mutate(Day = str_remove(Day, \"Day.\"))\nNWS.DF %<>% pivot_wider(., names_from = \"Variable\", values_from = \"value\")\nNWS.DF %<>% mutate(date = as.Date(paste(MO,Day,YR,sep=\"-\"), format=\"%m-%d-%Y\"))\nNWS.DF$SN[NWS.DF$date==as.Date(\"1978-12-07\")] <- 0\nNWS.DF %<>% \n  mutate(PR = recode(PR, T = \"0.005\"), \n         SN = recode(SN, T = \"0.005\")) %>%\n  mutate(High = as.numeric(TX), \n         Low = as.numeric(TN), \n         Precipitation = as.numeric(PR), \n         Snow = as.numeric(SN)\n         ) %>%\n    select(date, High, Low, Precipitation, Snow)\nlibrary(kableExtra)\nhead(NWS.DF, n=40) %>% kable() %>% scroll_box(width=\"600px\", height=\"400px\")\n\n\n\n \n  \n    date \n    High \n    Low \n    Precipitation \n    Snow \n  \n \n\n  \n    1940-10-01 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-02 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-03 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-04 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-05 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-06 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-07 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-08 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-09 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-10 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-11 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-12 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    1940-10-13 \n    75 \n    57 \n    0.010 \n    0 \n  \n  \n    1940-10-14 \n    70 \n    53 \n    0.005 \n    0 \n  \n  \n    1940-10-15 \n    64 \n    52 \n    0.005 \n    0 \n  \n  \n    1940-10-16 \n    72 \n    50 \n    0.000 \n    0 \n  \n  \n    1940-10-17 \n    72 \n    58 \n    0.130 \n    0 \n  \n  \n    1940-10-18 \n    78 \n    58 \n    0.000 \n    0 \n  \n  \n    1940-10-19 \n    78 \n    59 \n    0.005 \n    0 \n  \n  \n    1940-10-20 \n    64 \n    54 \n    0.140 \n    0 \n  \n  \n    1940-10-21 \n    63 \n    48 \n    0.050 \n    0 \n  \n  \n    1940-10-22 \n    61 \n    41 \n    0.000 \n    0 \n  \n  \n    1940-10-23 \n    58 \n    53 \n    0.630 \n    0 \n  \n  \n    1940-10-24 \n    57 \n    48 \n    1.030 \n    0 \n  \n  \n    1940-10-25 \n    57 \n    41 \n    0.000 \n    0 \n  \n  \n    1940-10-26 \n    57 \n    38 \n    0.000 \n    0 \n  \n  \n    1940-10-27 \n    56 \n    37 \n    0.005 \n    0 \n  \n  \n    1940-10-28 \n    53 \n    45 \n    0.180 \n    0 \n  \n  \n    1940-10-29 \n    59 \n    48 \n    0.580 \n    0 \n  \n  \n    1940-10-30 \n    59 \n    50 \n    0.500 \n    0 \n  \n  \n    1940-10-31 \n    52 \n    46 \n    0.250 \n    0 \n  \n  \n    1940-11-01 \n    52 \n    40 \n    0.170 \n    0 \n  \n  \n    1940-11-02 \n    53 \n    38 \n    0.020 \n    0 \n  \n  \n    1940-11-03 \n    47 \n    36 \n    0.005 \n    0 \n  \n  \n    1940-11-04 \n    55 \n    32 \n    0.000 \n    0 \n  \n  \n    1940-11-05 \n    51 \n    42 \n    0.070 \n    0 \n  \n  \n    1940-11-06 \n    58 \n    46 \n    0.280 \n    0 \n  \n  \n    1940-11-07 \n    56 \n    46 \n    0.850 \n    0 \n  \n  \n    1940-11-08 \n    50 \n    42 \n    0.290 \n    0 \n  \n  \n    1940-11-09 \n    48 \n    35 \n    0.020 \n    0 \n  \n\n\n\n\n\n\n\n\nThis would normally be a pain; timetk makes it easy. I want to aggregate them by the last period of whatever month it happens to be.\n\nlibrary(timetk)\nNWS.Analysis.M <- NWS.DF %>% condense_period(., date, .period=\"1 month\", .side=\"end\")\n\n\n\n\n\nlibrary(fpp3)\n\n── Attaching packages ──────────────────────────────────────────── fpp3 0.4.0 ──\n\n\n✔ lubridate   1.9.0     ✔ feasts      0.3.0\n✔ tsibble     1.1.3     ✔ fable       0.3.2\n✔ tsibbledata 0.4.1     \n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()        masks base::date()\n✖ magrittr::extract()      masks tidyr::extract()\n✖ dplyr::filter()          masks stats::filter()\n✖ kableExtra::group_rows() masks dplyr::group_rows()\n✖ tsibble::intersect()     masks base::intersect()\n✖ tsibble::interval()      masks lubridate::interval()\n✖ dplyr::lag()             masks stats::lag()\n✖ magrittr::set_names()    masks purrr::set_names()\n✖ tsibble::setdiff()       masks base::setdiff()\n✖ tsibble::union()         masks base::union()\n\nNWS.TS.M <- NWS.Analysis.M %>% mutate(YM=yearmonth(date)) %>% as_tsibble(index=YM)\nNWS.Analysis.M %>%\n  mutate(YM=yearmonth(date)) %>%\n  select(YM, High, Low) %>%\n  pivot_longer(c(High, Low)) %>%\n  mutate(Temperature=name) %>%\n  select(-name) %>%\n  as_tsibble(index=YM, key=Temperature) %>%\n  autoplot(value, alpha=0.3) + \n  labs(title=\"High and Low Temperatures in Portland, Oregon\",\n       x = \"Month\",\n       y = \"Temperature (F)\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/R-RStudio/index.html",
    "href": "posts/R-RStudio/index.html",
    "title": "Getting Started: R and RStudio",
    "section": "",
    "text": "The following tutorial contains instructions and a video walk through for installing R, RStudio, and the tidyverse – an R verse consisting of a few packages that ease data importation, management (including dates and categorical variables), wrangling, and visualization.\nYou can find R from here by navigating in accordance with your operating system. If you work on a Mac, be careful about the different versions that depend on the underlying hardward [Apple Silicon (ARM64) versus Intel Macs] Link\nIf you skip the above step, the download page for RStudio will remind you that you RStudio requires R. The download page can be found here."
  },
  {
    "objectID": "posts/visualizing-two-quantities/index.html",
    "href": "posts/visualizing-two-quantities/index.html",
    "title": "Visualizing Two Quantitative Variables",
    "section": "",
    "text": "A dataset for illustrating the various available visualizations needs a certain degree of richness with manageable size. The dataset on Bonds contains three categorical and a few quantitative indicators sufficient to show what we might wish.\n\n\n\nBonds <- read.csv(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/BondFunds.csv\"))\n\n\n\n\n\nlibrary(skimr)\nBonds %>%\n    skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFund.Number\n0\n1\n4\n6\n0\n184\n0\n\n\nType\n0\n1\n20\n23\n0\n2\n0\n\n\nFees\n0\n1\n2\n3\n0\n2\n0\n\n\nRisk\n0\n1\n7\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAssets\n0\n1\n910.65\n2253.27\n12.40\n113.72\n268.4\n621.95\n18603.50\n▇▁▁▁▁\n\n\nExpense.Ratio\n0\n1\n0.71\n0.26\n0.12\n0.53\n0.7\n0.90\n1.94\n▂▇▅▁▁\n\n\nReturn.2009\n0\n1\n7.16\n6.09\n-8.80\n3.48\n6.4\n10.72\n32.00\n▁▇▅▁▁\n\n\nX3.Year.Return\n0\n1\n4.66\n2.52\n-13.80\n4.05\n5.1\n6.10\n9.40\n▁▁▁▅▇\n\n\nX5.Year.Return\n0\n1\n3.99\n1.49\n-7.30\n3.60\n4.3\n4.90\n6.80\n▁▁▁▅▇\n\n\n\n\n\nMost data types are represented. There is no time variable so dates and the visualizations that go with time series are omitted."
  },
  {
    "objectID": "posts/visualizing-two-quantities/index.html#geom_point",
    "href": "posts/visualizing-two-quantities/index.html#geom_point",
    "title": "Visualizing Two Quantitative Variables",
    "section": "geom_point()",
    "text": "geom_point()\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009) + geom_point()\n\n\n\n\n\nA little better: theming\nI do not like the default theme.\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009) + geom_point() + theme_minimal()"
  },
  {
    "objectID": "posts/visualizing-two-quantities/index.html#fixing-overplotting",
    "href": "posts/visualizing-two-quantities/index.html#fixing-overplotting",
    "title": "Visualizing Two Quantitative Variables",
    "section": "Fixing Overplotting",
    "text": "Fixing Overplotting\nggplot has an alternative geometry known as geom_jitter() that jitters – adds arbitrarily small amounts to the x and y coordinates.\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009) + geom_jitter() + theme_minimal()\n\n\n\n\nThe two controls for the jitter are width:\n\n\n\nwidth\n\n\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009) + geom_jitter(width = 0.25) + theme_minimal()\n\n\n\n\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009) + geom_jitter(height = 0.25) + theme_minimal()\n\n\n\n\nand the height\n ## Some other elements\nSince I am going to work with Risk, let’s try that in color.\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009, color = Risk) + geom_point() + theme_minimal()"
  },
  {
    "objectID": "posts/visualizing-two-quantities/index.html#a-bubble-plot",
    "href": "posts/visualizing-two-quantities/index.html#a-bubble-plot",
    "title": "Visualizing Two Quantitative Variables",
    "section": "A bubble plot?",
    "text": "A bubble plot?\nNow I will put Risk on x and Returns on y with the size of the bubble determined by Assets. First, without jitter.\n\nBonds %>%\n    ggplot() + aes(x = Risk, y = Return.2009, size = Assets, color = Risk) + geom_point() +\n    theme_minimal() + guides(color = \"none\")\n\n\n\n\n\nBonds %>%\n    ggplot() + aes(x = Risk, y = Return.2009, color = Risk, size = Assets) + geom_jitter(width = 0.45) +\n    theme_minimal() + guides(color = \"none\")"
  },
  {
    "objectID": "posts/visualizing-two-quantities/index.html#deploying-facets",
    "href": "posts/visualizing-two-quantities/index.html#deploying-facets",
    "title": "Visualizing Two Quantitative Variables",
    "section": "Deploying Facets",
    "text": "Deploying Facets\n\nBonds %>%\n    ggplot() + aes(x = Assets, y = Return.2009, color = Risk, facet = Risk) + geom_point() +\n    theme_minimal() + guides(color = \"none\") + facet_wrap(~Risk)"
  },
  {
    "objectID": "posts/pivots/index.html",
    "href": "posts/pivots/index.html",
    "title": "Pivoting Data: Long and Wide",
    "section": "",
    "text": "The ability to pivot data from long to wide format or from wide to long format is one of the greatest time saving devices that I know of. Let’s first look at the data types: wide and long.\n\n\nI will use climate data covering the city of Portland from the National Weather Service. [The data were obtained from:] (https://w2.weather.gov/climate/local_data.php?wfo=pqr) and you will notice that there are data for Astoria, Salem and Eugene, also. Notice this is the Local Data and Records tab.\n\n\n\nScreenShot\n\n\nI downloaded the Portland data and examined the spreadsheet. It has a rather straightforward wide structure – it has data in the column names. Other common examples are accounting data with the variables listed as rows and the time periods as the columns.\n\n\n\nNWS Spreadsheet\n\n\nThere are a few rows describing the data that will have to be eliminated to import the data; that’s the skip flag so I will use skip=6. If we examine row 7, we will see what will become the variable names. YR and MO are year and month, respectively, there is then a blank and the remaining names are the day; it extends to 31. For each month, there are four rows representing the high TX, the low TN, precipitation PR, and snow SN. Scrolling rightward, we see the remainder of the spreadsheet from the image above; there is also an AVG or Total column.\n\n\n\nNWS Spreadsheet\n\n\nWere I to import them as is, let’s see what happens just skipping the first six rows. I will use the gt package to show what I have.\n\nlibrary(tidyverse)\nlibrary(gt)\nNWS <- read.csv(url(\"https://www.weather.gov/source/pqr/climate/webdata/Portland_dailyclimatedata.csv\"), skip=6)\nhead(NWS, 10) %>% gt()\n\n\n\n\n\n  \n  \n    \n      YR\n      MO\n      X\n      X1\n      X2\n      X3\n      X4\n      X5\n      X6\n      X7\n      X8\n      X9\n      X10\n      X11\n      X12\n      X13\n      X14\n      X15\n      X16\n      X17\n      X18\n      X19\n      X20\n      X21\n      X22\n      X23\n      X24\n      X25\n      X26\n      X27\n      X28\n      X29\n      X30\n      X31\n      AVG.or.Total\n    \n  \n  \n    1940\n10\nTX\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\n75\n70\n64\n72\n72\n78\n78\n64\n63\n61\n58\n57\n57\n57\n56\n53\n59\n59\n52\nM\n    1940\n10\nTN\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\n57\n53\n52\n50\n58\n58\n59\n54\n48\n41\n53\n48\n41\n38\n37\n45\n48\n50\n46\nM\n    1940\n10\nPR\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\n0.01\nT\nT\n0\n0.13\n0\nT\n0.14\n0.05\n0\n0.63\n1.03\n0\n0\nT\n0.18\n0.58\n0.5\n0.25\nM\n    1940\n10\nSN\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\nM\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    1940\n11\nTX\n52\n53\n47\n55\n51\n58\n56\n50\n48\n47\n46\n45\n45\n47\n53\n49\n46\n49\n46\n49\n50\n44\n42\n44\n51\n44\n45\n59\n57\n45\n-\n49.1\n    1940\n11\nTN\n40\n38\n36\n32\n42\n46\n46\n42\n35\n34\n35\n33\n34\n33\n28\n27\n36\n30\n29\n36\n33\n28\n37\n35\n37\n36\n38\n43\n40\n39\n-\n35.9\n    1940\n11\nPR\n0.17\n0.02\nT\n0\n0.07\n0.28\n0.85\n0.29\n0.02\n0.01\n0.01\n0\n0\n0\n0\n0\n0.29\n0.01\n0\n0.37\nT\n0\n0.12\n0.62\n0\n0\n0.51\n0.89\nT\nT\n-\n4.53\n    1940\n11\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n-\n0\n    1940\n12\nTX\n51\n53\n52\n51\n56\n54\n50\n51\n48\n50\n46\n45\n43\n40\n39\n39\n41\n41\n45\n46\n62\n60\n56\n53\n54\n45\n50\n51\n43\n44\n45\n48.5\n    1940\n12\nTN\n42\n40\n42\n42\n44\n37\n34\n35\n32\n26\n34\n28\n27\n25\n29\n33\n35\n34\n35\n41\n39\n39\n42\n42\n42\n40\n38\n36\n35\n37\n32\n36\n  \n  \n  \n\n\n\n\nThat is a pretty good start. There are a few types of missing data (the M values) and some conversions to consider before I can start. There are some - for days that do not exist. T stands for Trace amount, the lowest recorded numeric values are 0.01 inches. There are also values labelled as T/A which I assume to be Trace/Accumulation because there is no obvious dictionary describing their exact meanings.\nLet’s start by reflecting a skip of the first six rows and two sets of missing values, M and -. I also want to rename the column that has no name in the original spreadsheet to be Variable because this is that column reflecting which of the four actual variables that we have for the month-year combination.\n\nNWS <- read.csv(url(\"https://www.weather.gov/source/pqr/climate/webdata/Portland_dailyclimatedata.csv\"), \n                skip=6, \n                na.strings = c(\"M\",\"-\", \"\")) %>% \n  rename(Variable = X)\nhead(NWS, 10) %>% gt()\n\n\n\n\n\n  \n  \n    \n      YR\n      MO\n      Variable\n      X1\n      X2\n      X3\n      X4\n      X5\n      X6\n      X7\n      X8\n      X9\n      X10\n      X11\n      X12\n      X13\n      X14\n      X15\n      X16\n      X17\n      X18\n      X19\n      X20\n      X21\n      X22\n      X23\n      X24\n      X25\n      X26\n      X27\n      X28\n      X29\n      X30\n      X31\n      AVG.or.Total\n    \n  \n  \n    1940\n10\nTX\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n75\n70\n64\n72\n72\n78\n78\n64\n63\n61\n58\n57\n57\n57\n56\n53\n59\n59\n52\nNA\n    1940\n10\nTN\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n57\n53\n52\n50\n58\n58\n59\n54\n48\n41\n53\n48\n41\n38\n37\n45\n48\n50\n46\nNA\n    1940\n10\nPR\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.01\nT\nT\n0\n0.13\n0\nT\n0.14\n0.05\n0\n0.63\n1.03\n0\n0\nT\n0.18\n0.58\n0.5\n0.25\nNA\n    1940\n10\nSN\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    1940\n11\nTX\n52\n53\n47\n55\n51\n58\n56\n50\n48\n47\n46\n45\n45\n47\n53\n49\n46\n49\n46\n49\n50\n44\n42\n44\n51\n44\n45\n59\n57\n45\nNA\n49.1\n    1940\n11\nTN\n40\n38\n36\n32\n42\n46\n46\n42\n35\n34\n35\n33\n34\n33\n28\n27\n36\n30\n29\n36\n33\n28\n37\n35\n37\n36\n38\n43\n40\n39\nNA\n35.9\n    1940\n11\nPR\n0.17\n0.02\nT\n0\n0.07\n0.28\n0.85\n0.29\n0.02\n0.01\n0.01\n0\n0\n0\n0\n0\n0.29\n0.01\n0\n0.37\nT\n0\n0.12\n0.62\n0\n0\n0.51\n0.89\nT\nT\nNA\n4.53\n    1940\n11\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNA\n0\n    1940\n12\nTX\n51\n53\n52\n51\n56\n54\n50\n51\n48\n50\n46\n45\n43\n40\n39\n39\n41\n41\n45\n46\n62\n60\n56\n53\n54\n45\n50\n51\n43\n44\n45\n48.5\n    1940\n12\nTN\n42\n40\n42\n42\n44\n37\n34\n35\n32\n26\n34\n28\n27\n25\n29\n33\n35\n34\n35\n41\n39\n39\n42\n42\n42\n40\n38\n36\n35\n37\n32\n36\n  \n  \n  \n\n\n\n\nI can handle the T/A values by just removing the /A that appears in a few places.\n\nNWS <- NWS %>% \n  mutate(across(where(is.character), \n                ~str_remove(.x, \"/A\")))\n\nThe T values still exist and but this will be enough to avail us of easy access to some monthly data for a first pivot example after eliminating one additional problem. The data end in December 2019.\n\nNWS %>% tail(n = 10) %>% gt()\n\n\n\n\n\n  \n  \n    \n      YR\n      MO\n      Variable\n      X1\n      X2\n      X3\n      X4\n      X5\n      X6\n      X7\n      X8\n      X9\n      X10\n      X11\n      X12\n      X13\n      X14\n      X15\n      X16\n      X17\n      X18\n      X19\n      X20\n      X21\n      X22\n      X23\n      X24\n      X25\n      X26\n      X27\n      X28\n      X29\n      X30\n      X31\n      AVG.or.Total\n    \n  \n  \n    2019\n11\nPR\n0\n0\n0\n0\nT\n0\n0\n0\n0.19\n0.05\n0\n0.17\n0\n0\n0.13\nT\n0.08\n0.11\n0.49\n0\n0\n0\n0\n0.16\n0.05\n0.09\n0\n0\n0\nT\nNA\n1.52\n    2019\n11\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nT\nNA\nT\n    2019\n12\nTX\n43\n47\n49\n50\n53\n50\n46\n53\n49\n45\n47\n54\n49\n47\n44\n48\n42\n43\n57\n59\n51\n46\n48\n40\n44\n46\n45\n48\n48\n48\n51\n48.1\n    2019\n12\nTN\n35\n30\n32\n38\n39\n38\n43\n45\n38\n38\n42\n45\n40\n40\n37\n36\n35\n32\n38\n50\n43\n42\n35\n32\n31\n27\n37\n40\n40\n40\n40\n38\n    2019\n12\nPR\n0.12\n0\n0\nT\n0\n0.25\n0.46\nT\n0\n0.32\n0.29\n0.31\n0\n0.03\n0\nT\n0\n0.18\n0.64\n0.4\n0.88\n0.17\n0.09\nT\n0.02\nT\n0.01\n0\nT\n0\n0.22\n4.39\n    2019\n12\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    2020\n1\nTX\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2020\n1\nTN\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2020\n1\nPR\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n    2020\n1\nSN\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n  \n  \n  \n\n\n\n\nI want to filter those rows out.\n\nNWS <- NWS %>% filter(!(MO==1 & YR==2020)) \nNWS %>% tail(n=10) %>% gt()\n\n\n\n\n\n  \n  \n    \n      YR\n      MO\n      Variable\n      X1\n      X2\n      X3\n      X4\n      X5\n      X6\n      X7\n      X8\n      X9\n      X10\n      X11\n      X12\n      X13\n      X14\n      X15\n      X16\n      X17\n      X18\n      X19\n      X20\n      X21\n      X22\n      X23\n      X24\n      X25\n      X26\n      X27\n      X28\n      X29\n      X30\n      X31\n      AVG.or.Total\n    \n  \n  \n    2019\n10\nPR\n0\nT\n0.02\n0.06\n0\n0\n0.08\n0.02\n0\n0\nT\n0\n0\n0\nT\n0.37\n0.28\n0.02\n0.43\n0.03\n0.01\n0.15\n0\n0\n0.04\nT\n0\n0\nT\n0\n0\n1.51\n    2019\n10\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    2019\n11\nTX\n62\n63\n59\n54\n49\n66\n62\n62\n51\n55\n62\n52\n53\n57\n58\n56\n56\n58\n55\n58\n57\n50\n50\n51\n51\n44\n47\n44\n45\n45\nNA\n54.4\n    2019\n11\nTN\n31\n33\n37\n37\n35\n43\n37\n37\n40\n48\n44\n45\n44\n43\n44\n46\n49\n52\n47\n40\n34\n32\n31\n40\n41\n41\n37\n37\n26\n26\nNA\n39.2\n    2019\n11\nPR\n0\n0\n0\n0\nT\n0\n0\n0\n0.19\n0.05\n0\n0.17\n0\n0\n0.13\nT\n0.08\n0.11\n0.49\n0\n0\n0\n0\n0.16\n0.05\n0.09\n0\n0\n0\nT\nNA\n1.52\n    2019\n11\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nT\nNA\nT\n    2019\n12\nTX\n43\n47\n49\n50\n53\n50\n46\n53\n49\n45\n47\n54\n49\n47\n44\n48\n42\n43\n57\n59\n51\n46\n48\n40\n44\n46\n45\n48\n48\n48\n51\n48.1\n    2019\n12\nTN\n35\n30\n32\n38\n39\n38\n43\n45\n38\n38\n42\n45\n40\n40\n37\n36\n35\n32\n38\n50\n43\n42\n35\n32\n31\n27\n37\n40\n40\n40\n40\n38\n    2019\n12\nPR\n0.12\n0\n0\nT\n0\n0.25\n0.46\nT\n0\n0.32\n0.29\n0.31\n0\n0.03\n0\nT\n0\n0.18\n0.64\n0.4\n0.88\n0.17\n0.09\nT\n0.02\nT\n0.01\n0\nT\n0\n0.22\n4.39\n    2019\n12\nSN\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n  \n  \n  \n\n\n\n\nFrom here I should be able to build some monthly data.\n\n\n\nI want to pick out four columns from which to build dates for the data; let’s work on a monthly time series. Because the sum or average is already a column, I do not need to create it. I only need select it.\n\n# Now to create a Monthly time series.\nNWS.Monthly.Base <- NWS %>% \n  select(YR, MO, Variable, AVG.or.Total)\n\nI will use a pipe from the magrittr package to reduce typing. %<>% substitutes for a combination of <- and %>% to update the object that I am operating on. I have some character values in that column and the original picture of the wide end of the data shows a missing average/total for October 1940; the T values are replaced by 0.005.\n\nlibrary(magrittr)\nNWS.Monthly.Base %<>% filter(!(MO==10 & YR==1940)) %>%\n  mutate(AVG.or.Total = recode(AVG.or.Total, T = \"0.005\"))\n\nFrom there, I will use pivot_wider to move Variable to columns and their names and taking the values of each from the average/total column. How does it look?\n\nNWS.Monthly.Tidy <- NWS.Monthly.Base %>%  \n  pivot_wider(names_from = \"Variable\", \n              values_from = \"AVG.or.Total\")\nNWS.Monthly.Tidy %>% head() %>% gt()\n\n\n\n\n\n  \n  \n    \n      YR\n      MO\n      TX\n      TN\n      PR\n      SN\n    \n  \n  \n    1940\n11\n49.1\n35.9\n4.53\n0\n    1940\n12\n48.5\n36\n4.85\n0\n    1941\n1\n47.4\n35.2\n5.27\n0\n    1941\n2\n55.1\n37.1\n1.59\n0\n    1941\n3\n63.5\n40.6\n1.74\n0\n    1941\n4\n65.8\n43.1\n1.66\n0\n  \n  \n  \n\n\n\n\nLet me put together a date using paste and lubridate’s year-month format.\n\nlibrary(lubridate)\nNWS.Monthly.Tidy %<>%  mutate(Month.Yr =\n                                ym(paste(YR,MO, sep=\"-\")))\n\nWhat about turning them numeric?\n\nNWS.Monthly.Tidy %<>%  mutate(High = as.numeric(TX), \n         Low = as.numeric(TN), \n         Precipitation = as.numeric(PR), \n         Snow = as.numeric(SN)\n         ) %>%\n  select(Month.Yr, High, Low, Precipitation, Snow)\nNWS.Monthly.Tidy %>% head(n=10) %>% gt()\n\n\n\n\n\n  \n  \n    \n      Month.Yr\n      High\n      Low\n      Precipitation\n      Snow\n    \n  \n  \n    1940-11-01\n49.1\n35.9\n4.53\n0\n    1940-12-01\n48.5\n36.0\n4.85\n0\n    1941-01-01\n47.4\n35.2\n5.27\n0\n    1941-02-01\n55.1\n37.1\n1.59\n0\n    1941-03-01\n63.5\n40.6\n1.74\n0\n    1941-04-01\n65.8\n43.1\n1.66\n0\n    1941-05-01\n67.1\n48.1\n4.27\n0\n    1941-06-01\n71.6\n52.6\n0.81\n0\n    1941-07-01\n84.5\n58.3\n0.03\n0\n    1941-08-01\n77.6\n58.0\n1.45\n0\n  \n  \n  \n\n\n\n\nThat’s exactly what I need. To treat it as a functional time series, let me deploy the fpp3 package, tsibble requires the specification of a time index and these are monthly data but they are tidy, rows represent the units [periods of time] and the columns are variables. This is a time series because one of them is time.\n\nlibrary(fpp3)\nNWS.Monthly.TS <- NWS.Monthly.Tidy %>% \n  mutate(YM = yearmonth(Month.Yr)) %>%\n  as_tsibble(index=YM)\n\nTo see the fluctuation in high and low temperatures from 2000 to 2019, we can show it.\n\nlibrary(hrbrthemes)\nNWS.Monthly.TS %>% \n  filter(Month.Yr > as.Date(\"2000-01-01\")) %>% \n  ggplot() + \n  aes(x=YM) + \n  geom_ribbon(aes(ymin=Low, ymax=High), alpha=0.5) + \n  theme_ipsum() +\n  labs(title=\"Monthly Temperature Range in Portland\",\n       x=\"Month\")\n\n\n\n\nBecause it is enabled, what does the STL decomposition suggest for temperature change; let’s look at the high temperatures.\n\nNWS.Monthly.TS %>% \n  model(STL(High ~ season(period=\"1 year\") + trend(window=30, degree=0))) %>% \n  components() %>% \n  autoplot()\n\n\n\n\n\n\nThe key feature is spreading out the row for each initial variable in the pivot command and then clearing out the messy values. To turn it into a monthly time series, fpp3 has the yearmonth data structure.\n\n\n\n\nLet me start with the original data and a single column omission, I want to get rid of the monthly total/average column and start some daily data.\n\nNWS.Daily <- NWS %>% select(-AVG.or.Total)\nnames(NWS.Daily) <- c(\"YR\",\"MO\",\"Variable\",paste0(\"Day.\",1:31))\nhead(NWS.Daily)\n\n    YR MO Variable Day.1 Day.2 Day.3 Day.4 Day.5 Day.6 Day.7 Day.8 Day.9 Day.10\n1 1940 10       TX  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>   <NA>\n2 1940 10       TN  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>   <NA>\n3 1940 10       PR  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>   <NA>\n4 1940 10       SN  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>   <NA>\n5 1940 11       TX    52    53    47    55    51    58    56    50    48     47\n6 1940 11       TN    40    38    36    32    42    46    46    42    35     34\n  Day.11 Day.12 Day.13 Day.14 Day.15 Day.16 Day.17 Day.18 Day.19 Day.20 Day.21\n1   <NA>   <NA>     75     70     64     72     72     78     78     64     63\n2   <NA>   <NA>     57     53     52     50     58     58     59     54     48\n3   <NA>   <NA>   0.01      T      T      0   0.13      0      T   0.14   0.05\n4   <NA>   <NA>      0      0      0      0      0      0      0      0      0\n5     46     45     45     47     53     49     46     49     46     49     50\n6     35     33     34     33     28     27     36     30     29     36     33\n  Day.22 Day.23 Day.24 Day.25 Day.26 Day.27 Day.28 Day.29 Day.30 Day.31\n1     61     58     57     57     57     56     53     59     59     52\n2     41     53     48     41     38     37     45     48     50     46\n3      0   0.63   1.03      0      0      T   0.18   0.58    0.5   0.25\n4      0      0      0      0      0      0      0      0      0      0\n5     44     42     44     51     44     45     59     57     45   <NA>\n6     28     37     35     37     36     38     43     40     39   <NA>\n\n\nWe can pivot this with the new name variable to be called Day and the value of the four rows to value. I also want to extract the number at the end of the Day.\n\nNWS.Daily <- NWS.Daily %>% \n  pivot_longer(., cols=starts_with(\"Day.\"), names_to = \"Day\", values_to = \"value\") %>% \n  mutate(Day = str_remove(Day, \"Day.\"))\n\nNow I want to partially pivot the data back to wider formats. In this case, the names of the new columns need to represent the four variables with the values coming from value. Let’s try it out.\n\nNWS.Daily %<>% pivot_wider(., names_from = \"Variable\", values_from = \"value\")\nhead(NWS.Daily)\n\n# A tibble: 6 × 7\n     YR    MO Day   TX    TN    PR    SN   \n  <int> <int> <chr> <chr> <chr> <chr> <chr>\n1  1940    10 1     <NA>  <NA>  <NA>  <NA> \n2  1940    10 2     <NA>  <NA>  <NA>  <NA> \n3  1940    10 3     <NA>  <NA>  <NA>  <NA> \n4  1940    10 4     <NA>  <NA>  <NA>  <NA> \n5  1940    10 5     <NA>  <NA>  <NA>  <NA> \n6  1940    10 6     <NA>  <NA>  <NA>  <NA> \n\n\nI want to create a date to identifier that is proper for this daily data.\n\nNWS.Daily %<>%  mutate(date = as.Date(paste(MO,Day,YR,sep=\"-\"), format=\"%m-%d-%Y\"))\n\nThere is one space value of snow, December 7, 1978. I need to fix that before we can turn them into numeric values.\n\nNWS.Daily %>% filter(date==as.Date(\"1978-12-07\")) %>% head\n\n# A tibble: 1 × 8\n     YR    MO Day   TX    TN    PR    SN    date      \n  <int> <int> <chr> <chr> <chr> <chr> <chr> <date>    \n1  1978    12 7     35    23    0     \" \"   1978-12-07\n\nNWS.Daily$SN[NWS.Daily$date==as.Date(\"1978-12-07\")] <- 0\n\nThat will allow me to turn this into proper numeric data after I account for the T values.\n\nNWS.Daily %<>% \n  mutate(PR = recode(PR, T = \"0.005\"), \n         SN = recode(SN, T = \"0.005\"))\n\nNow let me actually create numeric variables and select the necessary data for further analysis that has nice names.\n\nNWS.Daily %<>% mutate(High = as.numeric(TX), \n         Low = as.numeric(TN), \n         Precipitation = as.numeric(PR), \n         Snow = as.numeric(SN)\n         )\n\nThere is a remaining problem. There are dates that can be constructed that do not actually exist, February 29, etc. because the spreadsheet had to have 31 columns for days that could exist. This is easy enough to clean up by dropping the missing dates.\n\nNWS.Daily.Clean <- NWS.Daily %>% \n  select(date, High, Low, Precipitation, Snow) %>% \n  filter(!(is.na(date)))\nsummary(NWS.Daily.Clean)\n\n      date                 High             Low        Precipitation   \n Min.   :1940-10-01   Min.   : 14.00   Min.   :-3.00   Min.   :0.0000  \n 1st Qu.:1960-07-24   1st Qu.: 52.00   1st Qu.:38.00   1st Qu.:0.0000  \n Median :1980-05-16   Median : 61.00   Median :45.00   Median :0.0050  \n Mean   :1980-05-16   Mean   : 62.62   Mean   :44.99   Mean   :0.1017  \n 3rd Qu.:2000-03-08   3rd Qu.: 73.00   3rd Qu.:53.00   3rd Qu.:0.1000  \n Max.   :2019-12-31   Max.   :107.00   Max.   :74.00   Max.   :2.6900  \n                      NA's   :12       NA's   :12      NA's   :12      \n      Snow         \n Min.   : 0.00000  \n 1st Qu.: 0.00000  \n Median : 0.00000  \n Mean   : 0.01655  \n 3rd Qu.: 0.00000  \n Max.   :14.40000  \n NA's   :12        \n\n\nThere are still 12 missing days. Those are right at the beginning. Let’s drop those.\n\nNWS.Daily.TS <- NWS.Daily.Clean %>% filter(!is.na(Snow))\nsummary(NWS.Daily.TS)\n\n      date                 High             Low        Precipitation   \n Min.   :1940-10-13   Min.   : 14.00   Min.   :-3.00   Min.   :0.0000  \n 1st Qu.:1960-08-02   1st Qu.: 52.00   1st Qu.:38.00   1st Qu.:0.0000  \n Median :1980-05-22   Median : 61.00   Median :45.00   Median :0.0050  \n Mean   :1980-05-22   Mean   : 62.62   Mean   :44.99   Mean   :0.1017  \n 3rd Qu.:2000-03-11   3rd Qu.: 73.00   3rd Qu.:53.00   3rd Qu.:0.1000  \n Max.   :2019-12-31   Max.   :107.00   Max.   :74.00   Max.   :2.6900  \n      Snow         \n Min.   : 0.00000  \n 1st Qu.: 0.00000  \n Median : 0.00000  \n Mean   : 0.01655  \n 3rd Qu.: 0.00000  \n Max.   :14.40000  \n\n\nThis can be turned into a tsibble to make sure the dates are proper.\n\nlibrary(kableExtra)\nNWS.Daily.TS <- NWS.Daily.TS %>% as_tsibble(index=date) \nNWS.Daily.TS %>%\n  head(n=50) %>%\n  kable() %>% \n  scroll_box(width=\"800px\", height=\"400px\")\n\n\n\n \n  \n    date \n    High \n    Low \n    Precipitation \n    Snow \n  \n \n\n  \n    1940-10-13 \n    75 \n    57 \n    0.010 \n    0 \n  \n  \n    1940-10-14 \n    70 \n    53 \n    0.005 \n    0 \n  \n  \n    1940-10-15 \n    64 \n    52 \n    0.005 \n    0 \n  \n  \n    1940-10-16 \n    72 \n    50 \n    0.000 \n    0 \n  \n  \n    1940-10-17 \n    72 \n    58 \n    0.130 \n    0 \n  \n  \n    1940-10-18 \n    78 \n    58 \n    0.000 \n    0 \n  \n  \n    1940-10-19 \n    78 \n    59 \n    0.005 \n    0 \n  \n  \n    1940-10-20 \n    64 \n    54 \n    0.140 \n    0 \n  \n  \n    1940-10-21 \n    63 \n    48 \n    0.050 \n    0 \n  \n  \n    1940-10-22 \n    61 \n    41 \n    0.000 \n    0 \n  \n  \n    1940-10-23 \n    58 \n    53 \n    0.630 \n    0 \n  \n  \n    1940-10-24 \n    57 \n    48 \n    1.030 \n    0 \n  \n  \n    1940-10-25 \n    57 \n    41 \n    0.000 \n    0 \n  \n  \n    1940-10-26 \n    57 \n    38 \n    0.000 \n    0 \n  \n  \n    1940-10-27 \n    56 \n    37 \n    0.005 \n    0 \n  \n  \n    1940-10-28 \n    53 \n    45 \n    0.180 \n    0 \n  \n  \n    1940-10-29 \n    59 \n    48 \n    0.580 \n    0 \n  \n  \n    1940-10-30 \n    59 \n    50 \n    0.500 \n    0 \n  \n  \n    1940-10-31 \n    52 \n    46 \n    0.250 \n    0 \n  \n  \n    1940-11-01 \n    52 \n    40 \n    0.170 \n    0 \n  \n  \n    1940-11-02 \n    53 \n    38 \n    0.020 \n    0 \n  \n  \n    1940-11-03 \n    47 \n    36 \n    0.005 \n    0 \n  \n  \n    1940-11-04 \n    55 \n    32 \n    0.000 \n    0 \n  \n  \n    1940-11-05 \n    51 \n    42 \n    0.070 \n    0 \n  \n  \n    1940-11-06 \n    58 \n    46 \n    0.280 \n    0 \n  \n  \n    1940-11-07 \n    56 \n    46 \n    0.850 \n    0 \n  \n  \n    1940-11-08 \n    50 \n    42 \n    0.290 \n    0 \n  \n  \n    1940-11-09 \n    48 \n    35 \n    0.020 \n    0 \n  \n  \n    1940-11-10 \n    47 \n    34 \n    0.010 \n    0 \n  \n  \n    1940-11-11 \n    46 \n    35 \n    0.010 \n    0 \n  \n  \n    1940-11-12 \n    45 \n    33 \n    0.000 \n    0 \n  \n  \n    1940-11-13 \n    45 \n    34 \n    0.000 \n    0 \n  \n  \n    1940-11-14 \n    47 \n    33 \n    0.000 \n    0 \n  \n  \n    1940-11-15 \n    53 \n    28 \n    0.000 \n    0 \n  \n  \n    1940-11-16 \n    49 \n    27 \n    0.000 \n    0 \n  \n  \n    1940-11-17 \n    46 \n    36 \n    0.290 \n    0 \n  \n  \n    1940-11-18 \n    49 \n    30 \n    0.010 \n    0 \n  \n  \n    1940-11-19 \n    46 \n    29 \n    0.000 \n    0 \n  \n  \n    1940-11-20 \n    49 \n    36 \n    0.370 \n    0 \n  \n  \n    1940-11-21 \n    50 \n    33 \n    0.005 \n    0 \n  \n  \n    1940-11-22 \n    44 \n    28 \n    0.000 \n    0 \n  \n  \n    1940-11-23 \n    42 \n    37 \n    0.120 \n    0 \n  \n  \n    1940-11-24 \n    44 \n    35 \n    0.620 \n    0 \n  \n  \n    1940-11-25 \n    51 \n    37 \n    0.000 \n    0 \n  \n  \n    1940-11-26 \n    44 \n    36 \n    0.000 \n    0 \n  \n  \n    1940-11-27 \n    45 \n    38 \n    0.510 \n    0 \n  \n  \n    1940-11-28 \n    59 \n    43 \n    0.890 \n    0 \n  \n  \n    1940-11-29 \n    57 \n    40 \n    0.005 \n    0 \n  \n  \n    1940-11-30 \n    45 \n    39 \n    0.005 \n    0 \n  \n  \n    1940-12-01 \n    51 \n    42 \n    0.060 \n    0 \n  \n\n\n\n\n\nOne decomposition to make sure it works.\n\nNWS.Daily.TS %>% model(STL(High)) %>% components() %>% autoplot()"
  },
  {
    "objectID": "posts/onedrive-is-dangerous/index.html",
    "href": "posts/onedrive-is-dangerous/index.html",
    "title": "Friends don’t let Friends use OneDrive for R Libraries",
    "section": "",
    "text": "Annotated OneDrive Image"
  },
  {
    "objectID": "posts/onedrive-is-dangerous/index.html#brief-background",
    "href": "posts/onedrive-is-dangerous/index.html#brief-background",
    "title": "Friends don’t let Friends use OneDrive for R Libraries",
    "section": "Brief Background",
    "text": "Brief Background\nFor longstanding file sharing reasons, OneDrive often locks files to sync and this can cause random crashes and assorted errors if the R libraries are installed there. On many computers, the default library location will exist inside the OneDrive’s domain of directories to backup. Indeed, Windows has generic file locking and sharing issues for certain file types."
  },
  {
    "objectID": "posts/onedrive-is-dangerous/index.html#how-to-fix-the-problem",
    "href": "posts/onedrive-is-dangerous/index.html#how-to-fix-the-problem",
    "title": "Friends don’t let Friends use OneDrive for R Libraries",
    "section": "How to Fix the Problem",
    "text": "How to Fix the Problem\n\nWe need to create a directory outside of the OneDrive’s purview; something directly off of root C: is best. Though you need not following my naming convention, I will use mkdir C:/RLibs. If you choose something different, that should be substituted below where I use RLibs.\nUsing the RStudio’s Tools > Install packages or the R Console, we will need to install usethis. At the console it is, install.packages(\"usethis\")\nlibrary(usethis)\nedit_r_profile()\n.libPaths(c(\"C:\\RLibs\", .libPaths()))\nRestart RStudio.\nTools > Install Packages should now default to C:\\RLibs.\n\nHere is a short video on youtube. WARNING: it contains some slip-ups that I intentionally made so that you can see what goes wrong in the easiest places for things to get stuck."
  },
  {
    "objectID": "posts/moving-averages-link/index.html",
    "href": "posts/moving-averages-link/index.html",
    "title": "Easy moving averages",
    "section": "",
    "text": "An r-bloggers post\nThere is a handy post on r-bloggers that details moving averages built around the amazing tidyquant package.\nFirst, get some data.\n\nlibrary(tidyverse)\nGlobalLandTemperaturesByMajorCity <- read_csv(\"data/GlobalLandTemperaturesByMajorCity.csv\",\ncol_types = cols(dt = col_date(format = \"%Y-%m-%d\")))\n\nLet me choose London.\n\nLondon.Data <- GlobalLandTemperaturesByMajorCity %>% filter(City==\"London\")\nhead(London.Data)\n\n# A tibble: 6 × 7\n  dt         AverageTemperature AverageTemperatu…¹ City  Country Latit…² Longi…³\n  <date>                  <dbl>              <dbl> <chr> <chr>   <chr>   <chr>  \n1 1743-11-01               7.54               1.75 Lond… United… 52.24N  0.00W  \n2 1743-12-01              NA                 NA    Lond… United… 52.24N  0.00W  \n3 1744-01-01              NA                 NA    Lond… United… 52.24N  0.00W  \n4 1744-02-01              NA                 NA    Lond… United… 52.24N  0.00W  \n5 1744-03-01              NA                 NA    Lond… United… 52.24N  0.00W  \n6 1744-04-01               8.30               2.50 Lond… United… 52.24N  0.00W  \n# … with abbreviated variable names ¹​AverageTemperatureUncertainty, ²​Latitude,\n#   ³​Longitude"
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html",
    "href": "posts/visualizing-one-qualitative-variable/index.html",
    "title": "Visualizing One Qualitative Variable",
    "section": "",
    "text": "A dataset for illustrating the various available visualizations needs a certain degree of richness with manageable size. The dataset on Bonds contains three categorical and a few quantitative indicators sufficient to show what we might wish.\n\n\n\nBonds <- read.csv(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/BondFunds.csv\"))\n\n\n\n\n\nlibrary(skimr)\nBonds %>%\n    skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFund.Number\n0\n1\n4\n6\n0\n184\n0\n\n\nType\n0\n1\n20\n23\n0\n2\n0\n\n\nFees\n0\n1\n2\n3\n0\n2\n0\n\n\nRisk\n0\n1\n7\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAssets\n0\n1\n910.65\n2253.27\n12.40\n113.72\n268.4\n621.95\n18603.50\n▇▁▁▁▁\n\n\nExpense.Ratio\n0\n1\n0.71\n0.26\n0.12\n0.53\n0.7\n0.90\n1.94\n▂▇▅▁▁\n\n\nReturn.2009\n0\n1\n7.16\n6.09\n-8.80\n3.48\n6.4\n10.72\n32.00\n▁▇▅▁▁\n\n\nX3.Year.Return\n0\n1\n4.66\n2.52\n-13.80\n4.05\n5.1\n6.10\n9.40\n▁▁▁▅▇\n\n\nX5.Year.Return\n0\n1\n3.99\n1.49\n-7.30\n3.60\n4.3\n4.90\n6.80\n▁▁▁▅▇\n\n\n\n\n\nMost data types are represented. There is no time variable so dates and the visualizations that go with time series are omitted."
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#bar-plots-and-column-plots",
    "href": "posts/visualizing-one-qualitative-variable/index.html#bar-plots-and-column-plots",
    "title": "Visualizing One Qualitative Variable",
    "section": "Bar plots and column plots",
    "text": "Bar plots and column plots\nThere are two ways to construct a barplot; we can let ggplot handle it on the raw data or calculate it ourselves. Let me focus on Risk."
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#geom_bar",
    "href": "posts/visualizing-one-qualitative-variable/index.html#geom_bar",
    "title": "Visualizing One Qualitative Variable",
    "section": "geom_bar()",
    "text": "geom_bar()\n\nBonds %>%\n    ggplot() + aes(x = Risk) + geom_bar()\n\n\n\n\n\nRaw Data Bar Plot [color]\n\nBonds %>%\n    ggplot() + aes(x = Risk, color = Risk) + geom_bar()\n\n\n\n\n\n\nRaw Data Bar Plot [color and fill]\nWe could color it.\n\nBonds %>%\n    ggplot() + aes(x = Risk, color = Risk) + geom_bar(fill = \"white\") + guides(color = FALSE)\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\n\n\nRaw Data Bar Plot [Fill]\nWe can fill the shapes.\n\n# guides(fill=FALSE) removes the legend\nBonds %>%\n    ggplot(., aes(x = Risk, fill = Risk)) + geom_bar() + guides(fill = FALSE)"
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#geom_bar-meets-fill",
    "href": "posts/visualizing-one-qualitative-variable/index.html#geom_bar-meets-fill",
    "title": "Visualizing One Qualitative Variable",
    "section": "geom_bar() meets fill",
    "text": "geom_bar() meets fill\nWe can also deploy fill but x is no longer the axis; the axis is some constant value with frequencies filled by the fill. This will require some prettying.\n\nA Cumulative Bar Plot\n\nBasic.Bar <- Bonds %>%\n    ggplot(., aes(x = \"\", fill = Risk)) + geom_bar()\nBasic.Bar\n\n\n\n\nThe prettying will require that I eliminate the x axis [set it to empty], include a theme, and give it proper labels.\n\n\nEnhanced Cumulative Bar Plot\n\nBonds %>%\n    ggplot(., aes(x = \"\", fill = Risk)) + geom_bar() + labs(x = \"\", y = \"Number of Funds\") +\n    theme_minimal() + theme(axis.text.x = element_blank())\n\n\n\n\n\n\nProportion Bar Plot\n\nBonds %>%\n    ggplot(., aes(x = \"\", fill = Risk)) + geom_bar(position = \"fill\") + labs(x = \"\",\n    y = \"Proportion of Funds\")\n\n\n\n\nThe prettying will require that I eliminate the x axis [set it to empty], include a theme, and give it proper labels.\n\n\nEnhanced Proportion Bar Plot\n\nBonds %>%\n    ggplot(., aes(x = \"\", fill = Risk)) + geom_bar(position = \"fill\") + labs(x = \"\",\n    y = \"Propotion of Funds\") + theme_minimal()"
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#geom_col",
    "href": "posts/visualizing-one-qualitative-variable/index.html#geom_col",
    "title": "Visualizing One Qualitative Variable",
    "section": "geom_col()",
    "text": "geom_col()\n\nRisk.Table <- table(Bonds$Risk) %>%\n    data.frame()\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq)) + geom_col()\n\n\n\n\n\nBeautifying geom_col()\nNow it really needs some beautification.\n\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq, fill = Var1)) + geom_col() + labs(x = \"Risk Levels\",\n    y = \"Number of Funds\") + theme_minimal() + theme(axis.text.x = element_blank()) +\n    scale_fill_viridis_d() + guides(fill = FALSE)"
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#position-fill",
    "href": "posts/visualizing-one-qualitative-variable/index.html#position-fill",
    "title": "Visualizing One Qualitative Variable",
    "section": "position = \"fill\"",
    "text": "position = \"fill\"\nThe two commands are symmetric in the sense that x as axis always splits it into multiple parts. fill will prove very useful with a two dimensional table.\n\nRisk.Table %>%\n    ggplot(., aes(x = 1, y = Freq, fill = Var1)) + geom_col(position = \"fill\") +\n    labs(x = \"Risk Levels\", y = \"Number of Funds\") + theme_minimal() + theme(axis.text.x = element_blank()) +\n    scale_fill_viridis_d() + guides(fill = FALSE)"
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#a-lollipop-chart",
    "href": "posts/visualizing-one-qualitative-variable/index.html#a-lollipop-chart",
    "title": "Visualizing One Qualitative Variable",
    "section": "A lollipop chart",
    "text": "A lollipop chart\nA lollipop chart is a combination of two geometries. It is a basic scatterplot combining one qualitative variable and the quantitative count of the number of observations. The head of the lollipop is a point while there is an accompanying line segment from (x,0) to (x,Freq) where Freq is the default name for a count from a table.\n\nBasic Lollipop Chart\n\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq, color = Var1)) + geom_point(size = 6) + labs(x = \"Risk Level\",\n    y = \"Number of Funds\", color = \"Risk Level\") + geom_segment(aes(xend = Var1,\n    y = 0, yend = Freq)) + theme_minimal()\n\n\n\n\n\n\nSlicked Lollipop Chart by Adjusting Segment Size\n\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq, color = Var1)) + geom_point(size = 6) + labs(x = \"Risk Levels\",\n    y = \"Number of Funds\") + geom_segment(aes(xend = Var1, y = 0, yend = Freq), size = 1.5) +\n    theme_minimal() + guides(color = FALSE)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq, color = Var1)) + geom_point(size = 6) + labs(x = \"Risk Levels\",\n    y = \"Number of Funds\") + geom_segment(aes(xend = Var1, y = 0, yend = Freq)) +\n    theme_minimal() + scale_color_viridis_d() + guides(color = FALSE) + coord_flip()\n\n\n\n\n\n\nA Lollipop Table [geom_label()]\nNow I will switch up the points to be the actual values as text. For this, I use the geom_text aesthetic that requires a label to be assigned. I also want to put down the lines before the text to avoid overlap.\n\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq, color = Var1, label = Freq)) + labs(x = \"Risk Levels\",\n    y = \"Number of Funds\") + geom_segment(aes(xend = Var1, y = 0, yend = Freq)) +\n    geom_label(size = 6) + theme_minimal() + scale_color_viridis_d() + guides(color = FALSE) +\n    coord_flip()\n\n\n\n\n\n\nA Lollipop Table [geom_text() inverse]\nThe ggplot is built in layers so the segment before the label makes sure that the white shows up. The fill and a discrete color are combined to create this graphical table.\n\nRisk.Table %>%\n    ggplot(., aes(x = Var1, y = Freq, color = Var1, fill = Var1, label = Freq)) +\n    geom_segment(aes(xend = Var1, y = 0, yend = Freq), size = 1.5) + geom_label(size = 6,\n    color = \"white\") + labs(x = \"Risk Levels\", y = \"Number of Funds\") + theme_minimal() +\n    scale_color_viridis_d() + scale_fill_viridis_d() + guides(fill = FALSE, color = FALSE) +\n    coord_flip()"
  },
  {
    "objectID": "posts/visualizing-one-qualitative-variable/index.html#i-hate-pie-charts",
    "href": "posts/visualizing-one-qualitative-variable/index.html#i-hate-pie-charts",
    "title": "Visualizing One Qualitative Variable",
    "section": "I HATE PIE CHARTS",
    "text": "I HATE PIE CHARTS\nA pie chart is fairly easy to do. Let’s go back and show something that I find pretty amazing. A pie chart is a bar chart [the fill variety] with coordinates that fill a circle rather than a square. We take the most basic bar plot – Basic.Bar – and add three things: new coordinates that are polar, labels, and a blank theme to eliminate axis labels.\n\nBasic.Bar + coord_polar(\"y\", start = 0) + labs(x = \"\", y = \"\") + theme_void()"
  },
  {
    "objectID": "posts/quick-look-at-vix/index.html",
    "href": "posts/quick-look-at-vix/index.html",
    "title": "A brief look at VIX",
    "section": "",
    "text": "NB: I originally wrote this on February 27, 2020 so there is commentary surrounding that date. It was done on the quick for curiosity. I will update it by recompiling it with new data and will update the commentary noting when it took place.\nChicago Board Of Exchange (CBOE) makes data available regularly. To judge the currency of the data, I have tailed it below after converting the dates to a valid date format.\n\nlibrary(tidyverse)\nVIX <- read.csv(url(\"https://cdn.cboe.com/api/global/us_indices/daily_prices/VIX_History.csv\"))\nVIX$Dates <- as.Date(VIX$DATE,\n  format = \"%m/%d/%Y\")\ntail(VIX)\n\n           DATE  OPEN  HIGH   LOW CLOSE      Dates\n8310 12/21/2022 21.25 21.29 19.94 20.07 2022-12-21\n8311 12/22/2022 20.08 24.30 20.01 21.97 2022-12-22\n8312 12/23/2022 22.17 22.64 20.78 20.87 2022-12-23\n8313 12/27/2022 21.67 22.80 21.59 21.65 2022-12-27\n8314 12/28/2022 21.47 22.26 20.96 22.14 2022-12-28\n8315 12/29/2022 22.25 22.31 21.36 21.44 2022-12-29\n\n\nThe data was straightforward to get a hold of. Now let me plot it. I want to do this with a candlestick plot – a way of displaying intra-day volatility. There’s so much data that the views aren’t great.\n\nlibrary(plotly)\n# create the candlestick plot\nfig <- VIX  %>% plot_ly(x = ~Dates, type=\"candlestick\",\n          open = ~OPEN, close = ~CLOSE,\n          high = ~HIGH, low = ~LOW) \nfig <- fig %>% layout(title = \"A Historical Look at VIX\")\nfig\n\n\n\n\n\nAs an overall it has been worse, but keep in mind, that big blip happened TODAY! What does it look like in perspective [keeping in mind that the futures are currently just under 40] since 2012?\n\nfig2 <- VIX %>% filter(Dates > as.Date(\"01/01/2012\", format = \"%m/%d/%Y\")) %>% plot_ly(x = ~Dates, type=\"candlestick\",\n          open = ~OPEN, close = ~CLOSE,\n          high = ~HIGH, low = ~LOW) \nfig2 <- fig2 %>% layout(title = \"VIX Since 2012\")\nfig2\n\n\n\n\n\n\n\nI will touch the file about daily to track the evolution.\n\nlibrary(hrbrthemes); library(viridis)\nVIX <- VIX %>% mutate(Percent.Change = (CLOSE - lag(CLOSE)) / lag(CLOSE)) \np <- ggplot(VIX, aes(x=Dates, y=Percent.Change, size=Percent.Change/10, color=Percent.Change)) + \n  geom_point(alpha=0.5, shape=21, inherit.aes = TRUE) +\n  scale_size_continuous(range=c(0.05,2), guide=FALSE) +\n  geom_line() + \n  geom_smooth(color=\"orange\", method=\"loess\", span=0.05, se=FALSE) + \n  geom_vline(xintercept = as.Date(\"02/27/2020\", format = \"%m/%d/%Y\"), color=\"red\", alpha=0.2, linetype = \"dotted\") + \n  geom_vline(xintercept = as.Date(\"09/12/2008\", format = \"%m/%d/%Y\"), color=\"red\", alpha=0.4) +\n  geom_label(data = data.frame(x = as.Date(\"2008-02-12\"),\n    y = 0.75, label = \"Lehman Brothers\"),mapping = aes(x = x, y = y, label = label), size = 3.86605783866058, angle = 0L, lineheight = 1L, hjust = 0.5, vjust = 0.5, colour = \"red\", family = \"sans\", fontface = \"plain\", label.padding = structure(0.25, class = \"unit\", valid.unit = 3L, unit = \"lines\"), label.size = 0.25, label.r = structure(0.15, class = \"unit\", valid.unit = 3L, unit = \"lines\"), inherit.aes = FALSE, show.legend = FALSE) + \n  scale_color_viridis_c(guide=\"none\") +\n  scale_fill_viridis_c(guide=\"none\") +\n    theme_ipsum()\nfig3 <- ggplotly(p)\nfig3\n\n\n\n\n\nNB: This commentary was in mid-March. This doesn’t look good. The smooth on a small span is uncomfortably headed upward and today will shock it like no previous day in a very long while."
  },
  {
    "objectID": "posts/visualizing-mixed-data/index.html",
    "href": "posts/visualizing-mixed-data/index.html",
    "title": "Visualizing One Qualitative and One Quantitative Variable",
    "section": "",
    "text": "A dataset for illustrating the various available visualizations needs a certain degree of richness with manageable size. The dataset on Bonds contains three categorical and a few quantitative indicators sufficient to show what we might wish.\n\n\n\nBonds <- read.csv(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/BondFunds.csv\"))\n\n\n\n\n\nlibrary(skimr)\nBonds %>%\n    skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n184\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFund.Number\n0\n1\n4\n6\n0\n184\n0\n\n\nType\n0\n1\n20\n23\n0\n2\n0\n\n\nFees\n0\n1\n2\n3\n0\n2\n0\n\n\nRisk\n0\n1\n7\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAssets\n0\n1\n910.65\n2253.27\n12.40\n113.72\n268.4\n621.95\n18603.50\n▇▁▁▁▁\n\n\nExpense.Ratio\n0\n1\n0.71\n0.26\n0.12\n0.53\n0.7\n0.90\n1.94\n▂▇▅▁▁\n\n\nReturn.2009\n0\n1\n7.16\n6.09\n-8.80\n3.48\n6.4\n10.72\n32.00\n▁▇▅▁▁\n\n\nX3.Year.Return\n0\n1\n4.66\n2.52\n-13.80\n4.05\n5.1\n6.10\n9.40\n▁▁▁▅▇\n\n\nX5.Year.Return\n0\n1\n3.99\n1.49\n-7.30\n3.60\n4.3\n4.90\n6.80\n▁▁▁▅▇\n\n\n\n\n\nMost data types are represented. There is no time variable so dates and the visualizations that go with time series are omitted."
  },
  {
    "objectID": "posts/visualizing-mixed-data/index.html#geom_boxplot",
    "href": "posts/visualizing-mixed-data/index.html#geom_boxplot",
    "title": "Visualizing One Qualitative and One Quantitative Variable",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\nThis will construct a boxplot of quantitative y for each value of the qualitative variable placed on x. This is very hard to read because of the extrema.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets)) + geom_boxplot()"
  },
  {
    "objectID": "posts/visualizing-mixed-data/index.html#geom_dotplot",
    "href": "posts/visualizing-mixed-data/index.html#geom_dotplot",
    "title": "Visualizing One Qualitative and One Quantitative Variable",
    "section": "geom_dotplot()",
    "text": "geom_dotplot()\nThe number of bins, the axis they are placed on, and the size of the dots are core to dotplots. It is often simply a matter of trial and error.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets, color = Risk)) + geom_dotplot(binaxis = \"y\",\n    bins = 50, dotsize = 0.3)\n\nWarning in geom_dotplot(binaxis = \"y\", bins = 50, dotsize = 0.3): Ignoring\nunknown parameters: `bins`\n\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\nImproved\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets, color = Risk)) + geom_dotplot(binaxis = \"y\",\n    bins = 50, dotsize = 0.3) + guides(color = FALSE) + theme_minimal()\n\nWarning in geom_dotplot(binaxis = \"y\", bins = 50, dotsize = 0.3): Ignoring\nunknown parameters: `bins`\n\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`."
  },
  {
    "objectID": "posts/visualizing-mixed-data/index.html#geom_violin",
    "href": "posts/visualizing-mixed-data/index.html#geom_violin",
    "title": "Visualizing One Qualitative and One Quantitative Variable",
    "section": "geom_violin()",
    "text": "geom_violin()\nThe most basic violin plot shows a two-sided density plot for each value of x. By default, all violins have the same area.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets)) + geom_violin()\n\n\n\n\n\nAdjusting the area: scale=count\nWe can adjust the violins to have area proportional to the count of observations by deploying the scale argument set equal to count.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets)) + geom_violin(scale = \"count\")\n\n\n\n\n\n\nAdjusting the area: scale=width\nWe can also adjust the violins to have equal width.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets)) + geom_violin(scale = \"width\")\n\n\n\n\n\n\nAdjusting the bandwidth\nWe can also make the violins smoother or more rigid with the adjust= argument. Numbers greater than one make it smoother.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets)) + geom_violin(scale = \"count\", adjust = 2)\n\n\n\n\nNumbers less than one make it less smooth.\n\nBonds %>%\n    ggplot(., aes(x = Risk, y = Assets)) + geom_violin(scale = \"count\", adjust = 1/2)"
  },
  {
    "objectID": "posts/visualizing-mixed-data/index.html#geom_density-with-colorfill",
    "href": "posts/visualizing-mixed-data/index.html#geom_density-with-colorfill",
    "title": "Visualizing One Qualitative and One Quantitative Variable",
    "section": "geom_density() with color/fill",
    "text": "geom_density() with color/fill\nWe can color the lines of a density plot to try and showcase the various distributions.\n\nBonds %>%\n    ggplot(., aes(x = Assets, color = Risk)) + geom_density()\n\n\n\n\nWe fill the shape of density plot to try and showcase the various distributions.\n\nBonds %>%\n    ggplot(., aes(x = Assets, fill = Risk)) + geom_density()\n\n\n\n\nThis almost always needs lightening.\n\nBonds %>%\n    ggplot(., aes(x = Assets, fill = Risk)) + geom_density(alpha = 0.2)\n\n\n\n\nIn this case, it helps to remove the outline.\n\nBonds %>%\n    ggplot(., aes(x = Assets, fill = Risk)) + geom_density(alpha = 0.2, color = NA)"
  },
  {
    "objectID": "posts/visualizing-mixed-data/index.html#geom_beeswarm",
    "href": "posts/visualizing-mixed-data/index.html#geom_beeswarm",
    "title": "Visualizing One Qualitative and One Quantitative Variable",
    "section": "geom_beeswarm()",
    "text": "geom_beeswarm()\nRelated to the dotplot is the beeswarm. It requires installing a package with the geometry known as ggbeeswarm.\ninstall.packages(\"ggbeeswarm\")\n\nlibrary(ggbeeswarm)\nBonds %>%\n    ggplot() + aes(x = Risk, y = Assets) + geom_beeswarm()\n\n\n\n\n\nlibrary(ggbeeswarm)\nBonds %>%\n    ggplot() + aes(x = Risk, y = Assets, color = Risk) + geom_beeswarm() + guides(color = FALSE)"
  },
  {
    "objectID": "posts/importing-excel-data/index.html",
    "href": "posts/importing-excel-data/index.html",
    "title": "Importing Excel Data",
    "section": "",
    "text": "How To Import a Microsoft Excel File\nThe go to tool comes from the readxl library in R. We can install it with:\ninstall.packages(\"readxl\")\nTo use it, the Markdown must call it – make it active – just as we must at the command line to make it work. The Files pane will make this easier, we can right click to import and get code from the subsequent interaction.\nlibrary(readxl)\nThe command to read Excel files comes in three forms:\n- read_excel()\n- read_xls()\n- read_xlsx()\nwhere the first works for all file types while the second is written specifically for older .xls files and the third is written for newer .xlsx file types. If we type ?read_excel we can obtain the help file that guides us through a host of situations including specifying a range of cells, whether or not to use the first row as column names, the data type in a column, what is missing [NA], whether rows should be skipped, and a host of others. The one thing that is required is the file that we wish to import [known to this command as the path]. We can acquire the file from the following link. If my file is known to my computer as /home/rob/Downloads/BondFunds.xlsx then I also want to be careful about the sheet, in this case, it is JustData:\n\nlibrary(tidyverse)\nlibrary(readxl)\nBonds <- read_excel(path=\"~/Downloads/BondFunds.xlsx\", sheet=\"JustData\")\nBonds\n\n# A tibble: 184 × 9\n   `Fund Number` Type         Assets Fees  Expen…¹ Retur…² 3-Yea…³ 5-Yea…⁴ Risk \n   <chr>         <chr>         <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl> <chr>\n 1 FN-1          Intermediat…  7268. No       0.45     6.9     6.9     5.5 Belo…\n 2 FN-2          Intermediat…   475. No       0.5      9.8     7.5     6.1 Belo…\n 3 FN-3          Intermediat…   193  No       0.71     6.3     7       5.6 Aver…\n 4 FN-4          Intermediat… 18604. No       0.13     5.4     6.6     5.5 Aver…\n 5 FN-5          Intermediat…   143. No       0.6      5.9     6.7     5.4 Aver…\n 6 FN-6          Intermediat…  1402. No       0.54     5.7     6.4     6.2 Aver…\n 7 FN-7          Intermediat…   986. No       0.49     3       6.8     5.3 Aver…\n 8 FN-8          Intermediat…  2189. No       0.55     7.4     6.4     5.2 Belo…\n 9 FN-9          Intermediat…   391. No       0.67     5.3     6.1     5   Belo…\n10 FN-10         Intermediat…   544. No       0.63     5.7     6.2     5.1 Belo…\n# … with 174 more rows, and abbreviated variable names ¹​`Expense Ratio`,\n#   ²​`Return 2009`, ³​`3-Year Return`, ⁴​`5-Year Return`\n\n\nThat works just as planned. If I leave the specification of the sheet out, it will load the first sheet.\n\nFirstSheet <- read_excel(path=\"~/Downloads/BondFunds.xlsx\")\n\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n\nFirstSheet\n\n# A tibble: 18 × 9\n   ...1                    ...2      ...3  ...4  ...5  ...6  ...7  ...8  mosai…¹\n   <chr>                   <chr>     <chr> <chr> <chr> <lgl> <lgl> <lgl> <lgl>  \n 1 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 2 Fees and Bond Type      Fees      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 3 Type                    No        Yes   Gran… <NA>  NA    NA    NA    NA     \n 4 Intermediate Government 0.288043… 0.18… 0.47… <NA>  NA    NA    NA    NA     \n 5 Short Term Corporate    0.418478… 0.10… 0.52… <NA>  NA    NA    NA    NA     \n 6 Grand Total             0.706521… 0.29… 1     <NA>  NA    NA    NA    NA     \n 7 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 8 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 9 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n10 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n11 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n12 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n13 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n14 Risk and Bond Type      Risk      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n15 Type                    Above av… Aver… Belo… Gran… NA    NA    NA    NA     \n16 Intermediate Government 29        32    26    87    NA    NA    NA    NA     \n17 Short Term Corporate    30        37    30    97    NA    NA    NA    NA     \n18 Grand Total             59        69    56    184   NA    NA    NA    NA     \n# … with abbreviated variable name ¹​`mosaic(xtabs(~Type+Fees, data=Bonds))`\n\n\nThat is not well-formatted because the first sheet is a table of sorts. A little bit of Rvangelism.\n\n\nA look at the magic of R.\nI am going to use R’s ability to define variable(s) to make my life easier. I do not wish to know what the tabs are; let R figure it out.\n\nAllSheets <- function(path) { # Feed a path to an Excel file\n  WorkBook <- excel_sheets(path=path) %>% # Get a vector of sheet names\n    map(~ read_excel(path=path, sheet=.x)) # Load each sheet by name\n  names(WorkBook) <- excel_sheets(path=path) # Rename the sheets by their names\n  return(WorkBook)\n}\nMyWB <- AllSheets(path=\"~/Downloads/BondFunds.xlsx\")\n\nNew names:\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n\nMyWB\n\n$ContingencyTable\n# A tibble: 18 × 9\n   ...1                    ...2      ...3  ...4  ...5  ...6  ...7  ...8  mosai…¹\n   <chr>                   <chr>     <chr> <chr> <chr> <lgl> <lgl> <lgl> <lgl>  \n 1 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 2 Fees and Bond Type      Fees      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 3 Type                    No        Yes   Gran… <NA>  NA    NA    NA    NA     \n 4 Intermediate Government 0.288043… 0.18… 0.47… <NA>  NA    NA    NA    NA     \n 5 Short Term Corporate    0.418478… 0.10… 0.52… <NA>  NA    NA    NA    NA     \n 6 Grand Total             0.706521… 0.29… 1     <NA>  NA    NA    NA    NA     \n 7 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 8 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n 9 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n10 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n11 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n12 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n13 <NA>                    <NA>      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n14 Risk and Bond Type      Risk      <NA>  <NA>  <NA>  NA    NA    NA    NA     \n15 Type                    Above av… Aver… Belo… Gran… NA    NA    NA    NA     \n16 Intermediate Government 29        32    26    87    NA    NA    NA    NA     \n17 Short Term Corporate    30        37    30    97    NA    NA    NA    NA     \n18 Grand Total             59        69    56    184   NA    NA    NA    NA     \n# … with abbreviated variable name ¹​`mosaic(xtabs(~Type+Fees, data=Bonds))`\n\n$DATA\n# A tibble: 184 × 11\n   `Fund Number` Type   Assets Fees  Expen…¹ Retur…² 3-Yea…³ 5-Yea…⁴ Risk  ...10\n   <chr>         <chr>   <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl> <chr> <lgl>\n 1 FN-1          Inter…  7268. No       0.45     6.9     6.9     5.5 Belo… NA   \n 2 FN-2          Inter…   475. No       0.5      9.8     7.5     6.1 Belo… NA   \n 3 FN-3          Inter…   193  No       0.71     6.3     7       5.6 Aver… NA   \n 4 FN-4          Inter… 18604. No       0.13     5.4     6.6     5.5 Aver… NA   \n 5 FN-5          Inter…   143. No       0.6      5.9     6.7     5.4 Aver… NA   \n 6 FN-6          Inter…  1402. No       0.54     5.7     6.4     6.2 Aver… NA   \n 7 FN-7          Inter…   986. No       0.49     3       6.8     5.3 Aver… NA   \n 8 FN-8          Inter…  2189. No       0.55     7.4     6.4     5.2 Belo… NA   \n 9 FN-9          Inter…   391. No       0.67     5.3     6.1     5   Belo… NA   \n10 FN-10         Inter…   544. No       0.63     5.7     6.2     5.1 Belo… NA   \n# … with 174 more rows, 1 more variable: `par(mfrow=c(2,2))` <chr>, and\n#   abbreviated variable names ¹​`Expense Ratio`, ²​`Return 2009`,\n#   ³​`3-Year Return`, ⁴​`5-Year Return`\n\n$IGDATA\n# A tibble: 87 × 11\n   `Fund Number` Type  Assets Fees  Expen…¹ Retur…² 3-Yea…³ 5-Yea…⁴ Risk    Bins\n   <chr>         <chr>  <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <dbl>\n 1 FN-1          Inte…  7268. No       0.45     6.9     6.9     5.5 Belo… -10.0 \n 2 FN-2          Inte…   475. No       0.5      9.8     7.5     6.1 Belo…  -5.01\n 3 FN-3          Inte…   193  No       0.71     6.3     7       5.6 Aver…  -0.01\n 4 FN-4          Inte… 18604. No       0.13     5.4     6.6     5.5 Aver…   4.99\n 5 FN-5          Inte…   143. No       0.6      5.9     6.7     5.4 Aver…   9.99\n 6 FN-6          Inte…  1402. No       0.54     5.7     6.4     6.2 Aver…  15.0 \n 7 FN-7          Inte…   986. No       0.49     3       6.8     5.3 Aver…  20.0 \n 8 FN-8          Inte…  2189. No       0.55     7.4     6.4     5.2 Belo…  25.0 \n 9 FN-9          Inte…   391. No       0.67     5.3     6.1     5   Belo…  30.0 \n10 FN-10         Inte…   544. No       0.63     5.7     6.2     5.1 Belo…  35.0 \n# … with 77 more rows, 1 more variable: Midpoints <dbl>, and abbreviated\n#   variable names ¹​`Expense Ratio`, ²​`Return 2009`, ³​`3-Year Return`,\n#   ⁴​`5-Year Return`\n\n$STCDATA\n# A tibble: 97 × 11\n   `Fund Number` Type  Assets Fees  Expen…¹ Retur…² 3-Yea…³ 5-Yea…⁴ Risk    Bins\n   <chr>         <chr>  <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <dbl>\n 1 FN-88         Shor…  139.  No       0.51     5.5     5.1     4.3 Belo… -10.0 \n 2 FN-89         Shor…  124.  No       0.32     5       4.4     4.1 Belo…  -5.01\n 3 FN-90         Shor… 1922   Yes      1.08    12.1     5.5     5   Aver…  -0.01\n 4 FN-91         Shor…  203.  Yes      1        8.3     5.2     4.4 Belo…   4.99\n 5 FN-92         Shor…   66.1 No       0.71     6.8     4.9     4   Belo…   9.99\n 6 FN-93         Shor… 1346   No       0.65     8.6     6.1     4.8 Belo…  15.0 \n 7 FN-94         Shor… 4773.  No       0.56     5       4.9     4.2 Belo…  20.0 \n 8 FN-95         Shor…   77.5 No       0.51     2.2     3.7     3.5 Belo…  25.0 \n 9 FN-96         Shor…   76.2 No       0.68     2.5     5.2     4.2 Belo…  30.0 \n10 FN-97         Shor…  146.  No       0.55    12.2     5.8     4.8 Aver…  35.0 \n# … with 87 more rows, 1 more variable: Midpoints <dbl>, and abbreviated\n#   variable names ¹​`Expense Ratio`, ²​`Return 2009`, ³​`3-Year Return`,\n#   ⁴​`5-Year Return`\n\n$RETURN2009\n# A tibble: 97 × 2\n   `Intermediate Government` `Short Term Corporate`\n                       <dbl>                  <dbl>\n 1                       6.9                    5.5\n 2                       9.8                    5  \n 3                       6.3                   12.1\n 4                       5.4                    8.3\n 5                       5.9                    6.8\n 6                       5.7                    8.6\n 7                       3                      5  \n 8                       7.4                    2.2\n 9                       5.3                    2.5\n10                       5.7                   12.2\n# … with 87 more rows\n\n$JustData\n# A tibble: 184 × 9\n   `Fund Number` Type         Assets Fees  Expen…¹ Retur…² 3-Yea…³ 5-Yea…⁴ Risk \n   <chr>         <chr>         <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl> <chr>\n 1 FN-1          Intermediat…  7268. No       0.45     6.9     6.9     5.5 Belo…\n 2 FN-2          Intermediat…   475. No       0.5      9.8     7.5     6.1 Belo…\n 3 FN-3          Intermediat…   193  No       0.71     6.3     7       5.6 Aver…\n 4 FN-4          Intermediat… 18604. No       0.13     5.4     6.6     5.5 Aver…\n 5 FN-5          Intermediat…   143. No       0.6      5.9     6.7     5.4 Aver…\n 6 FN-6          Intermediat…  1402. No       0.54     5.7     6.4     6.2 Aver…\n 7 FN-7          Intermediat…   986. No       0.49     3       6.8     5.3 Aver…\n 8 FN-8          Intermediat…  2189. No       0.55     7.4     6.4     5.2 Belo…\n 9 FN-9          Intermediat…   391. No       0.67     5.3     6.1     5   Belo…\n10 FN-10         Intermediat…   544. No       0.63     5.7     6.2     5.1 Belo…\n# … with 174 more rows, and abbreviated variable names ¹​`Expense Ratio`,\n#   ²​`Return 2009`, ³​`3-Year Return`, ⁴​`5-Year Return`"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis, Modelling, and Decision-Making",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nJan 26, 2023\n\n\nFriends don’t let Friends use OneDrive for R Libraries\n\n\nRobert W. Walker\n\n\n1 min\n\n\n\n\n\n\n\nJan 25, 2023\n\n\nVisualizing Two Qualitative Variables\n\n\nRobert W. Walker\n\n\n1 min\n\n\n\n\n\n \n\n\n\nJan 25, 2023\n\n\nVisualizing One Quantitative Variable\n\n\nRobert W. Walker\n\n\n6 min\n\n\n\n\n\n \n\n\n\nJan 25, 2023\n\n\nChanging the Default ggplot theme\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nJan 25, 2023\n\n\nVisualizing Two Quantitative Variables\n\n\nRobert W. Walker\n\n\n1 min\n\n\n\n\n\n \n\n\n\nJan 25, 2023\n\n\nVisualizing One Qualitative Variable\n\n\nRobert W. Walker\n\n\n4 min\n\n\n\n\n\n \n\n\n\nJan 25, 2023\n\n\nVisualizing One Qualitative and One Quantitative Variable\n\n\nRobert W. Walker\n\n\n2 min\n\n\n\n\n\n\n\nJan 5, 2023\n\n\nGetting Started: R and RStudio\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nJan 4, 2023\n\n\nTutorials on Wrangling\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nSep 6, 2022\n\n\nA Small Thread on Smart Prediction\n\n\nRobert W. Walker\n\n\n5 min\n\n\n\n\n\n\n\nApr 12, 2022\n\n\nNormal Residuals in Radiant\n\n\nRobert W. Walker\n\n\n1 min\n\n\n\n\n\n\n\nJun 30, 2021\n\n\nggtimeseries\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nJun 28, 2021\n\n\nthe clock package: a c port\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nJun 24, 2021\n\n\nA nice post on seasonal adjustment\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nJun 24, 2021\n\n\nEasy moving averages\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nJun 24, 2021\n\n\nA brief look at VIX\n\n\nRobert W. Walker\n\n\n2 min\n\n\n\n\n\n\n\nMay 29, 2021\n\n\nAllison Horst teaches ACFs\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\n\nMar 24, 2021\n\n\ntimetk is really, really handy\n\n\nRobert W. Walker\n\n\n2 min\n\n\n\n\n\n\n\nNov 28, 2020\n\n\nfredr: quick and dirty\n\n\nRobert W. Walker\n\n\n1 min\n\n\n\n\n\n\n\nNov 24, 2020\n\n\nVaccine Efficacy: A Binomial Problem\n\n\nRobert W. Walker\n\n\n2 min\n\n\n\n\n\n \n\n\n\nSep 13, 2020\n\n\nImporting Excel Data\n\n\nRobert W. Walker\n\n\n1 min\n\n\n\n\n\n\n\nSep 12, 2020\n\n\nPivoting Data: Long and Wide\n\n\nRobert W. Walker\n\n\n7 min\n\n\n\n\n\n \n\n\n\nOct 25, 2019\n\n\nA Quick and Dirty Introduction to R\n\n\nRWW\n\n\n1 min\n\n\n\n\n\n\n \n\n\n\nOct 9, 2019\n\n\nTables, Pivots, Bars, and Mosaics\n\n\nRWW\n\n\n16 min\n\n\n\n\n\n\n\nJan 1, 2019\n\n\nWelcome to the FAQ for DADM\n\n\nRobert W. Walker\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the DADM FAQ",
    "section": "",
    "text": "GSM 5103 and GSMPR 622 are the core courses in statistics and data education in the Atkinson Graduate School of Management at Willamette University. This web presence collects a series of discord threads that I created since the pandemic began. Rather than having to move them among instances, I can give them a permanent home here."
  },
  {
    "objectID": "about.html#maintainer",
    "href": "about.html#maintainer",
    "title": "About the DADM FAQ",
    "section": "Maintainer",
    "text": "Maintainer\nRobert W. Walker is Associate Professor of Quantitative Methods in the Atkinson Graduate School of Management at Willamette University. He earned a Ph. D. in political science from the University of Rochester in 2005 and has previously held teaching positions at Dartmouth College, Rice University, Texas A&M University, and Washington University in Saint Louis. His current research develops and applies semi-Markov processes to time-series, cross-section data in international relations and international/comparative political economy. He teaches courses in quantitative methods/applied statistics and microeconomic strategy and previously taught four iterations in the U. S. National Science Foundation funded Empirical Implications of Theoretical Models sequence at Washington University in Saint Louis. His work with Curt Signorino and Muhammet Bas was awarded the Miller Prize for the best article in Political Analysis in 2009."
  }
]